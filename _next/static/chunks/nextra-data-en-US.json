{"/concurrent-programming-basic/blocking-vs-nonblocking":{"title":"Blocking Vs Nonblocking","data":{"블로킹-vs-논블로킹#블로킹 vs 논블로킹":"","블로킹#블로킹":"블로킹 연산은 이전 문서에서 살펴봤던 동기화 예제에서 모두 살펴봤었습니다. 동기화를 논블로킹 방식으로도 수행할 수 있는데 논블로킹 방식으로 동기화를 수행하는 것은 아래에 별도의 섹션에서 정리하도록 하겠습니다.블로킹이라는 것은 어떤 작업이 끝날 때까지 이 작업을 호출한 곳에서 기다리는 것을 의미합니다. 쉽게 이야기해서 caller 가 callee 의 작업이 끝날 때 까지 기다리는 것을 의미합니다.블로킹 기반으로 동기(Synchronization) 연산을 수행하는 예제는 아래와 같습니다.","블로킹-기반의-동기synchronization-예제#블로킹 기반의 동기(Synchronization) 예제":"package io.chagchagchag.example.foobar.concurrent.sync_async.simple;\r\n\r\nimport java.time.LocalTime;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class SimpleSyncExample {\r\n  public static void main(String [] args){\r\n    log.info(\"(start) main function \" + LocalTime.now());\r\n    var result = getLongDelayJob();\r\n    var increased = result + 1;\r\n    assert increased == 501;\r\n    log.info(\"(end) main function \" + LocalTime.now());\r\n  }\r\n\r\n  public static int getLongDelayJob(){\r\n    long current = System.currentTimeMillis();\r\n    while(true){\r\n      long timeSpent = System.currentTimeMillis() - current;\r\n      if(timeSpent > 1000) break;\r\n    }\r\n    return 500;\r\n  }\r\n}\n출력결과\n15:20:13.250 [main] INFO ...sync_async.simple.SimpleAsyncExample -- (start) main function 15:20:13.248764\r\n15:20:14.253 [main] INFO ...sync_async.simple.SimpleAsyncExample -- (end) main function 15:20:14.253948300","블로킹-방식의-비동기asynchronization-예제#블로킹 방식의 비동기(Asynchronization) 예제":"package io.chagchagchag.example.foobar.concurrent.sync_async.simple;\r\n\r\nimport java.time.LocalTime;\r\nimport java.util.function.Consumer;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class SimpleAsyncExample {\r\n  public static void main(String [] args){\r\n    log.info(\"(start) main function \" + LocalTime.now());\r\n    execLongDelayJob(i -> {\r\n      var result = i + i;\r\n      log.info(\"result == {}\", result);\r\n    });\r\n    log.info(\"(end) main function \" + LocalTime.now());\r\n  }\r\n\r\n  public static void execLongDelayJob(Consumer<Integer> consumer){\r\n    final long current = System.currentTimeMillis();\r\n    while(true){\r\n      final long spent = System.currentTimeMillis() - current;\r\n      if(spent > 1000) break;\r\n    }\r\n\r\n    consumer.accept(500);\r\n  }\r\n}\r\n출력결과\n16:38:48.054 [main] INFO ...sync_async.simple.SimpleAsyncExample -- (start) main function 16:38:48.050013500\r\n16:38:49.062 [main] INFO ...sync_async.simple.SimpleAsyncExample -- result == 1000\r\n16:38:49.064 [main] INFO ...sync_async.simple.SimpleAsyncExample -- (end) main function 16:38:49.063973","논블로킹#논블로킹":"","논블로킹-방식의-동기-synchronization-예제#논블로킹 방식의 동기 (Synchronization) 예제":"논블로킹 방식으로 동기연산을 수행하려면 어떻게 해야할까요? callee 측의 작업이 오래 걸리는 작업입니다. 그런데 caller 측에서는 블로킹이 일어나지 않아야 합니다. 맞습니다. 이런 경우 callee 측의 작업을 별도의 스레드에서 수행하고 이 별도의 스레드가 끝났는지를 주기적으로 체크합니다. 그리고 작업이 끝난 것을 확인했을 때 연산 결과값을 이용해서 다음 작업을 수행합니다. 별도의 스레드가 끝났는지 주기적으로 체크하는 동안에는 다른 작업을 수행하게 될 수 있기에 논블로킹이라고 부릅니다.예제는 아래와 같습니다.\npackage io.chagchagchag.example.foobar.concurrent.sync_async;\r\n\r\nimport java.time.LocalTime;\r\nimport java.util.concurrent.ExecutionException;\r\nimport java.util.concurrent.Executors;\r\nimport java.util.concurrent.Future;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class SyncNonBlockingExample {\r\n  public static void main(String [] args) throws InterruptedException, ExecutionException {\r\n    log.info(\"(start) main function \" + LocalTime.now());\r\n\r\n    var count = 1;\r\n    Future<Integer> job = doLongDelayJob();\r\n    while(!job.isDone()){\r\n      log.info(String.format(\"대기 중... %s\", count++)); // 대기 중에 counting 연산을 수행\r\n      Thread.sleep(100);\r\n    }\r\n\r\n    var total = job.get() + 1;\r\n    assert total == 1112;\r\n\r\n    log.info(\"(end) main function \" + LocalTime.now());\r\n  }\r\n\r\n  public static Future<Integer> doLongDelayJob(){\r\n    var executor = Executors.newSingleThreadExecutor();\r\n    try{\r\n      return executor.submit(() -> {\r\n        long start = System.currentTimeMillis();\r\n        while(true){\r\n          long delay = System.currentTimeMillis() - start;\r\n          if(delay > 1000) break;\r\n        }\r\n        return 1111;\r\n      });\r\n    }\r\n    catch (Exception e){\r\n      e.printStackTrace();\r\n      throw new RuntimeException(\"ERROR\");\r\n    }\r\n    finally {\r\n      executor.shutdown();\r\n    }\r\n  }\r\n}\n출력결과\n18:07:59.983 [main] INFO ...sync_async.SyncNonBlockingExample -- (start) main function 18:07:59.979258800\r\n18:07:59.997 [main] INFO ...sync_async.SyncNonBlockingExample -- 대기 중... 1\r\n18:08:00.111 [main] INFO ...sync_async.SyncNonBlockingExample -- 대기 중... 2\r\n18:08:00.222 [main] INFO ...sync_async.SyncNonBlockingExample -- 대기 중... 3\r\n18:08:00.332 [main] INFO ...sync_async.SyncNonBlockingExample -- 대기 중... 4\r\n18:08:00.441 [main] INFO ...sync_async.SyncNonBlockingExample -- 대기 중... 5\r\n18:08:00.551 [main] INFO ...sync_async.SyncNonBlockingExample -- 대기 중... 6\r\n18:08:00.662 [main] INFO ...sync_async.SyncNonBlockingExample -- 대기 중... 7\r\n18:08:00.771 [main] INFO ...sync_async.SyncNonBlockingExample -- 대기 중... 8\r\n18:08:00.880 [main] INFO ...sync_async.SyncNonBlockingExample -- 대기 중... 9\r\n18:08:00.990 [main] INFO ...sync_async.SyncNonBlockingExample -- 대기 중... 10\r\n18:08:01.099 [main] INFO ...sync_async.SyncNonBlockingExample -- (end) main function 18:08:01.098719700\n출력결과에서 보이듯 caller 측에서는 100ms 마다 한번씩 자기자신의 일을 수행하면서 doLongDelayJob() 함수의 결과값을 리턴받기를 기다립니다. doLongDelayJob() 함수가 실행중일 동안 caller 가 블로킹된 것이 아니기에 논블로킹방식이라고 부릅니다.\n위의 논블로킹 방식의 동기연산을 그림으로 표현하면 아래와 같습니다.","논블로킹-방식의-비동기-synchronization-예제#논블로킹 방식의 비동기 (Synchronization) 예제":"블로킹 방식의 비동기(Asynchronization) 예제에서는 caller 가 callee 측의 연산의 결과값을 알아야 할 필요가 없음에도 caller 가 블로킹되고 있었습니다.그렇다면 caller 가 블로킹되지 않도록 논블로킹 방식으로 callee 를 호출하려면 어떻게 해야할까요? 그렇습니다. 별도의 스레드에서 callee 를 호출하고 caller 는 자신의 작업을 계속하면 됩니다.예제는 아래와 같습니다.\npackage io.chagchagchag.example.foobar.concurrent.sync_async;\r\n\r\nimport java.time.LocalTime;\r\nimport java.util.concurrent.Executors;\r\nimport java.util.function.Consumer;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class AsyncNonBlockingExample {\r\n  public static void main(String [] args){\r\n    log.info(\"(start) main function \" + LocalTime.now());\r\n    execLongDelayJob(i -> {\r\n      var result = 1 + i;\r\n      assert result == 1112;\r\n      log.info(\"result = {}\", result);\r\n    });\r\n    log.info(\"(end) main function \" + LocalTime.now());\r\n  }\r\n\r\n  public static void execLongDelayJob(Consumer<Integer> callback){\r\n    var executor = Executors.newSingleThreadExecutor();\r\n    try{\r\n      executor.submit(()->{\r\n        long start = System.currentTimeMillis();\r\n        while(true){\r\n          long delay = System.currentTimeMillis() - start;\r\n          if(delay > 1000) break;\r\n        }\r\n        callback.accept(1111);\r\n        log.info(\"작업이 끝났어요~!!! --- \" + LocalTime.now());\r\n        return 1111;\r\n      });\r\n    }\r\n    catch (Exception e){\r\n      e.printStackTrace();\r\n      throw new RuntimeException(\"ERROR\");\r\n    }\r\n    finally {\r\n      executor.shutdown();\r\n    }\r\n  }\r\n}\n출력결과\n18:21:05.366 [main] INFO ...sync_async.AsyncNonBlockingExample -- (start) main function 18:21:05.361457\r\n18:21:05.382 [main] INFO ...sync_async.AsyncNonBlockingExample -- (end) main function 18:21:05.381471500\r\n18:21:06.383 [pool-1-thread-1] INFO ...sync_async.AsyncNonBlockingExample -- result = 1112\r\n18:21:06.387 [pool-1-thread-1] INFO ...sync_async.AsyncNonBlockingExample -- 작업이 끝났어요~!!! --- 18:21:06.387829200\n출력결과에서 보이듯 caller 측인 메인 스레드의 호출작업이 모두 끝나고 메인스레드는 자기 자신을 종료합니다. 하지만, 별도의 스레드에서 수행되고 있는 callee 는 1초 뒤에 자기 자신이 작업을 완료했음을 로그에서 표현하고 있습니다.\n위의 논블로킹 방식의 비동기 연산을 그림으로 표현하면 아래와 같습니다."}},"/concurrent-programming-basic/completable-future":{"title":"Completable Future","data":{"completablefuture#CompletableFuture":""}},"/":{"title":"Introduction","data":{"":"목차\n동시성 프로그래밍 개념들\nNIO, AIO\nReactive Programming\nSpring Webflux\nSpring Cloud Stream With Kafka\nSpring Cloud Reactive Circuit Breaker\nKotlin Coroutine\nServer Sent Event(SSE)\nWebflux Websocket\nSpring Data R2dbc\nSpring Data Reactive Mongodb"}},"/concurrent-programming-basic/completable-stage":{"title":"Completable Stage","data":{"completablestage#CompletableStage":""}},"/concurrent-programming-basic/sync-vs-async":{"title":"Sync Vs Async","data":{"동기-vs-비동기#동기 vs 비동기":"오늘은 감기기운이 있어서 문서 작업을 시작하려 하는 데에 시간이 꽤 걸리기도 했고 분리수거 + 집안 청소를 하느라 거의 2시간 이상이 걸렸네요. 골골 거리면서 청소한다고 머리까지 아파서 라면을 엄청 맵고 짜게 끌여먹으면서 박카스를 마시니 그나마 나아지네요. 라면 + 박카스는 저의 민간요법 중 하나입니다....오늘 정리할 내용은 동기 vs 비동기 에 관련된 내용입니다. 너무 진지하게 심취하기보다는 비교적 쉽고 융통성 있게 개념을 정리하려 노력해보겠습니다.\r\n이걸 언제 정리하고 있나 하면서 멍때리다가 천리길도 한걸음부터라는 생각이 들면서 정리를 다시 시작하게 되었습니다","동기-synchronization#동기 (Synchronization)":"동기 라는 개념은 컴퓨터공학, 전자공학을 배우신 분들은 익숙하실 듯 합니다. 흔히 트랜지스터 별로 클록이 다르기에 서로 클록이 1이 되는 시점을 맞춰서 동기화 하는 그런 글들이 보신적이 있을 겁니다.컴퓨터공학, 전자공학이 아니더라도 일반인 분들 역시 드롭박스나 구글 드라이브에서 한동안 유행했던 동기화 버튼을 본적이 있을 것입니다.동기화라는 개념을 쉽게 설명하면 이렇습니다. 한쪽에서 다른 쪽의 결과값을 받아서 결과값을 맞추는 것을 동기화라고 합니다. 함수 관점에서 동기화는 caller 가 callee 의 결과값을 알기 위해 리턴값을 받는 동작을 의미합니다. 이때 callee 의 작업이 오래 걸리게 되어 기다리게 된다면 이렇게 기다리는 작업은 Blocking 이라고 부릅니다. 따라서 위의 예제는 블로킹 방식의 동기연산입니다.쉽게 이야기하면 아래와 같은 코드가 동기화를 수행하는 코드입니다.\npackage io.chagchagchag.example.foobar.concurrent.sync_async.simple;\r\n\r\nimport java.time.LocalTime;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class SimpleSyncExample {\r\n  public static void main(String [] args){\r\n    log.info(\"(start) main function \" + LocalTime.now());\r\n    var result = getLongDelayJob();\r\n    var increased = result + 1;\r\n    assert increased == 501;\r\n    log.info(\"(end) main function \" + LocalTime.now());\r\n  }\r\n\r\n  public static int getLongDelayJob(){\r\n    long current = System.currentTimeMillis();\r\n    while(true){\r\n      long timeSpent = System.currentTimeMillis() - current;\r\n      if(timeSpent > 1000) break;\r\n    }\r\n    return 500;\r\n  }\r\n}\n출력결과\n15:20:13.250 [main] INFO ...sync_async.simple.SimpleAsyncExample -- (start) main function 15:20:13.248764\r\n15:20:14.253 [main] INFO ...sync_async.simple.SimpleAsyncExample -- (end) main function 15:20:14.253948300\n\r\ncaller 인 main() 함수는 callee 인 getLongDelayJob() 함수가 1초가 넘게 실행이 끝날 때 까지 기다리고 있습니다.이렇게 caller 가 callee 의 결과를 알아야 다음 수행이 가능할 때 Synchronized 연산이라고 부르고, 1초가 넘도록 대기하게 되는 현상은 Blocking 이라고 부릅니다.요약해보겠습니다. 동기화는 caller 가 callee 의 결과값을 알기 위해 리턴값을 받는 동작을 의미합니다. 이때 callee 의 작업이 오래 걸리게 되어 기다리게 된다면 이렇게 기다리는 작업은 Blocking 이라고 부릅니다. 따라서 위의 예제는 블로킹 방식의 동기연산입니다.","흔한-단어의-오용--동기화-vs-블로킹#흔한 단어의 오용 : 동기화 vs 블로킹":"많은 사람들이 오해를 하는 내용이고 저 역시도 오해를 한적이 있습니다.블로킹은 하나의 연산이 오래 걸리는 것으로 인해 다른 연산들을 막고 있는 것을 의미합니다.반면 동기화는 한쪽에서 다른 한쪽의 값이 필요할 때 그 값을 가져와서 그 값을 기반으로 다른 작업을 수행하는 것을 의미합니다.교과서에 자주 나오는 동기화 예제를 보면 오래 걸리는 작업을 멀티 스레드 기반으로 돌릴때 조건변수의 동기화에 대한 예제가 많다보니 동기화는 블로킹이 일어난다는 착각이 들기 쉬운데요. 동기화와 블로킹은 개념이 가리키는 포인트가 조금 다릅니다. 동기화는 값을 맞추는 것을 의미하고, 블로킹은 어떤 작업이 오래 걸리는 것으로 인해 기다리고 있는 현상을 의미합니다. 동기화가 시간이 오래 걸리는 작업을 의미하지는 않습니다. 어떤 값을 리턴받은 것을 맞추는(싱크)하는 작업이라고 생각하면 쉽습니다.","비동기-asynchronization#비동기 (Asynchronization)":"비동기는 caller 가 callee 를 호출했을 때 callee 가 반환하는 값을 기반으로 caller 가 이 값으로 다른 작업을 수행할 필요가 없을때 주로 비동기라고 합니다. 쉽게 이야기하면 caller 가 callee 의 값을 받아서 맞출 필요가 없는 경우를 의미합니다.아래는 비동기 예제입니다. 위에서 살펴봤던 동기 방식의 예제를 비동기 버전으로 바꿨습니다. 그리고 비동기방식이지만 여전히 블로킹이 되고 있습니다.\npackage io.chagchagchag.example.foobar.concurrent.sync_async.simple;\r\n\r\nimport java.time.LocalTime;\r\nimport java.util.function.Consumer;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class SimpleAsyncExample {\r\n  public static void main(String [] args){\r\n    log.info(\"(start) main function \" + LocalTime.now());\r\n    execLongDelayJob(i -> {\r\n      var result = i + i;\r\n      log.info(\"result == {}\", result);\r\n    });\r\n    log.info(\"(end) main function \" + LocalTime.now());\r\n  }\r\n\r\n  public static void execLongDelayJob(Consumer<Integer> consumer){\r\n    final long current = System.currentTimeMillis();\r\n    while(true){\r\n      final long spent = System.currentTimeMillis() - current;\r\n      if(spent > 1000) break;\r\n    }\r\n\r\n    consumer.accept(500);\r\n  }\r\n}\r\n출력결과\n16:38:48.054 [main] INFO ...sync_async.simple.SimpleAsyncExample -- (start) main function 16:38:48.050013500\r\n16:38:49.062 [main] INFO ...sync_async.simple.SimpleAsyncExample -- result == 1000\r\n16:38:49.064 [main] INFO ...sync_async.simple.SimpleAsyncExample -- (end) main function 16:38:49.063973\ncaller 인 main 스레드는 여전히 callee 인 execLongDelayJob(Consumer) 의 작업이 끝나고 있기를 기다리고 있는 현상은 Blocking 입니다. 하지만, callee 인 execLongDelayJob(Consumer) 의 결과값을 알 필요는 없습니다. 이렇게 caller 가 callee 의 연산 결과를 알 필요가 없는 경우의 연산을 비동기 라고 부릅니다."}},"/kotlin-coroutine/intro":{"title":"Intro","data":{"":"kotlin 과 kotlin 의 coroutine 에 대해서는 아래 문서를 참고바랍니다.\nchagchagchag.github.io/docs-kotlin-coroutine"}},"/nio-and-aio/java-io-java-nio-java-aio":{"title":"Java Io Java Nio Java Aio","data":{"java-io-vs-java-nio-vs-java-aio#Java IO vs Java NIO vs Java AIO":"","함수-호출-관점#함수 호출 관점":"동기\t비동기\tBlocking\tJava IO\tX\tNon-Blocking\tJava NIO(File IO 는 Non Blocking 불가)\tJava AIO\t\n함수의 호출로만 봤을 때 Java IO, Java NIO, Java AIO 는 각각 아래와 같습니다.\nJava IO : 블로킹 방식의 동기 연산입니다.\nJava NIO : 논블로킹 방식의 동기 연산입니다. 다만, File IO 는 Java NIO 에서도 Non Blocking 이 불가능합니다.\nJava AIO : 논블로킹 방식의 비동기 연산이 가능합니다.","io-모델-관점#IO 모델 관점":"동기\t비동기\tBlocking\tJava IO\tX\tNon-Blocking\tJava NIO, Java AIO\tX\t\nIO 모델 방식으로 따져봤을 때 Java IO, Java NIO, Java AIO 는 각각 아래와 같습니다.\nJava IO : 블로킹 기반의 동기 연산입니다.\nJava NIO : 논블로킹 방식의 동기 연산입니다.\nJAVA AIO : Java AIO 역시 IO 연산작업에 있어서는 블로킹 방식의 동기연산이 됩니다.","java-io#Java IO":"Java IO 는 Java 1.0 부터 처음 도입되었습니다. Java IO 는 블로킹 방식의 동기연산을 수행합니다. Java IO는 파일과 네트워크에 데이터를 읽고 쓸 수 있는 InputStream, OutputStream API를 제공합니다."}},"/concurrent-programming-basic/intro":{"title":"Intro","data":{}},"/nio-and-aio/intro":{"title":"Intro","data":{}},"/nio-and-aio/java-nio-socket-communication":{"title":"Java Nio Socket Communication","data":{"java-의-socket-통신#Java 의 Socket 통신":"설명은 추후 시간이 나는대로 계속해서 업데이트 해나갈 예정입니다.","예제-1#예제 1":"예제코드는 https://github.com/chagchagchag/webflux-mongo-mysql-redis/tree/main/demo-nio/src/main/java/io/chagchagchag/example/foobar/nio/socket 에 Example1_ 로 시작하는 파일명 들입니다.","client#Client":"package io.chagchagchag.example.foobar.nio.socket;\r\n\r\nimport java.net.InetSocketAddress;\r\nimport java.nio.ByteBuffer;\r\nimport java.nio.channels.SocketChannel;\r\nimport java.nio.charset.StandardCharsets;\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class Example1_Client_SocketChannel {\r\n  @SneakyThrows\r\n  public static void main(String [] args){\r\n    log.info(\"main function start\");\r\n    try(var socketChannel = SocketChannel.open()){\r\n      var address = new InetSocketAddress(\"localhost\", 8080);\r\n      var connected = socketChannel.connect(address);\r\n      log.info(\"connected : {}\", connected);\r\n\r\n      String message = \"안녕하세요. 클라이언트에요.\";\r\n      ByteBuffer requestMessageBuffer = ByteBuffer.wrap(message.getBytes());\r\n      socketChannel.write(requestMessageBuffer);\r\n      requestMessageBuffer.clear();\r\n\r\n      ByteBuffer result = ByteBuffer.allocateDirect(1024);\r\n      while(socketChannel.read(result) > 0){\r\n        result.flip();\r\n        log.info(\"서버 응답 (Response) = {}\", StandardCharsets.UTF_8.decode(result));\r\n        result.clear();\r\n      }\r\n    }\r\n    log.info(\"main function end\");\r\n  }\r\n}","server#Server":"Channel 을 통해서 소켓 커넥션을 열고 Channel 로 accept() 를 합니다. 소켓통신을 배워본적이 있다면 accept()는 클라이언트의 응답을 기다리는 동작이라는 것을 알고 계실 겁니다. Java IO 에서의 ServerSocket 의 accept() 는 블로킹이 발생하는 작업이지만, NIO는 accept() 를 논블로킹 방식으로 수행합니다.\npackage io.chagchagchag.example.foobar.nio.socket;\r\n\r\nimport java.net.InetSocketAddress;\r\nimport java.nio.ByteBuffer;\r\nimport java.nio.channels.ServerSocketChannel;\r\nimport java.nio.charset.StandardCharsets;\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class Example1_Server_ServerSocketChannel {\r\n  @SneakyThrows\r\n  public static void main (String [] args){\r\n    log.info(\"main function started\");\r\n    try(var serverChannel = ServerSocketChannel.open()){\r\n      var address = new InetSocketAddress(\"localhost\", 8080);\r\n      serverChannel.bind(address);\r\n\r\n      try(var clientSocket = serverChannel.accept()){\r\n        ByteBuffer buffer = ByteBuffer.allocateDirect(1024);\r\n        clientSocket.read(buffer);\r\n        buffer.flip();\r\n\r\n        var decodeMessage = StandardCharsets.UTF_8.decode(buffer);\r\n        var clientMessage = String.valueOf(decodeMessage);\r\n        log.info(\"클라이언트로부터 온 메시지 = {}\", clientMessage);\r\n\r\n        var responseMessage = \"안녕하세요. 저는 서버입니다.\";\r\n        var responseBuffer = ByteBuffer.wrap(responseMessage.getBytes());\r\n        clientSocket.write(responseBuffer);\r\n        responseBuffer.flip();\r\n      }\r\n    }\r\n    log.info(\"main function end\");\r\n  }\r\n}","출력결과#출력결과":"","client-1#Client":"10:37:59.175 [main] INFO io.chagchagchag.example.foobar.nio.socket.Example1_Client_SocketChannel -- main function start\r\n10:37:59.196 [main] INFO io.chagchagchag.example.foobar.nio.socket.Example1_Client_SocketChannel -- connected : true\r\n10:38:17.826 [main] INFO io.chagchagchag.example.foobar.nio.socket.Example1_Client_SocketChannel -- 서버 응답 (Response) = 안녕하세요. 저는 서버입니다.\r\n10:38:17.827 [main] INFO io.chagchagchag.example.foobar.nio.socket.Example1_Client_SocketChannel -- main function end\r\n\r\nProcess finished with exit code 0","server-1#Server":"10:36:40.736 [main] INFO io.chagchagchag.example.foobar.nio.socket.Example1_Server_ServerSocketChannel -- main function started\r\n\r\nProcess finished with exit code 130"}},"/nio-and-aio/what-is-nio":{"title":"What Is Nio","data":{"java-nio#Java NIO":"Java NIO 는 Java New Input/Output 을 의미합니다. (Non blocking IO 를 의미하는 것은 아닙니다.)Java NIO 는 Java 1.4 에서 처음 도입되었고 파일과 네트워크에 데이터를 읽고 쓸 수 있는 API 를 제공하고 있습니다. 대부분의 I/O에 대해서는 논블로킹 방식의 동기 연산을 지원하지만 Java NIO 역시 File I/O 의 경우는 블로킹 방식의 동기 연산만 지원됩니다.Selector, Channel 기반으로 높은 성능을 제공하는데, 톰캣에서도 NIO가 지원되고 Netty 역시 NIO 기반으로 이루어져 있습니다. 다만 톰캣의 경우 스레드 풀 기반으로 커넥션 풀을 관리하는데 스레드를 그대로 가져다 쓰는 것으로 인해 Netty 에 비해 조금은 무거운 컨테이너입니다.JAVA IO 는 byte 또는 character 기반의 데이터 단위로 데이터를 처리하지만 Java NIO 는 buffer 단위로 데이터를 처리합니다. Java IO 에서는 흔히 잘 알려져 있는 InputStream, OutputStream 을 이용해서 데이터를 처리하지만 Java NIO 에서는 Channel 단위로 데이터를 처리합니다.지금까지의 내용을 정리해보면 아래와 같습니다.\n\tJava NIO\tJava IO\t데이터 처리 방향\t양방향\t단방향\t데이터 처리 방식\tChannel\tInputStream, OutputStream\t데이터 단위\tbuffer\tbyte, character\tnonblocking?\tFile IO를 제외한 모든 IO에 대해 논블로킹방식의 동기연산을 지원\t모든 IO 연산을 Blocking 방식의 동기연산으로만 수행 가능\tetc\tSelector 지원","channel-buffer-의-개념#Channel, Buffer 의 개념":"위에서 살펴봤던 표에서는 Channel, Buffer 의 개념을 설명해보겠습니다. Buffer 는 데이터를 읽거나 쓰기 위해 데이터를 저장하는 용도로 사용합니다. 그리고 이 Buffer 에 접근하기 위해서는 Channel 의 read(), write() 함수를 사용해서 읽거나 쓰는 행동을 수행합니다.\nread() 함수를 수행할 때에는 사이즈에 맞는 Buffer 를 생성하고 Channel 으l read()  를 사용해서 File 의 내용들을 Buffer 에 기록합니다.\nwrite() 함수를 수행할 때에는 사이즈에 맞는 Buffer 를 생성하고 Channel 의 write() 를 사용해서 File 에 Buffer 에 있는 내용들을 기록합니다.","buffer-클래스의-종류#Buffer 클래스의 종류":"ByteBuffer : byte 단위로 데이터를 읽고 씁니다. 하위자료형으로는 HeapByteBuffer, MappedByteBuffer, DirectByteBuffer 가 있습니다. 이 Buffer 들에 대해서는 이 문서 내의 Java NIO의 주요 Buffer들 (커널 접근 가능 여부 등) 에 정리해두었습니다.\nCharBuffer, ShortBuffer, IntBuffer, LongBuffer\n각각 char 단위, short 단위, int 단위, long 단위를 읽을 수 있는 버퍼입니다.\nFloatBuffer, DoubleBuffer : 실수자료형을 취급하는 Buffer 입니다.","java-nio-의-주요-buffer들-커널-접근-가능-여부-등#Java NIO 의 주요 Buffer들 (커널 접근 가능 여부 등)":"","directbytebuffer#DirectByteBuffer":"DirectByteBuffer 는 off-heap 메모리에 데이터를 저장합니다. 커널 메모리에서 복사ㅡㄹ 하지 않기에 데이터를 읽고 쓰는 속도가 빠릅니다. 다만 비용이 많이 드는 System Call 을 사용하기에 allocate, deallocate가 느리다는 단점이 있습니다.allocateDirect() 함수로 생성가능합니다. 아래는 DirectByteBuffer 를 생성하는 예제 코드입니다.\nvar directByteBuffer = ByteBuffer.allocateDirect(1024);\r\nassert directByteBuffer.isDirect();","heapbytebuffer#HeapByteBuffer":"HeapByteBuffer 는 데이터를 JVM Heap 메모리에 저장합니다. byte array 를 래핑하는 Buffer 인데, 커널 메모리에서 복사해서 저장하는 버퍼이기에 복사에 대한 연산으로 인해 커널을 한번 더 IO 가 일어난다는 점에서 읽기 속도가 느리다는 단점이 있습니다. (내부적으로는 임시로 Direct Buffer 를 만드는 연산을 수행하기에 성능이 저하됩니다.)GC에 의해 관리되기에 allocate, deallocate 가 빠릅니다.allocate() 함수 또는 wrap() 함수로 생성 가능합니다. 아래는 HeapByteBuffer 를 생성하는 예제 코드 입니다.\nvar heapByteBuffer = ByteBuffer.allocate(1024);\r\nassert !heapByteBuffer.isDirect(); \r\n\r\nvar byteBufferByWrap = ByteBuffer.wrap(\"hello\".getBytes()); \r\nassert !byteBufferByWrap.isDirect();","buffer-의-위치-관련-주요-필드#Buffer 의 위치 관련 주요 필드":"Buffer 에는 위치를 가리키는 주요 속성들이 있는데 이 속성들을 가리키는 메서드를 적절히 사용해야 NIO 소켓 프로그래밍 시에 유용하게 사용이 가능합니다.\ncapacity\nBuffer 가 저장할 수 있는 데이터의 최대 크기를 의미합니다. Buffer 생성시 지정해서 Buffer를 지정된 사이즈로 생성합니다. 한번 생성된 Buffer 사이즈는 변경이 불가합니다.\nposition\nBuffer 에서의 현재 위치를 가리키는 역할을 합니다. 버퍼에서 데이터를 읽거나 쓸때 현재 위치에서부터 시작하게 되고 Buffer 에 1Byte 가 추가될 때마다 1씩 위치 값이 증가합니다.\nlimit\nBuffer 에서 데이터를 읽거나 쓸 수 있는 마지막 위치를 의미합니다. capacity 와 같은 값입니다.\nmark\n현재 position 위치를 mark() 로 지정하는 것이 가능합니다. reset()을 호출할 경우에는 position 을 mark 로이동시킵니다.\n각 위치(오프셋) 또는 사이즈의 범위의 위치 등을 표현해보면 아래와 같습니다.\n0 <= mark <= position <= limit <= capacity\nBuffer 는 생성시에 capacity 를 기준으로 크기가 설정되는데 따라서 capacity 는 초기에 지정한 size 이기에 가장 맨 뒤의 위치를 가리키게 됩니다. limit 은 Buffer 생성 초기에는 capacity 가 가리키는 위치를 함께 가리킵니다. 그리고 데이터를 읽을 때는 처음부터 읽어야 하기 때문에 position 은 0 으로 초기에 세팅됩니다.","buffer-의-주요-메서드#Buffer 의 주요 메서드":"","flip#flip()":"flip() 메서드\nbuffer 의 limit 위치를 현재 position 으로 위치시킵니다.\nlimit의 위치 변경이 완료되면 position 의 위치를 0으로 변경합니다.\nbuffer 를 쓰기 모드에서 읽기 모드로 전환할 때 사용합니다.\n현재까지 읽던 위치로 limit 의 위치를 변경해서 position 을 0으로 해서 처음부터 limit 까지 읽는 동작을 의미합니다.","rewind-메서드#rewind() 메서드":"rewind()\n데이터를 처음부터 limit 만큼 읽어들일 때 사용하는 함수입니다. 데이터를 처음부터 읽어들이려 하는데 읽어들일 사이즈를 limit으로 지정합니다.\nbuffer 내의 position 을 0 으로 변경하는 이유는 데이터를 처음부터 다시 읽어들이기 위해서입니다.","clear-메서드#clear() 메서드":"clear()\n버퍼를 초기화 할 때 사용합니다. 버퍼를 초기화하므로 모든 위치(오프셋) 관련 변수들은 기본 값으로 변경해줍니다.\nbuffer 내의 limit 포인터의 위치는 capacity 의 위치로 바꿔주고, position 은 버퍼의 제일 앞 부분인 0 으로 초기화 해줍니다.","buffer-위치-이동-메서드-연습-예제#Buffer 위치 이동 메서드 연습 예제":"예제 코드는 https://github.com/chagchagchag/webflux-mongo-mysql-redis/blob/main/demo-nio/src/main/java/io/chagchagchag/example/foobar/nio/Example1_FileChannelRead.java 에서 확인 가능합니다.\n// ...\r\n\r\n@Slf4j\r\npublic class Example1_FileChannelRead {\r\n  @SneakyThrows\r\n  public static void main(String [] args){\r\n    log.info(\"main function started\");\r\n\r\n    var path = Example1_FileChannelRead.class\r\n        .getClassLoader()\r\n        .getResource(\"example1-data.txt\")\r\n        .getFile();\r\n\r\n    var file = new File(path);\r\n\r\n    try (var fileChannel = FileChannel.open(file.toPath())){\r\n      var byteBuffer = ByteBuffer.allocateDirect(1024);\r\n      bufferLog(\"버퍼할당\", byteBuffer);\r\n\r\n\r\n      fileChannel.read(byteBuffer);\r\n      bufferLog(\"읽기 연산(read) - 버퍼에 쓰는 작업\", byteBuffer);\r\n\r\n      byteBuffer.flip();\r\n      bufferLog(\"읽기 전환(Flip)\", byteBuffer);\r\n\r\n      byteBuffer.rewind();\r\n      bufferLog(\"첫 위치로 전환(rewind)\", byteBuffer);\r\n\r\n      log.info(\"buffer = {}\", StandardCharsets.UTF_8.decode(byteBuffer));\r\n      bufferLog(\"Buffer연산 없이 decode 수행\", byteBuffer);\r\n\r\n      log.info(\"buffer = {}\", StandardCharsets.UTF_8.decode(byteBuffer));\r\n      bufferLog(\"Buffer연산 없이 decode 수행\", byteBuffer);\r\n\r\n      byteBuffer.clear();\r\n      bufferLog(\"clear\", byteBuffer);\r\n    }\r\n\r\n    log.info(\"main function end\");\r\n  }\r\n\r\n  public static void bufferLog(String operation, ByteBuffer buffer){\r\n    log.info(String.format(\"%s >>> position = %s, limit = %s, capacity = %s\\n\", operation, buffer.position(), buffer.limit(), buffer.capacity()));\r\n  }\r\n}\r\nexample1-data.txt\nNVIDIA Corporation provides graphics, and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications. The Compute & Networking segment comprises Data Center computing platforms and end-to-end networking platforms, including Quantum for InfiniBand and Spectrum for Ethernet; NVIDIA DRIVE automated-driving platform and automotive development agreements; Jetson robotics and other embedded platforms; NVIDIA AI Enterprise and other software; and DGX Cloud software and services. The company's products are used in gaming, professional visualization, data center, and automotive markets. It sells its products to original equipment manufacturers, original device manufacturers, system integrators and distributors, independent software vendors, cloud service providers, consumer internet companies, add-in board manufacturers, distributors, automotive manufacturers and tier-1 automotive suppliers, and other ecosystem participants. NVIDIA Corporation was incorporated in 1993 and is headquartered in Santa Clara, California.\r\n출처 : https://finance.yahoo.com/quote/NVDA/profile\n출력결과\n08:44:52.388 [main] INFO io...Example1_FileChannelRead -- main function started\r\n08:44:52.407 [main] INFO io...Example1_FileChannelRead -- 버퍼할당 >>> position = 0, limit = 1024, capacity = 1024\r\n\r\n08:44:52.407 [main] INFO io...Example1_FileChannelRead -- 읽기 연산(read) - 버퍼에 쓰는 작업 >>> position = 1024, limit = 1024, capacity = 1024\r\n\r\n08:44:52.408 [main] INFO io...Example1_FileChannelRead -- 읽기 전환(Flip) >>> position = 0, limit = 1024, capacity = 1024\r\n\r\n08:44:52.408 [main] INFO io...Example1_FileChannelRead -- 첫 위치로 전환(rewind) >>> position = 0, limit = 1024, capacity = 1024\r\n\r\n08:44:52.409 [main] INFO io...Example1_FileChannelRead -- buffer = NVIDIA Corporation provides graphics, and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications. The Compute & Networking segment comprises Data Center computing platforms and end-to-end networking platforms, including Quantum for InfiniBand and Spectrum for Ethernet; NVIDIA DRIVE automated-driving platform and automotive development agreements; Jetson robotics and other embedded platforms; NVIDIA AI Enterprise and other software; and DGX Cloud software and services. The company's products are used in gaming, professional visualization\r\n08:44:52.412 [main] INFO io...Example1_FileChannelRead -- Buffer연산 없이 decode 수행 >>> position = 1024, limit = 1024, capacity = 1024\r\n\r\n08:44:52.412 [main] INFO io...Example1_FileChannelRead -- buffer = \r\n08:44:52.412 [main] INFO io...Example1_FileChannelRead -- Buffer연산 없이 decode 수행 >>> position = 1024, limit = 1024, capacity = 1024\r\n\r\n08:44:52.412 [main] INFO io...Example1_FileChannelRead -- clear >>> position = 0, limit = 1024, capacity = 1024\r\n\r\n08:44:52.412 [main] INFO io...Example1_FileChannelRead -- main function end\r\n\r\nProcess finished with exit code 0","java-nio-사용시-non-blocking-방식으로-사용하는-방법#Java NIO 사용시 Non Blocking 방식으로 사용하는 방법":"SocketChannel, ServerSeocketChannel 이 extends 하고 있는 AbstractSelectableChannel 은 SelectableChannel 을 extends 하고 있습니다.\n그리고 SelectableChannel 은 configureBlocking(boolean), register() 함수를 제공하는데 그 중 configureBlocking(boolean) 메서드를 이용해 논블로킹을 지정가능합니다.serverSocketChannel 의 accept(), socketChannel 의 connect() 사용시 위의 configureBlocking(boolean) 을 사용하면 논블로킹으로 네트워크 IO를 할지여부를 지정가능합니다.e.g. ServerSocketChannel 의 accept() 메서드를 nonblocking 하게 실행\ntry (var serverChannel = ServerSocketChannel.open()){\r\n    var address = new InetSocketAddress(\"localhost\", 8080);\r\n    serverChannel.bind(address);\r\n    serverChannel.configureBlocking(false); /// nonblocking 설정 \r\n    \r\n    var clientSocket = serverChannel.accept(); \r\n    assert clientSocket !== null;\r\n}\ne.g. SocketChannel 의 connect() 메서드를 nonblocking 하게 실행\ntry (var socketChannel = SocketChannel.open()){\r\n    var address = new InetSocketAddress(\"localhost\", 8080);\r\n    socketChannel.configureBlocking(false);\r\n    var connected = socketChannel.connect(address);\r\n    assert !connected;\r\n}","nio-기반-간단한-소켓-프로그래밍-예제#NIO 기반 간단한 소켓 프로그래밍 예제":"예제와 설명은 Java NIO 소켓통신 을 참고해주세요."}},"/r2dbc-mysql/example":{"title":"Example","data":{}},"/nio-and-aio/what-is-aio":{"title":"What Is Aio","data":{"java-aio-의-개념-예제#Java AIO 의 개념, 예제":"","java-aio-란#Java AIO 란?":"Java AIO 는 NIO2 라고도 불리는 라이브러리입니다. Java 1.7 부터 지원되기 시작했습니다.Java AIO 에서는 아래와 같은 비동기 채널들이 지원됩니다.\nAsynchronousChannel\nAsynchronousSocketChannel\nAsynchronousServerSocketChannel\nAsynchronousFileChannel\nJava AIO 는 callback, future 를 이용해서 작업이 완료되었을 때의 동작을 식(Statement)로 전달할 수 있다는 장점이 있습니다.\n내부적으로는 Thread Pool, epoll, kqueue 등의 이벤트 알림 system call 을 이용해서 IO를 비동기적으로 처리합니다. IO 처리시에 내부적으로 처리를 하는 구조는 아래와 같습니다.Read, Write 등과 같은 IO 요청이 왔을 때 요청에 대해서 calller에게 Channel 객체 또는 Future 를 반환해줍니다. 그리고 내부적인 Thread Pool 내에 존재하는 Task Queue 에 이것을 쌓아둡니다. 그리고 내부적인 Thread 들은 이 Task Queue 내의 작업을 처리합니다.만약 처리가 모두 수행된다면 각각의 스레드는 자신에게 등록된 callback 을 수행합니다.그리고 Caller 측에서는 Callee 로부터 전달받은 Channel 또는 Future 를 지속적으로 isDone(), isOpen() 같은 메서드를 주기적으로 검사하는 작업을 통해 작업이 끝났음을 확인해서 후처리하는 것이 가능합니다. 이런 검사 작업은 별도의 스레드에서 주기적으로 검사하게 하는 등의 작업을 수행하게 하는 식으로 비동기 논블로킹의 작업이 되도록 구성하는 것 역시 가능합니다.","예제-1-file-aio---asyncfilechannel-예제#예제 1. File AIO - AsyncFileChannel 예제":"자세한 설명은 추후 시간이 된다면 설명을 추가하도록 하겠습니다. 현재 취직을 준비중이어서 다른 작업을 해야 해서 설명은 생략하겠습니다.","코드#코드":"예제 코드는 https://github.com/chagchagchag/webflux-mongo-mysql-redis/tree/main/demo-aio/src/main/java/io/chagchagchag/example/foobar/aio 에 있습니다.\npackage io..;\r\n\r\nimport java.io.File;\r\nimport java.nio.ByteBuffer;\r\nimport java.nio.channels.AsynchronousFileChannel;\r\nimport java.nio.channels.CompletionHandler;\r\nimport java.nio.charset.StandardCharsets;\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class Example1_AioFileChannel {\r\n  @SneakyThrows\r\n  public static void main(String [] args){\r\n    log.info(\"main function started\");\r\n\r\n    var filePath = Example1_AioFileChannel.class\r\n        .getClassLoader()\r\n        .getResource(\"example1-data.txt\")\r\n        .getFile();\r\n\r\n    var file = new File(filePath);\r\n\r\n    try(var channel = AsynchronousFileChannel.open(file.toPath())){\r\n      ByteBuffer buffer = ByteBuffer.allocateDirect(1024);\r\n      channel.read(buffer, 0, null, new CompletionHandler<Integer, Object>() {\r\n        @SneakyThrows\r\n        @Override\r\n        public void completed(Integer result, Object attachment) {\r\n          buffer.flip();\r\n          var resultString = StandardCharsets.UTF_8.decode(buffer);\r\n          log.info(String.format(\"resultString = %s\", resultString));\r\n          channel.close();\r\n        }\r\n\r\n        @Override\r\n        public void failed(Throwable exc, Object attachment) {\r\n\r\n        }\r\n\r\n      });\r\n\r\n      while (channel.isOpen()){\r\n        log.info(\"Reading ... \");\r\n      }\r\n    }\r\n\r\n    log.info(\"main function end\");\r\n  }\r\n}","출력결과#출력결과":"12:35:36.187 [main] INFO io...Example1_AioFileChannel -- main function started\r\n12:35:36.202 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.202 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.202 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.202 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.202 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.202 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.202 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.202 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.202 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.202 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.202 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.202 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.202 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.202 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.203 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.204 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.205 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.206 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.207 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.208 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.209 [Thread-16] INFO io...Example1_AioFileChannel -- resultString = NVIDIA Corporation provides graphics, and compute and networking solutions in the United States, Taiwan, China, Hong Kong, and internationally. The Graphics segment offers GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure, and solutions for gaming platforms; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU or vGPU software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse software for building and operating metaverse and 3D internet applications. The Compute & Networking segment comprises Data Center computing platforms and end-to-end networking platforms, including Quantum for InfiniBand and Spectrum for Ethernet; NVIDIA DRIVE automated-driving platform and automotive development agreements; Jetson robotics and other embedded platforms; NVIDIA AI Enterprise and other software; and DGX Cloud software and services. The company's products are used in gaming, professional visualization\r\n12:35:36.209 [main] INFO io...Example1_AioFileChannel -- Reading ... \r\n12:35:36.210 [main] INFO io...Example1_AioFileChannel -- main function end\r\n\r\nProcess finished with exit code 0","예제-2-file-aio---future-기반-예제#예제 2. File AIO - Future 기반 예제":"자세한 설명은 추후 시간이 된다면 설명을 추가하도록 하겠습니다. 현재 취직을 준비중이어서 다른 작업을 해야 해서 설명은 생략하겠습니다.예제 코드는 https://github.com/chagchagchag/webflux-mongo-mysql-redis/tree/main/demo-aio/src/main/java/io/chagchagchag/example/foobar/aio 에 있습니다.","코드-1#코드":"package io..;\r\n\r\nimport java.io.File;\r\nimport java.nio.ByteBuffer;\r\nimport java.nio.channels.AsynchronousFileChannel;\r\nimport java.nio.charset.StandardCharsets;\r\nimport java.util.concurrent.Future;\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class Example2_AioFileFuture {\r\n  @SneakyThrows\r\n  public static void main(String [] args){\r\n    log.info(\"main function started\");\r\n\r\n    var filePath = Example1_AioFileChannel.class\r\n        .getClassLoader()\r\n        .getResource(\"example2-data.txt\")\r\n        .getFile();\r\n\r\n    var file = new File(filePath);\r\n\r\n    try(var channel = AsynchronousFileChannel.open(file.toPath())){\r\n      ByteBuffer buffer = ByteBuffer.allocateDirect(1024);\r\n      Future<Integer> readFuture = channel.read(buffer, 0);\r\n\r\n      while (!readFuture.isDone()){\r\n        log.info(\"Reading ... \");\r\n      }\r\n      buffer.flip();\r\n      var resultString = StandardCharsets.UTF_8.decode(buffer);\r\n      log.info(String.format(\"resultString = %s\", resultString));\r\n    }\r\n    log.info(\"main function end\");\r\n  }\r\n}","출력결과-1#출력결과":"12:39:37.637 [main] INFO io...Example2_AioFileFuture -- main function started\r\n12:39:37.651 [main] INFO io...Example2_AioFileFuture -- resultString = \r\n12:39:37.651 [main] INFO io...Example2_AioFileFuture -- main function end\r\n\r\nProcess finished with exit code 0","예제-3-socket-aio----channel-기반#예제 3. Socket AIO -  Channel 기반":"자세한 설명은 추후 시간이 된다면 설명을 추가하도록 하겠습니다. 현재 취직을 준비중이어서 다른 작업을 해야 해서 설명은 생략하겠습니다.예제 코드는 https://github.com/chagchagchag/webflux-mongo-mysql-redis/tree/main/demo-aio/src/main/java/io/chagchagchag/example/foobar/aio 에 있습니다.","server#Server":"package io..;\r\n\r\nimport java.net.InetSocketAddress;\r\nimport java.nio.ByteBuffer;\r\nimport java.nio.channels.AsynchronousServerSocketChannel;\r\nimport java.nio.channels.AsynchronousSocketChannel;\r\nimport java.nio.channels.CompletionHandler;\r\nimport java.nio.charset.StandardCharsets;\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class Example3_AioSocket_Channel_Server {\r\n  @SneakyThrows\r\n  public static void main(String [] args){\r\n    log.info(\"main function started\");\r\n\r\n    try(var serverChannel = AsynchronousServerSocketChannel.open()){\r\n      var address = new InetSocketAddress(\"localhost\", 8080);\r\n      serverChannel.bind(address);\r\n\r\n      serverChannel.accept(null, new CompletionHandler<AsynchronousSocketChannel, Object>() {\r\n        @Override\r\n        public void completed(AsynchronousSocketChannel clientSocketChannel, Object attachment) {\r\n          log.info(\"서버소켓 Accept 시작\");\r\n          var requestBuffer = ByteBuffer.allocateDirect(1024);\r\n\r\n          clientSocketChannel.read(requestBuffer, null, new CompletionHandler<Integer, Object>() {\r\n            @SneakyThrows\r\n            @Override\r\n            public void completed(Integer result, Object attachment) {\r\n              requestBuffer.flip();\r\n              var requestMessage = StandardCharsets.UTF_8.decode(requestBuffer);\r\n              log.info(\"requestMessage = {}\", requestMessage);\r\n\r\n              var response = \"안녕하세요. 저는 서버입니다. 이제 서버 끄겠습니다.\";\r\n              var responseMessageBuffer = ByteBuffer.wrap(response.getBytes());\r\n              clientSocketChannel.write(responseMessageBuffer);\r\n              clientSocketChannel.close();\r\n              log.info(\"end client\");\r\n            }\r\n\r\n            @Override\r\n            public void failed(Throwable exc, Object attachment) {\r\n\r\n            }\r\n          });\r\n        }\r\n\r\n        @Override\r\n        public void failed(Throwable exc, Object attachment) {\r\n\r\n        }\r\n      });\r\n\r\n      Thread.sleep(100000); // 100 초 동안 서버 기동\r\n    }\r\n    log.info(\"main function end\");\r\n  }\r\n}","client#Client":"package io..;\r\n\r\nimport java.io.IOException;\r\nimport java.net.InetSocketAddress;\r\nimport java.nio.ByteBuffer;\r\nimport java.nio.channels.SocketChannel;\r\nimport java.nio.charset.StandardCharsets;\r\nimport java.util.ArrayList;\r\nimport java.util.List;\r\nimport java.util.concurrent.CompletableFuture;\r\nimport java.util.concurrent.Executors;\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class Example3_AioSocket_Channel_Client {\r\n  @SneakyThrows\r\n  public static void main(String [] args){\r\n    List<CompletableFuture> completableFutures = new ArrayList<>();\r\n    log.info(\"main function started\");\r\n\r\n    var executor = Executors.newFixedThreadPool(30);\r\n\r\n    for(var i=0; i<100; i++){\r\n      log.info(\"sending start\");\r\n      var future = CompletableFuture.runAsync(()->{\r\n        SocketChannel socketChannel = null;\r\n        try {\r\n          socketChannel = SocketChannel.open();\r\n          var address = new InetSocketAddress(\"localhost\", 8080);\r\n          var connected = socketChannel.connect(address);\r\n          log.info(\"connected >> {}\", connected);\r\n\r\n          String request = \"저는 클라이언트에요\";\r\n          ByteBuffer requestBuffer = ByteBuffer.wrap(request.getBytes());\r\n          socketChannel.write(requestBuffer);\r\n\r\n          ByteBuffer result = ByteBuffer.allocate(1024);\r\n          if (!socketChannel.isConnected())\r\n            return;\r\n\r\n          while (socketChannel.isConnected() && socketChannel.read(result) > 0) {\r\n            result.flip();\r\n            log.info(\"서버에서 응답이 왔어요. 응답 메시지 >>> {}\", StandardCharsets.UTF_8.decode(result));\r\n            result.clear();\r\n          }\r\n        }\r\n        catch (Exception e){\r\n          e.printStackTrace();\r\n          log.info(\"서버가 중지 되었습니다.\");\r\n        }\r\n        finally {\r\n          try {\r\n            socketChannel.close();\r\n          } catch (IOException e) {\r\n            throw new RuntimeException(e);\r\n          }\r\n        }\r\n        log.info(\"sending end\");\r\n      }, executor);\r\n\r\n      completableFutures.add(future);\r\n    }\r\n\r\n    CompletableFuture.allOf(completableFutures.toArray(new CompletableFuture[0])).join();\r\n    executor.shutdown();\r\n    log.info(\"main function end\");\r\n  }\r\n}","출력결과-2#출력결과":"","server-1#Server":"15:02:49.400 [main] INFO io...Example3_AioSocket_Channel_Server -- main function started\r\n15:03:00.973 [Thread-17] INFO io...Example3_AioSocket_Channel_Server -- 서버소켓 Accept 시작\r\n15:03:00.980 [Thread-16] INFO io...Example3_AioSocket_Channel_Server -- requestMessage = 저는 클라이언트에요\r\n15:03:00.984 [Thread-16] INFO io...Example3_AioSocket_Channel_Server -- end client\r\n15:04:29.438 [main] INFO io...Example3_AioSocket_Channel_Server -- main function end\r\n\r\nProcess finished with exit code 0","client-1#Client":"15:03:00.937 [main] INFO io...Example3_AioSocket_Channel_Client -- main function started\r\n15:03:00.942 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.945 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.945 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.945 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.946 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.946 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.946 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.946 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.946 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.946 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.947 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.947 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.948 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.948 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.949 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.949 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.949 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.949 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.950 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.950 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.950 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.951 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.951 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.951 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.951 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.951 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.952 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.952 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.952 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.953 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.954 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.955 [main] INFO io...Example3_AioSocket_Channel_Client -- sending start\r\n15:03:00.972 [pool-1-thread-1] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.972 [pool-1-thread-8] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.972 [pool-1-thread-16] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.973 [pool-1-thread-28] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.973 [pool-1-thread-13] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.973 [pool-1-thread-23] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.972 [pool-1-thread-6] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.972 [pool-1-thread-2] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.972 [pool-1-thread-3] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.973 [pool-1-thread-22] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.973 [pool-1-thread-21] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.972 [pool-1-thread-11] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.973 [pool-1-thread-7] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.972 [pool-1-thread-17] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.974 [pool-1-thread-30] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.973 [pool-1-thread-27] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.973 [pool-1-thread-24] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.974 [pool-1-thread-26] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.972 [pool-1-thread-5] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.972 [pool-1-thread-18] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.974 [pool-1-thread-25] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.972 [pool-1-thread-14] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.973 [pool-1-thread-10] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.972 [pool-1-thread-4] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.973 [pool-1-thread-19] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.972 [pool-1-thread-9] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.973 [pool-1-thread-20] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.972 [pool-1-thread-12] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.973 [pool-1-thread-29] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.972 [pool-1-thread-15] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n15:03:00.985 [pool-1-thread-15] INFO io...Example3_AioSocket_Channel_Client -- 서버에서 응답이 왔어요. 응답 메시지 >>> 안녕하세요. 저는 서버입니다. 이제 서버 끄겠습니다.\r\n15:03:00.986 [pool-1-thread-15] INFO io...Example3_AioSocket_Channel_Client -- sending end\r\n15:03:00.987 [pool-1-thread-15] INFO io...Example3_AioSocket_Channel_Client -- connected >> true\r\n...","예제-4-socket-aio---future-기반#예제 4. Socket AIO - Future 기반":"자세한 설명은 추후 시간이 된다면 설명을 추가하도록 하겠습니다. 현재 취직을 준비중이어서 다른 작업을 해야 해서 설명은 생략하겠습니다.예제 코드는 https://github.com/chagchagchag/webflux-mongo-mysql-redis/tree/main/demo-aio/src/main/java/io/chagchagchag/example/foobar/aio 에 있습니다.","server-2#Server":"package io..;\r\n\r\nimport java.net.InetSocketAddress;\r\nimport java.nio.ByteBuffer;\r\nimport java.nio.channels.AsynchronousServerSocketChannel;\r\nimport java.nio.channels.AsynchronousSocketChannel;\r\nimport java.nio.charset.StandardCharsets;\r\nimport java.util.concurrent.Future;\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class Example3_AioSocket_Future_Server {\r\n  @SneakyThrows\r\n  public static void main(String [] args){\r\n    log.info(\"main function started\");\r\n\r\n    var serverSocketChannel = AsynchronousServerSocketChannel.open();\r\n    var address = new InetSocketAddress(\"localhost\", 8080);\r\n    serverSocketChannel.bind(address);\r\n\r\n    // client 접속 받는 Future\r\n    Future<AsynchronousSocketChannel> clientSocketFuture = serverSocketChannel.accept();\r\n\r\n    // 조금 더 갖춰진 예제를 만든다면 별도의 스레드에서 실행하도록 작성 필요\r\n    while(!clientSocketFuture.isDone()){\r\n      Thread.sleep(200);\r\n      log.info(\"Client Socket is still live (ON)\");\r\n    }\r\n\r\n    var clientSocket = clientSocketFuture.get();\r\n\r\n    var requestBuffer = ByteBuffer.allocateDirect(1024);\r\n    Future<Integer> readFuture = clientSocket.read(requestBuffer);\r\n    while(!readFuture.isDone()){\r\n      log.info(\"(Still Reading... ) Reading Future is Not Closed ... \");\r\n    }\r\n\r\n    requestBuffer.flip();\r\n    var request = StandardCharsets.UTF_8.decode(requestBuffer);\r\n    log.info(\"클라이언트의 메시지 >>> {}\", request);\r\n\r\n    var response = \"서버입니다. 안녕히 잘 지내시죠? 이제 서버 끕니다.\";\r\n    var responseMessageBuffer = ByteBuffer.wrap(response.getBytes());\r\n    clientSocket.write(responseMessageBuffer);\r\n    clientSocket.close();\r\n\r\n    log.info(\"main function end\");\r\n  }\r\n}","client-2#Client":"package io..;\r\n\r\nimport java.io.IOException;\r\nimport java.net.InetSocketAddress;\r\nimport java.nio.ByteBuffer;\r\nimport java.nio.channels.SocketChannel;\r\nimport java.nio.charset.StandardCharsets;\r\nimport java.util.ArrayList;\r\nimport java.util.List;\r\nimport java.util.concurrent.CompletableFuture;\r\nimport java.util.concurrent.Executors;\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class Example3_AioSocket_Future_Client {\r\n  @SneakyThrows\r\n  public static void main(String [] args){\r\n    List<CompletableFuture> completableFutures = new ArrayList<>();\r\n    log.info(\"main function started\");\r\n\r\n    var executor = Executors.newFixedThreadPool(30);\r\n\r\n    for(var i=0; i<100; i++){\r\n      log.info(\"sending start\");\r\n      var future = CompletableFuture.runAsync(()->{\r\n        SocketChannel socketChannel = null;\r\n        try {\r\n          socketChannel = SocketChannel.open();\r\n          var address = new InetSocketAddress(\"localhost\", 8080);\r\n          var connected = socketChannel.connect(address);\r\n          log.info(\"connected >> {}\", connected);\r\n\r\n          String request = \"저는 클라이언트에요\";\r\n          ByteBuffer requestBuffer = ByteBuffer.wrap(request.getBytes());\r\n          socketChannel.write(requestBuffer);\r\n\r\n          ByteBuffer result = ByteBuffer.allocate(1024);\r\n          if (!socketChannel.isConnected())\r\n            return;\r\n\r\n          while (socketChannel.isConnected() && socketChannel.read(result) > 0) {\r\n            result.flip();\r\n            log.info(\"서버에서 응답이 왔어요. 응답 메시지 >>> {}\", StandardCharsets.UTF_8.decode(result));\r\n            result.clear();\r\n          }\r\n        }\r\n        catch (Exception e){\r\n          e.printStackTrace();\r\n          log.info(\"서버가 중지 되었습니다.\");\r\n        }\r\n        finally {\r\n          try {\r\n            socketChannel.close();\r\n          } catch (IOException e) {\r\n            throw new RuntimeException(e);\r\n          }\r\n        }\r\n        log.info(\"sending end\");\r\n      }, executor);\r\n\r\n      completableFutures.add(future);\r\n    }\r\n\r\n    CompletableFuture.allOf(completableFutures.toArray(new CompletableFuture[0])).join();\r\n    executor.shutdown();\r\n    log.info(\"main function end\");\r\n  }\r\n}","출력결과-3#출력결과":"","server-3#Server":"15:12:59.025 [main] INFO io...Example3_AioSocket_Future_Server -- main function started\r\n15:12:59.260 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:12:59.463 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:12:59.668 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:12:59.869 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:00.072 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:00.274 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:00.480 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:00.682 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:00.887 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:01.089 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:01.289 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:01.491 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:01.694 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:01.894 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:02.097 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:02.299 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:02.501 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:02.702 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:02.904 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:03.111 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:03.313 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:03.529 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:03.733 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:03.935 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:04.141 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:04.348 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:04.561 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:04.762 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:04.965 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:05.167 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:05.370 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:05.572 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:05.787 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:05.992 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:06.194 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:06.398 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:06.612 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:06.817 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:07.022 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:07.228 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:07.431 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:07.633 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:07.836 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:08.036 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:08.238 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:08.441 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:08.642 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:08.846 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:09.048 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:09.252 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:09.456 [main] INFO io...Example3_AioSocket_Future_Server -- Client Socket is still live (ON)\r\n15:13:09.458 [main] INFO io...Example3_AioSocket_Future_Server -- (Still Reading... ) Reading Future is Not Closed ... \r\n15:13:09.459 [main] INFO io...Example3_AioSocket_Future_Server -- 클라이언트의 메시지 >>> 저는 클라이언트에요\r\n15:13:09.463 [main] INFO io...Example3_AioSocket_Future_Server -- main function end","client-3#Client":"15:13:09.284 [main] INFO io...Example3_AioSocket_Future_Client -- main function started\r\n15:13:09.289 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.296 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.296 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.296 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.297 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.297 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.298 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.298 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.298 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.299 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.299 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.300 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.300 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.300 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.300 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.300 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.301 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.301 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.301 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.301 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.302 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.304 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.304 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.305 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.305 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.305 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.306 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.307 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.308 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.308 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.308 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.309 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.310 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.312 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.312 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.312 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.312 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.312 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.312 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.313 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.313 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.313 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.313 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.313 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.313 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.313 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.313 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.313 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.313 [main] INFO io...Example3_AioSocket_Future_Client -- sending start\r\n15:13:09.331 [pool-1-thread-23] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.332 [pool-1-thread-26] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.330 [pool-1-thread-11] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.331 [pool-1-thread-7] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.330 [pool-1-thread-3] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.331 [pool-1-thread-2] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.330 [pool-1-thread-4] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.332 [pool-1-thread-28] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.331 [pool-1-thread-19] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.330 [pool-1-thread-14] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.332 [pool-1-thread-27] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.331 [pool-1-thread-24] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.330 [pool-1-thread-16] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.331 [pool-1-thread-1] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.330 [pool-1-thread-8] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.332 [pool-1-thread-25] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.331 [pool-1-thread-22] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.330 [pool-1-thread-6] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.331 [pool-1-thread-5] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.330 [pool-1-thread-12] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.330 [pool-1-thread-15] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.331 [pool-1-thread-9] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.330 [pool-1-thread-21] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.330 [pool-1-thread-18] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.332 [pool-1-thread-30] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.330 [pool-1-thread-20] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.330 [pool-1-thread-17] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.332 [pool-1-thread-29] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.330 [pool-1-thread-13] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.331 [pool-1-thread-10] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:09.464 [pool-1-thread-21] INFO io...Example3_AioSocket_Future_Client -- 서버에서 응답이 왔어요. 응답 메시지 >>> 서버입니다. 안녕히 잘 지내시죠? 이제 서버 끕니다.\r\n15:13:09.465 [pool-1-thread-21] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:09.467 [pool-1-thread-21] INFO io...Example3_AioSocket_Future_Client -- connected >> true\r\n15:13:10.003 [pool-1-thread-19] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.003 [pool-1-thread-19] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.004 [pool-1-thread-20] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.004 [pool-1-thread-20] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.005 [pool-1-thread-27] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.006 [pool-1-thread-27] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.006 [pool-1-thread-18] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.006 [pool-1-thread-18] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.007 [pool-1-thread-13] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.007 [pool-1-thread-13] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.007 [pool-1-thread-16] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.008 [pool-1-thread-16] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.008 [pool-1-thread-3] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.008 [pool-1-thread-3] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.008 [pool-1-thread-11] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.009 [pool-1-thread-11] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.009 [pool-1-thread-9] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.009 [pool-1-thread-9] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.009 [pool-1-thread-6] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.009 [pool-1-thread-6] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.009 [pool-1-thread-14] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.009 [pool-1-thread-14] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.009 [pool-1-thread-17] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.009 [pool-1-thread-17] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.010 [pool-1-thread-8] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.010 [pool-1-thread-8] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.010 [pool-1-thread-12] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.010 [pool-1-thread-12] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.012 [pool-1-thread-7] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.012 [pool-1-thread-7] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.012 [pool-1-thread-1] INFO io...Example3_AioSocket_Future_Client -- 서버가 중지 되었습니다.\r\n15:13:10.012 [pool-1-thread-1] INFO io...Example3_AioSocket_Future_Client -- sending end\r\n15:13:10.025 [main] INFO io...Example3_AioSocket_Future_Client -- main function end"}},"/reactive-mongodb/example":{"title":"Example","data":{}},"/r2dbc-mysql/intro":{"title":"Intro","data":{}},"/reactive-programming/intro":{"title":"Intro","data":{"intro#intro":""}},"/reactive-programming/java-nio-bad-point-and-solution":{"title":"Java Nio Bad Point and Solution","data":{"java-nio-의-논블로킹-방식-동기연산의-문제점과-해결책-멀티플렉싱#Java NIO 의 논블로킹 방식 동기연산의 문제점과 해결책, 멀티플렉싱":"","busy-waiting#Busy Waiting":"참고 : Busy Waiting이란?\nJava NIO 는 논블로킹 방식이지만 동기연산이 필요합니다. 논블로킹 방식이지만 동기연산을 수행하기 때문에 IO 작업시 특정 루프 내에서 주기적으로 상태를 체크하고 자원관리를 해줘야 한다는 단점이 있습니다. 이렇게 오랜 시간 동안 대기하면서 상태를 체크하는 것을 Busy Waiting 이라고 흔히 이야기 합니다. Busy Waiting 은 원하는 자원을 얻기 위해 권한을 얻을 수 있을때까지 주기적으로 체크를 수행하는 것을 의미합니다. 자원의 권한을 얻는데 드는 시간이 적거나, Context Switching 에 맡기기에는 가변운 작업일 경우에 Busy Waiting 을 하는 것을 선택합니다.이렇게 되면 지속적으로 CPU 를 점유하게 되므로 CPU 자원이 낭비된다는 단점이 있습니다. 그리고 확인하는 주기가 어떻게 되느냐에 따라서 응답 지연 시간 역시 어느 정도 발생하게 됩니다. 또한 코드의 복잡성이 증가합니다.Busy Waiting 을 하는 프로그램의 예를 들면 소켓 프로그램을 구현시 main 스레드에서 accept()가 되었는지 주기적으로 확인하는 구문을 작성하는 경우를 예로 들 수 있습니다. 이렇게 되면 채널 상태의 변화에 따라서 수동으로 상태를 체크하거나 특정 상태에 따라서 후 처리를 하는 등의 관리를 해야 하기 때문에 코드의 복잡성이 계속해서 증가하게 됩니다. 따라서 동시에 발생하는 요청이 증가할 경우 성능이 감소할 위험이 있습니다.","해결책--여러개의-channel-을-selector-로-multiplexing#해결책 : 여러개의 Channel 을 Selector 로 Multiplexing":"일반적으로 멀티플렉싱은 하나의 고 수준의 채널에서 저 수준의 채널들을 분류해주고 관리해주는 것을 의미합니다. NIO 에서 I/O Multiplexing 은 여러개의 Channel 을 하나의 Selector 로 관리하는 것을 의미합니다. 그림에서 보듯 Channel 들은 각각 Selector 에 자기 자신을 등록합니다. 그리고 Selector 는 Thread 를 선택해서 Thread 자원을 관리하고 있습니다. 즉, IO 입력 하나 하나가 Thread 를 가지고 있는 것이 아니라 Selector 에서 Thread 를 관리하면서 Selector 들을 선택하고 체크하는 역할을 수행합니다. 이렇게 하는 것의 장점은 개별 IO 작업이 BUSY WAITING 으로 인한 자원의 과소비를 Selector 하나만으로 이 작업을 수행하게 함으로써 BUSY WAITING 을 줄였다는 점이 장점입니다. Selector 는 여러개 있을 수 있습니다. 개별 Channel 이 가각 Thread 를 잡고 있는다거나 CPU를 과도하게 점유하는 것으로 인한 자원의 과소비나 BUSY WAITING 현상이 줄어들기에 Selector 를 활용한 Channel Multiplexing 개념은 Java NIO 의 논블로킹 방식의 동기 연산의 단점인 Busy Waiting 현상을 대폭 줄여주었습니다.","예제-nio-socket-programming#예제 (NIO Socket Programming)":""}},"/reactive-programming/netflix-rxjava-story":{"title":"Netflix Rxjava Story","data":{"netflix-rxjava-이야기#Netflix RxJava 이야기":"정리 예정\nFunctional Reactive Programming in the Netflix API"}},"/reactive-mongodb/intro":{"title":"Intro","data":{}},"/reactive-programming/publisher-subscriber-subscription-backpressure":{"title":"Publisher Subscriber Subscription Backpressure","data":{"reactive-streams---publisher-subscriber-개념-예제#Reactive Streams - Publisher, Subscriber 개념, 예제":"","참고#참고":"reactive streams github, reactive-streams-jvm\nreactive streams classes\nPublisher , Subscriber, Subscription\nPublisher.java , Subscriber.java , Subscription.java","예제-코드#예제 코드":"github","publisher-subscriber-supscription#Publisher, Subscriber, Supscription":"참고\nPublisher , Subscriber, Subscription\nPublisher.java , Subscriber.java , Subscription.java\nPublisher 는 Subscriber 를 등록할 수 있습니다. Subscriber 는 Publisher 에 자기 자신을 등록하기 위해 Publisher::subscribe(Subscriber) 메서드를 실행해서 자기 자신을 등록합니다.Publisher.java 의 코드는 아래와 같이 되어있습니다.\npackage org.reactivestreams;\r\npublic interface Publisher<T> {\r\n    public void subscribe(Subscriber<? super T> s);\r\n}\nSubscriber 는 Subscriber::onSubscribe(Subscrition) 을 통해서 Publisher 가 수락한 Subscription 객체를 수신합니다. Subscriber.java 의 코드는 아래와 같습니다.\npackage org.reactivestreams;\r\npublic interface Subscriber<T> {\r\n    public void onSubscribe(Subscription s);\r\n    public void onNext(T t);\r\n    public void onError(Throwable t);\r\n    public void onComplete();\r\n}\nSubscriber 객체는 onNext(T) 를 통해서 계속해서 구독하고 있는 이벤트를 수신합니다. 그리고 onError(Throwable) 과 onComplete() 는 최종적으로 단 한번 호출되는데, 예외가 발생했을 경우에는 onError(Throwable) 을 통해 종료가 되고, 정상적으로 종료될 때에는 onComplete() 를 통해서 종료됩니다.\nSubscription 객체는 Subscriber 가 Publisher 에게 자신을 subscribe(Subscriber) 할 때 Publisher 가 생성하는 객체이며, 이 것을 Subscriber의 onSubscribe(Subscription) 의 인자값으로 전달해주는 객체입니다.Subscription.java 의 코드는 아래와 같습니다.\npackage org.reactivestreams;\r\npublic interface Subscription {\r\n    public void request(long n);\r\n    public void cancel();\r\n}\nrequest 함수는 backpressure 를 조절하는 데에 사용됩니다. 그리고 cancel 은 onNext() 작업을 중단(취소)할수 있도록 Subscrition 객체를 이용해서 이벤트의 흐름을 취소할 때 사용되는 메서드입니다.","hot-publisher-cold-publisher#Hot Publisher, Cold Publisher":"Hot Publisher 는 subscriber 가 없는 상태에서도 데이터를 생성해서 stream 에 이벤트를 push 하는 것을 의미합니다. 모든 subscriber 들에게 같은 데이터를 전달합니다. 예를 들면 facebook 의 타임라인이 다른 사람들에게도 전파되는 것과 같은 현상을 예로 들 수 있습니다.Cold Publisher 는 subscribe 를 하는 순간부터 stream 이벤트가 시작되는 것을 의미합니다. subscriber 에 맞춰서 데이터 스트림을 제공하는 것이 가능합니다. 예를 들면 API 요청 처리, 파일 읽기 작업을 예로 들 수 있습니다.","eg-publisher-subscriber-subscription-예제#e.g Publisher, Subscriber, Subscription 예제":"예제 코드는 github 에 남겨두었습니다.\n간단한 메시지를 Publisher 에서 발행하고, Subscription 내에는 executorService 를 통해서 동시성제어를 수행하고 Subscriber 는 Publisher 가 만든 Subscription 객체를 이용해 지속적으로 request() 함수를 호출하는 예제입니다. 자세한 설명은 추후 시간이 된다면 설명을 추가하도록 하겠습니다.","message#Message":"데이터를 담는 용도의 record 객체입니다.\npackage io.chagchagchag.example.foobar.reactive_streams.publisher_subscriber.n_sized_message;\r\n\r\npublic record Message(\r\n    String message,\r\n    Integer requestedCnt\r\n) {\r\n\r\n}","nsizedmessagesubscriptionmessage#NSizedMessageSubscription<Message>":"백프레셔 함수인 request() 함수의 정의와, 동시성 제어시 필요한 스레드 풀의 갯수를 간단하게 정의한 executorService 등을 정의해둔 예제 용도의 단순한 기능을 가진 Subscription 클래스 예제입니다.\npackage io.chagchagchag.example.foobar.reactive_streams.publisher_subscriber.n_sized_message;\r\n\r\nimport java.util.Iterator;\r\nimport java.util.concurrent.ExecutorService;\r\nimport java.util.concurrent.Executors;\r\nimport java.util.concurrent.Flow;\r\nimport java.util.concurrent.Flow.Subscriber;\r\nimport java.util.concurrent.atomic.AtomicBoolean;\r\nimport java.util.concurrent.atomic.AtomicInteger;\r\nimport lombok.RequiredArgsConstructor;\r\n\r\n@RequiredArgsConstructor\r\npublic class NSizedMessageSubscription implements Flow.Subscription{\r\n  private final Subscriber<? super Message> subscriber;\r\n  private final Iterator<String> messages;\r\n  private final ExecutorService executorService = Executors.newSingleThreadExecutor();\r\n\r\n  // 백프레셔 요청 횟수 기록\r\n  private final AtomicInteger requestCnt = new AtomicInteger(1);\r\n  private final AtomicBoolean isCompleted = new AtomicBoolean(false);\r\n\r\n  @Override\r\n  public void request(long requestSize) {\r\n    executorService.submit(()->{\r\n      // requestSize 만큼 데이터를 처리\r\n      for(int i=0; i<requestSize; i++){\r\n        if(messages.hasNext()){\r\n          String message = messages.next();\r\n          subscriber.onNext(new Message(message, requestCnt.get()));\r\n        }\r\n        else{ // 더 이상 보낼 데이터가 없다. 종료 진행\r\n          // 현재 isCompleted 가 false 일때 true 로 바꿔준다.\r\n          var isChanged = isCompleted.compareAndSet(false, true);\r\n\r\n          if(isChanged){\r\n            executorService.shutdown(); // executorService 회수\r\n            subscriber.onComplete();  // subscriber 에 onComplete 이벤트 emit\r\n            isCompleted.set(true);  // isCompleted 를 true 로 세팅\r\n          }\r\n          break;\r\n        }\r\n      }\r\n\r\n      requestCnt.incrementAndGet();\r\n    });\r\n  }\r\n\r\n  @Override\r\n  public void cancel() {\r\n    // cancel 시에는 complete 수행\r\n    subscriber.onComplete();\r\n  }\r\n}","nsizedmessagepublishermessage#NSizedMessagePublisher<Message>":"간단한 7개 정도의 메시지를 새로 등록하는 Subscriber 에게 통지하는 간단한 예제 용도의 Publisher 입니다. Subscriber 가 subscribe(Subscriber) 메서드를 통해 자기 자신을 Publisher 에 등록하려 할 때 Publisher 는 Subscription 내에 메시지 데이터를 iterator 로 바인딩하고, subscriber 객체 역시 등록합니다.그리고 이 작업이 끝나면 Subscriber 의 onSubscribe(Subscription) 메서드를 호출해서 Subscriber 에게도 Subscription 객체를 전달해줍니다.\npackage io.chagchagchag.example.foobar.reactive_streams.publisher_subscriber.n_sized_message;\r\n\r\nimport java.util.ArrayList;\r\nimport java.util.Collections;\r\nimport java.util.Iterator;\r\nimport java.util.List;\r\nimport java.util.concurrent.Flow;\r\nimport java.util.concurrent.Flow.Subscriber;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class NSizedMessagePublisher implements Flow.Publisher<Message>{\r\n\r\n  @Override\r\n  public void subscribe(Subscriber<? super Message> subscriber) {\r\n    var messages = Collections.synchronizedList(\r\n        new ArrayList<>(\r\n            List.of(\r\n                \"1.배고파요\",\r\n                \"2.편의점가요\",\r\n                \"3.먹을게 없네요\",\r\n                \"4.다이어트하자요\",\r\n                \"5.산책해요\",\r\n                \"6.잠자요\",\r\n                \"7.퇴근해요\")\r\n        )\r\n    );\r\n\r\n    Iterator<String> iterator = messages.iterator();\r\n    var subscription = new NSizedMessageSubscription(subscriber, iterator);\r\n    subscriber.onSubscribe(subscription);\r\n  }\r\n}","nsizedmessagesubscriber#NSizedMessageSubscriber":"Subscriber 는 Publisher 가 onSubscribe(Subscription) 을 통해 전달해준 subscription 객체를 자기 자신의 멤버 필드 subscription 에도 바인딩해줍니다. 그리고 이 subscription 객체를 이용해서 backpressure 제어 메서드인 request() 메서드를 호출해서 데이터를 계속해서 소비하며 onComplete() 메시지가 발생할 때 까지 계속해서 소비하게 됩니다.\npackage io.chagchagchag.example.foobar.reactive_streams.publisher_subscriber.n_sized_message;\r\n\r\nimport java.util.concurrent.Flow;\r\nimport java.util.concurrent.Flow.Subscription;\r\nimport lombok.RequiredArgsConstructor;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\n@RequiredArgsConstructor\r\npublic class NSizedMessageSubscriber<T> implements Flow.Subscriber<T>{\r\n  private final Integer requestSize;\r\n  private Flow.Subscription subscription;\r\n  private int firstRequestSize = 1;\r\n  private int nextCnt = 0;\r\n\r\n  @Override\r\n  public void onSubscribe(Subscription subscription) {\r\n    this.subscription = subscription;\r\n    this.subscription.request(firstRequestSize);\r\n  }\r\n\r\n  @Override\r\n  public void onNext(T item) {\r\n    log.info(\"(onNext) item = {}\", item);\r\n    // nextCnt++ 연산을 수행하고, requestSize 만큼 데이터가 한 차례 들어왔음을 판정\r\n    if(nextCnt++ % requestSize == 0){\r\n      // 지정한 requestSize 에 도달해서 onNext 를 수행\r\n      log.info(\">>> onNext : request 를 publisher 의 subscription 에 전송합니다.\");\r\n      this.subscription.request(requestSize);\r\n    }\r\n  }\r\n\r\n  @Override\r\n  public void onError(Throwable throwable) {\r\n    log.error(\"error : {}\", throwable.getMessage());\r\n  }\r\n\r\n  @Override\r\n  public void onComplete() {\r\n    log.info(\"complete\");\r\n  }\r\n}\n출력결과\n12:31:01.664 [pool-1-thread-1] INFO io.chagchagchag.example.foobar.reactive_streams.publisher_subscriber.n_sized_message.NSizedMessageSubscriber -- (onNext) item = Message[message=1.배고파요, requestedCnt=1]\r\n12:31:01.689 [pool-1-thread-1] INFO io.chagchagchag.example.foobar.reactive_streams.publisher_subscriber.n_sized_message.NSizedMessageSubscriber -- >>> onNext : request 를 publisher 의 subscription 에 전송합니다.\r\n12:31:01.690 [pool-1-thread-1] INFO io.chagchagchag.example.foobar.reactive_streams.publisher_subscriber.n_sized_message.NSizedMessageSubscriber -- (onNext) item = Message[message=2.편의점가요, requestedCnt=2]\r\n12:31:01.690 [pool-1-thread-1] INFO io.chagchagchag.example.foobar.reactive_streams.publisher_subscriber.n_sized_message.NSizedMessageSubscriber -- (onNext) item = Message[message=3.먹을게 없네요, requestedCnt=2]\r\n12:31:01.690 [pool-1-thread-1] INFO io.chagchagchag.example.foobar.reactive_streams.publisher_subscriber.n_sized_message.NSizedMessageSubscriber -- (onNext) item = Message[message=4.다이어트하자요, requestedCnt=2]\r\n12:31:01.690 [pool-1-thread-1] INFO io.chagchagchag.example.foobar.reactive_streams.publisher_subscriber.n_sized_message.NSizedMessageSubscriber -- (onNext) item = Message[message=5.산책해요, requestedCnt=2]\r\n12:31:01.690 [pool-1-thread-1] INFO io.chagchagchag.example.foobar.reactive_streams.publisher_subscriber.n_sized_message.NSizedMessageSubscriber -- (onNext) item = Message[message=6.잠자요, requestedCnt=2]\r\n12:31:01.690 [pool-1-thread-1] INFO io.chagchagchag.example.foobar.reactive_streams.publisher_subscriber.n_sized_message.NSizedMessageSubscriber -- >>> onNext : request 를 publisher 의 subscription 에 전송합니다.\r\n12:31:01.690 [pool-1-thread-1] INFO io.chagchagchag.example.foobar.reactive_streams.publisher_subscriber.n_sized_message.NSizedMessageSubscriber -- (onNext) item = Message[message=7.퇴근해요, requestedCnt=3]\r\n12:31:01.690 [pool-1-thread-1] INFO io.chagchagchag.example.foobar.reactive_streams.publisher_subscriber.n_sized_message.NSizedMessageSubscriber -- complete\r\n\r\nProcess finished with exit code 0"}},"/r2dbc-mysql/what-is-r2dbc":{"title":"What Is R2dbc","data":{}},"/reactive-programming/proactor-pattern":{"title":"Proactor Pattern","data":{}},"/reactive-programming/reactor-pattern":{"title":"Reactor Pattern","data":{"reactor-pattern#Reactor Pattern":"Reactor Pattern 을 적용하기 전, 이전에 살펴본 nio 채팅 코드는 아래와 같았습니다.\n// ...\r\n\r\n  if(key.isAcceptable()){ // ACCEPT 이벤트일 경우\r\n    // (1)\r\n    // accept 를 통해 ClientSocket 획득\r\n    var clientSocket = ((ServerSocketChannel) key.channel()).accept();\r\n    // clientSocket 을 non-blocking 으로 설정\r\n    clientSocket.configureBlocking(false);\r\n    // clientSocket 을 selector 에 등록\r\n    clientSocket.register(selector, SelectionKey.OP_READ);\r\n  }\r\n  if(key.isReadable()){ // READ 이벤트 일 때\r\n    // clientSocket 을 얻어옴\r\n    var clientSocket = (SocketChannel) key.channel();\r\n\r\n    var requestBuffer = ByteBuffer.allocate(1024);\r\n    // (2)\r\n    clientSocket.read(requestBuffer); // clientSocket 으로부터 데이터 Read\r\n    requestBuffer.flip();\r\n\r\n    var received = new String(requestBuffer.array()).trim();\r\n    log.info(\"client received = {}\", received);\r\n\r\n    var send = \"답장보냅니다.\";\r\n    var responseBuffer = ByteBuffer.wrap(send.getBytes());\r\n    clientSocket.write(responseBuffer);\r\n    responseBuffer.clear();\r\n    clientSocket.close();\r\n  }\r\n\r\n// ...\n(1), (2) 로 표시한 부분에서는 accept, read 를 함수 호출로 처리하고 있습니다. 이렇게 함수를 그대로 작성해서 하는 것 보다는 조금은 확장성이 가능하도록 하는 코드를 작성해야 할 것 같습니다. 이번 문서에서는 이런 Plain 한 통신 로직을 Reactor Pattern 으로 바꾸면 어떻게 되는지를 확인해봅니다. Reactor 패턴은 이벤트를 감지하고 분류하는 Reactor 와 이벤트를 처리하는 Handler 로 이뤄져 있습니다.","reactor-pattern-이란#Reactor Pattern 이란?":"Reactor 패턴은 동시에 들어오는 요청들을 처리하기 위해 만들어진 이벤트 핸들링 패턴입니다. Reactor 패턴에는 Reactor, Handler 라고 하는 대표적인 두 요소가 있습니다.\nReactor : 별도의 스레드에서 실행합니다. 여러 요청의 WRITE, ACCEPT, READ 이벤트를 한 곳에 등록한 후 관찰합니다. 그리고 준비완료된 이벤트가 있을 경우 해당 이벤트를 request handler 에 전달합니다.\nHandler : Reactor 로부터 이벤트를 받아서 처리합니다. 이 Handler 는 들어오는 요청들을 demultiplexing (다중화 된 것을 풀어서 원하는 주소를 찾는 방식)을 해서 요청에 맞는 Request Handler 에 동기적으로 전달합니다.\n이렇게 이벤트의 처리를 핸들러가 처리하게끔 하는 방식은 Selector 를 이용한 Java NIO 처리와 유사한 모습이 있습니다. 조금 더 자세히 살펴보면 아래와 같은 구조로 처리를 수행합니다.\n위 그림에서 ACCEPT 이벤트를 처리하는 Handler, READ 이벤트를 처리하는 Handler 가 각각 존재합니다. 각각을 설명해보면 아래와 같습니다.Acceptor\nEventHandler 구현체의 일부입니다. Acceptor 는 ACCEPT 이벤트에만 집중합니다.\nAcceptor 외의 Handler  (그림에서는 오른쪽 Handler)\n위 그림에서는 Handler #1, Handler #2, ... Handler #n 이 Handler 입니다.\nREAD 이벤트에 집중해서 처리를 합니다.","reactor-구현#Reactor 구현":"Reactor 는 별도의 스레드에서 동작해야 합니다. 주로 Runnable 기반의 람다를 별도의 ExecutorService 에서 실행하는 경우가 많습니다.그리고 Selector 를 이용해서 요청들을 받으면서 요청이 어떤 이벤트인지 분류하고 이벤트들을 등록하고, 감시합니다. 그리고 이벤트의 준비가 되면 Dispatch 를 합니다. EventHandler 객체를 생성하고 call 을 합니다.","event-handler-구현#Event Handler 구현":"Reactor 로부터 이벤트를 받아서 처리합니다. Read 이벤트, Accept 이벤트에 따라 EventHandler를 각각 따로 EventHandler 를 만듭니다. 그리고 EventHandler 의 처리는 Reactor 에 영향을 주어서는 안되기에 EventHandler 의 처리는 별도의 스레드에서 실행합니다.","예제#예제":""}},"/reactive-programming/webflux-backpressure-handling":{"title":"Webflux Backpressure Handling","data":{"spring-webflux-의-backpressure-핸들링#Spring Webflux 의 Backpressure 핸들링":"우선 결론부터 이야기하면, spring webflux 에서는 Backpressure 를 지원하지만, 효율적으로 제공하지는 않습니다. 따라서 backpressure 처리가 중요한 경우 별도의 backpressure 처리로직을 작성해야 합니다.","참고자료#참고자료":"Backpressure Mechanism in Spring Webflux\nSpring Webflux 의 배압 메커니즘\n오늘 문서는 Backpressure Mechanism in Spring Webflux 을 요약하면서 Spring Webflux 의 배압 메커니즘 의 내용을 참고해서 요약한 내용입니다.","backpressure배압-이란#backpressure(배압) 이란?":"일반적인 backpressure 의 뜻 은 소프트웨어 시스템에서는 트래픽 통신에 부하를 주는 기능을 의미합니다.그런데 이 단어는 정반대의 의미로도 쓰입니다. backpressure 는 트래픽 통신에 부하를 주는 기능을 처리하는 메커니즘이라는 의미로도 사용합니다. 조금 더 자세히 설명하면, \"시스템이 다운 스트림을 제어하고 처리하는 데에 취하는 보호조치\" 를 backpressure 메커니즘으로도 부릅니다.오늘 이 문서에서 정리하는 내용은 \"다운스트림의 부하를 제어하고 처리하는 데에 취하는 보호조치라는 의미에서의 backpressure\" 의 개념입니다.그리고 backpressure 라는 용어와는 혼선을 피하기 위해 backpressure 를 제어한다, backpressure 를 관리한다라는 말을 따로 쓰고, backpressure 단어 자체는 그 자체로 시스템 부하 상황에 대해서만 사용하겠습니다.","eg-backpressure-가-발생하는상황#e.g. backpressure 가 발생하는상황":"Publisher, Consumer, GUI 가 있는 시스템이 있습니다.\nPublisher 는 10000/s 의 이벤트를 Consumer 로 보냅니다.\nConsumer 는 이것을 처리해야 하고 결과를 GUI 에 보냅니다.\nGUI 는 이 결과를 표시합니다.\n소비자는 7500/s 의 이벤트만 처리 가능합니다.\n이미지 출처 : https://www.baeldung.com/spring-webflux-backpressure\n이 속도로는 Consumer 가 backpressure 를 처리할 수 없습니다. 결국 시스템은 붕괴되고 사용자는 결과를 볼 수 없게 됩니다.","일반적인-backpressure-전략#일반적인 backpressure 전략":"일반적인 backpressure 를 처리할 때에는 아래와 같은 방식으로 제어를 하게 됩니다.\n첫번째 옵션 : 전송된 데이터 스트림 제어\n이 방식에서는 Publisher 가 이벤트 속도를 늦춰야 합니다. 이렇게 Publisher 에서 속도를 늦추면 Consumer는 과부하(overload)가 발생하지 않습니다. 이 방식은 모든 경우에 사용할 수 있는 방식이 아니기에 사용가능한 다른 옵션을 찾아야 할 수 있습니다.\n두번째 옵션 : 여분의 데이터를 버퍼링\n이 방식에서는 소비자는 나머지 이벤트를 처리할 수 있을 때 까지 임시로 데이터를 저장합니다. 즉, 버퍼링을 하는 방식입니다. 이 방식의 단점은 메모리의 충돌을 일으키는 버퍼 바인딩을 해제하는 것입니다.\n세번째 옵션 : 추적하지 못하는 추가 이벤트 삭제\n너무 오래된 이벤트일경우 삭제하는 방식. 이상적인 방식은 아닙니다. 이 기술을 사용하면 시스템이 붕괴되지는 않습니다.\n이미지 출처 : https://www.baeldung.com/spring-webflux-backpressure","이벤트-스트림-기반의-배압-제어#이벤트 스트림 기반의 배압 제어":"이 방식은 Publisher 가 보낸 이벤트를 제어하는 데에 중점을 두는 방식입니다.\nrequest : Subscriber 가 요청할 경우에만 새로운 이벤트를 전송\nemitter 요청시 엘리먼트 들을 수집하는 Pull 전략입니다.\nlimit : Client 측에서 수신할 이벤트 수를 제한\n위에서 정리한 제한된 푸시 전략으로 작동하며, Publisher 는 한번에 클라이언트에게 최대 항목 수를 보낼 수 있습니다.\ncancel : Consumer 가 더 아싱 이벤트를 처리할 수 없을 때 데이터 스트리밍을 취소합니다.\nConsumer 는 언제든지 전송을 중단하고 다시 스트림을 구독할 수 있습니다.\n이미지 출처 : https://www.baeldung.com/spring-webflux-backpressure","spring-webflux-의-backpressure-처리#Spring Webflux 의 backpressure 처리":"Spring Webflux 에서는 Project Reactor 가 배압의 처리를 담당하고 있습니다. 내부적으로는 Flux 의 개념을(On Backpressure and Ways to Reshape Requests) 사용해서 emitter 에서 생성된 이벤트를 제어하는 역할을 수행합니다.webflux 는 TCP 흐름제어를 이용해서 Backpressure 를 바이트 단위로 조절합니다. 하지만 소비자가 받을 수 있는 논리적인 요소까지는 처리하지 않습니다.내부 동작은 아래와 같이 동작합니다.\nwebflux 프레임워크는 TCP 를 통해 이벤트 전송/수신을 위해 이벤트를 바이트로 변환하는 역할을 합니다.\n다음 논리적 요소를 요청하기 전에 소비자가 시작하고 장기 실행 작업이 발생할 수 있습니다.\n수신자가 이벤트를 처리하는 동안 WebFlux는 새로운 이벤트에 대한 요구가 없기 때문에 확인 없이 바이트를 큐에 넣습니다.\nTCP 프로토콜의 특성으로 인해 새 이벤트가 있으면 게시자가 계속해서 네트워크로 보냅니다.\n이미지 출처 : https://www.baeldung.com/spring-webflux-backpressure\n그림을 자세히 보면 Consumer 는 일정하게 TCP 계층에 request(1), onNext() 를 하고 있지만, TCP 계층에서 Publisher 에 요청할 때에는 request 시에는 request(10)을 하고 onNext 시에는 onNext(!) 을 합니다.\nwebflux 은 단순히 TCP/IP 를 효율적으로 수행하는 계층이고, 사용자 영역에서의 논리적인 데이터(비즈니스로직)을 효율적으로 처리하기 위한 것은 사용자 레벨에서 직접 작성해야 한다는 사실을 알 수 있습니다.","webflux-에서-사용자-정의-backpressure-처리-로직-구현#webflux 에서 사용자 정의 backpressure 처리 로직 구현":"위의 이벤트 스트림 기반의 배압 제어 에서 정리한 아래의 세가지 요소들을 정의하는 세가지 예제를 살펴봅니다.\nrequest(n)\nlimitRate()\ncancel()","requestn#request(n)":"","limitrate#limitRate()":"","cancel#cancel":""}},"/reactive-programming/reactive-streams-libraries":{"title":"Reactive Streams Libraries","data":{"reactive-streams-라이브러리들#Reactive Streams 라이브러리들":"","reactive-streams-구현체-라이브러리들#Reactive Streams 구현체 라이브러리들":"Reactive Streams 를 구현한 구현체 라이브러리들은 Project Reactor, RxJava, Mutiny 가 있습니다.\nProject Reactor\nRxJava\nMutiny\nProject ReactorPivotal 사에서 개발한 라이브러리입니다. Spring Reactor 내에 포함되어 있습니다. Mono, Flux 라는 이름의 Publisher 클래스가 있습니다.RxJavaNetflix에서 개발한 프레임워크입니다. 닷넷 프레임워크에서 지원되던 Reactive Extensions를 Java 버전으로 포팅한 프레임워크입니다. Flowable, Observable, Single, Maybe, Completable 라는 이름의 퍼블리셔 클래스가 있습니다.MutinyHibernate Reactive 에서 비동기 라이브러리로 제공하는 라이브러리입니다. 대표적인 자료형 및 클래스는 Multi, Uni 라고 하는 퍼블리셔 클래스가 있습니다.","project-reactor#Project Reactor":"Pivotal 사에서 개발한 라이브러리입니다. Spring Reactor 내에 포함되어 있습니다. Mono, Flux 라는 이름의 Publisher 클래스가 있습니다.Project Reactor 의 Official Website 는 projectreactor.io이고Reference Guide 는 projectreactor.io - reference 입니다.","gradle-의존성#gradle 의존성":"// reactor-core\r\nimplementation(\"io.projectreactor:reactor-core:3.6.2\")","mono-와-flux#Mono 와 Flux":"Mono 는 Optional<T> 를 상속받은(extends) 자료형입니다. (Mono<T> : Optional<T>)값이 없는 경우 또는 하나의 값을 명시적으로 의미하고자 할 때 Mono 를 사용합니다.  흔히 Mono<Void> 를 사용하는 경우는 특정 작업이 완료되는 파이프라인이라는 것을 명시적으로 표현하고자 할 때 사용합니다.\nFlux 는 List<T> 를 상속받은(extends) 자료형입니다. (Flux<T>: List<T>)무한한 값을 가리키거나 사이즈가 정해져있는 유한한 여러개의 요소들을 가리킬 때 Flux 를 사용합니다.","flux#Flux":"참고 : prjectreactor.io - reference#fluxFlux 는 0 ~ n 개의 요소들을 전달합니다. 에러가 발생할경우에는 Error 시그널을 전달한 후에 종료를 합니다. 만약 모든 요소를 전달했을 경우에는 Complete 시그널이 전달되면서 종료됩니다. Flux 는 Backpressure 를 지원합니다.Flux 를 Mono 로 바꿔야할 때가 있습니다. 아래의 두가지 방식으로 변환이 가능합니다.Mono.from(Flux) 를 사용할 경우\nFlux 의 첫번째 요소만 Mono 에 전달됩니다.\nFlux.collectList() 를 사용\nFlux.collectList() 를 사용해서 List 로 변환해서 이것을 Mono<List<T>> 자료형으로 변환한다면 Mono 타입의 List 로 변환이 가능합니다.","예제-1-request-size-가-큰-subscriber#예제 1) request size 가 큰 Subscriber":"한번 subscribe 요청 시에 한번에 request(Integer.MAX_VALUE) 를 하는 커스텀 Subscriber 를 만들고 이라는 숫자열을 담고 있는 Flux 가 이 Subscriber 를 subscribe 하는 예제를 만들어봅니다.이 예제는 결국 적은 사이즈의 Flux 에 대해 subscribe 할 때 한번에 Integer.MAX_VALUE 만큼을request() 해서 onComlete() 가 발생하게끔 하는 결과를 만들어냅니다.\nBigRequestSizeSubscriber간단한 Subscriber 입니다. 1초에 한개의 요소를 구독(request()) 합니다.\npackage io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.bigsize_request;\r\n\r\nimport lombok.RequiredArgsConstructor;\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport org.reactivestreams.Subscriber;\r\nimport org.reactivestreams.Subscription;\r\n\r\n@Slf4j\r\n@RequiredArgsConstructor\r\npublic class BigRequestSizeSubscriber<T> implements Subscriber<T> {\r\n  private final Integer requestSize;\r\n\r\n  @Override\r\n  public void onSubscribe(Subscription s) {\r\n    log.info(\"(subscribe) --- \");\r\n    s.request(requestSize);\r\n    log.info(\" >>> subscriber.request({})\", requestSize);\r\n  }\r\n\r\n  @SneakyThrows\r\n  @Override\r\n  public void onNext(T t) {\r\n    log.info(\"(next) item : {}\", t);\r\n    Thread.sleep(1000);\r\n  }\r\n\r\n  @Override\r\n  public void onError(Throwable t) {\r\n    log.error(\"error : {}\", t.getMessage());\r\n  }\r\n\r\n  @Override\r\n  public void onComplete() {\r\n    log.info(\"=== (complete) ===\");\r\n  }\r\n}\nFiniteFluxClient\npackage io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.bigsize_request;\r\n\r\nimport java.util.List;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport reactor.core.publisher.Flux;\r\n\r\n@Slf4j\r\npublic class BigRequestSizeSubscribing_FluxClient {\r\n  public static void main(String[] args) {\r\n    log.info(\"main function started --- \");\r\n    getItems().subscribe(new BigRequestSizeSubscriber<>(Integer.MAX_VALUE));\r\n    log.info(\"main function end --- \");\r\n  }\r\n\r\n  private static Flux<Integer> getItems(){\r\n    return Flux.fromIterable(List.of(100,200,300,400,500));\r\n  }\r\n}\r\n출력결과\n08:24:50.463 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.bigsize_request.BigRequestSizeSubscribing_FluxClient -- main function started --- \r\n08:24:50.749 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.bigsize_request.BigRequestSizeSubscriber -- (subscribe) --- \r\n08:24:50.749 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.bigsize_request.BigRequestSizeSubscriber --  >>> subscriber.request(2147483647)\r\n08:24:50.754 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.bigsize_request.BigRequestSizeSubscriber -- (next) item : 100\r\n08:24:51.762 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.bigsize_request.BigRequestSizeSubscriber -- (next) item : 200\r\n08:24:52.774 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.bigsize_request.BigRequestSizeSubscriber -- (next) item : 300\r\n08:24:53.783 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.bigsize_request.BigRequestSizeSubscriber -- (next) item : 400\r\n08:24:54.793 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.bigsize_request.BigRequestSizeSubscriber -- (next) item : 500\r\n08:24:55.808 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.bigsize_request.BigRequestSizeSubscriber -- === (complete) ===\r\n08:24:55.808 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.bigsize_request.BigRequestSizeSubscribing_FluxClient -- main function end --- \r\n\r\nProcess finished with exit code 0","예제-2-request-size-를-적절하게-지정한-backpressure--subscriber-예제#예제 2) request size 를 적절하게 지정한 Backpressure  Subscriber 예제":"한번 subscribe 시에 처음에는 request(1) 을 하고 그 다음부터는 onNext() 에서 1초에 1개씩 request(1) 하는 커스텀 Subscriber 를 만들고 이라는 숫자열을 담고 있는 Flux 가 이 Subscriber 를 subscribe 하는 예제를 만들어봅니다.이 예제는 결국 처음 subscribe 시에는 request(1) 을 해서 그 이후부터는 onNext 에서 200,300,400,500 를 차례로 request 하면서 마지막에 도달 시 onComlete() 가 발생하게끔 하는 결과를 만들어냅니다.\nSmallSizeBackpressureSubscriber.java\npackage io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.smallsize_request_backpressure;\r\n\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport org.reactivestreams.Subscriber;\r\nimport org.reactivestreams.Subscription;\r\n\r\n@Slf4j\r\npublic class SmallSizeBackpressureSubscriber<T> implements Subscriber<T> {\r\n  private final Integer requestSize = 1;\r\n  private Subscription subscription;\r\n\r\n  @Override\r\n  public void onSubscribe(Subscription s) {\r\n    this.subscription = s;\r\n    log.info(\"(subscribe) --- \");\r\n    s.request(requestSize);\r\n    log.info(\" >>> subscriber.request({})\", requestSize);\r\n  }\r\n\r\n  @SneakyThrows\r\n  @Override\r\n  public void onNext(T t) {\r\n    log.info(\"(next) item : {}\", t);\r\n    Thread.sleep(1000);\r\n    // BigRequestSizeSubscriber 예제에서는 onNext() 내부에서 아래와 같이 request 를 하지 않았다는 점과 비교해보셔야 합니다.\r\n    subscription.request(requestSize);\r\n    log.info(\"requestSize : {}\", requestSize);\r\n  }\r\n\r\n  @Override\r\n  public void onError(Throwable t) {\r\n    log.error(\"error : {}\", t.getMessage());\r\n  }\r\n\r\n  @Override\r\n  public void onComplete() {\r\n    log.info(\"=== (complete) ===\");\r\n  }\r\n}\nSmallSizeBackpressureSubscribing_FluxClient.java\npackage io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.smallsize_request_backpressure;\r\n\r\nimport java.util.List;\r\nimport reactor.core.publisher.Flux;\r\n\r\npublic class SmallSizeBackpressureSubscribing_FluxClient {\r\n\r\n  public static void main(String[] args) {\r\n    getItems().subscribe(\r\n        new SmallSizeBackpressureSubscriber<>()\r\n    );\r\n  }\r\n\r\n  public static Flux<Integer> getItems(){\r\n    return Flux.fromIterable(List.of(1,2,3,4,5));\r\n  }\r\n}\n출력결과\n08:56:18.125 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.smallsize_request_backpressure.SmallSizeBackpressureSubscriber -- (subscribe) --- \r\n08:56:18.132 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.smallsize_request_backpressure.SmallSizeBackpressureSubscriber --  >>> subscriber.request(1)\r\n08:56:18.138 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.smallsize_request_backpressure.SmallSizeBackpressureSubscriber -- (next) item : 1\r\n08:56:19.150 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.smallsize_request_backpressure.SmallSizeBackpressureSubscriber -- requestSize : 1\r\n08:56:19.150 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.smallsize_request_backpressure.SmallSizeBackpressureSubscriber -- (next) item : 2\r\n08:56:20.167 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.smallsize_request_backpressure.SmallSizeBackpressureSubscriber -- requestSize : 1\r\n08:56:20.168 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.smallsize_request_backpressure.SmallSizeBackpressureSubscriber -- (next) item : 3\r\n08:56:21.174 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.smallsize_request_backpressure.SmallSizeBackpressureSubscriber -- requestSize : 1\r\n08:56:21.174 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.smallsize_request_backpressure.SmallSizeBackpressureSubscriber -- (next) item : 4\r\n08:56:22.175 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.smallsize_request_backpressure.SmallSizeBackpressureSubscriber -- requestSize : 1\r\n08:56:22.175 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.smallsize_request_backpressure.SmallSizeBackpressureSubscriber -- (next) item : 5\r\n08:56:23.185 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.smallsize_request_backpressure.SmallSizeBackpressureSubscriber -- requestSize : 1\r\n08:56:23.188 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.smallsize_request_backpressure.SmallSizeBackpressureSubscriber -- === (complete) ===\r\n\r\nProcess finished with exit code 0","예제-3-error-발생하면-곧바로-중지#예제 3) error 발생하면 곧바로 중지":"onComplete() 호출이 되지 않고 바로 중지되는 것을 확인 가능합니다.FluxErrorClient1.java\npackage io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.error;\r\n\r\nimport io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport reactor.core.publisher.Flux;\r\n\r\n@Slf4j\r\npublic class FluxErrorClient1 {\r\n  public static void main(String[] args) {\r\n    log.info(\"main function started\");\r\n    getItems()\r\n        .subscribe(\r\n            new SimpleSubscriber<>(Integer.MAX_VALUE)\r\n        );\r\n    log.info(\"main function end\");\r\n  }\r\n\r\n  public static Flux<Integer> getItems(){\r\n    return Flux.create(fluxSink -> {\r\n      fluxSink.next(0);\r\n      fluxSink.next(1);\r\n      var error = new IllegalStateException(\"Error 발생\");\r\n      fluxSink.error(error);\r\n    });\r\n  }\r\n}\n출력결과\n09:33:15.405 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.error.FluxErrorClient1 -- main function started\r\n09:33:15.519 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- (subscribe) --- \r\n09:33:15.519 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber --  >>> subscriber.request(2147483647)\r\n09:33:15.523 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- (next) item : 0\r\n09:33:16.529 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- (next) item : 1\r\n09:33:17.547 [main] ERROR io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- error : Error 발생\r\n09:33:17.547 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.error.FluxErrorClient1 -- main function end\nSimpleSubscriber.java\npackage io.chagchagchag.example.foobar.reactive_streams_libraries.reactor;\r\n\r\nimport lombok.RequiredArgsConstructor;\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport org.reactivestreams.Subscriber;\r\nimport org.reactivestreams.Subscription;\r\n\r\n@Slf4j\r\n@RequiredArgsConstructor\r\npublic class SimpleSubscriber<T> implements Subscriber<T> {\r\n  private final Integer requestSize;\r\n  @Override\r\n  public void onSubscribe(Subscription s) {\r\n    log.info(\"(subscribe) --- \");\r\n    s.request(requestSize);\r\n    log.info(\" >>> subscriber.request({})\", requestSize);\r\n  }\r\n\r\n  @SneakyThrows\r\n  @Override\r\n  public void onNext(T t) {\r\n    log.info(\"(next) item : {}\", t);\r\n    Thread.sleep(1000);\r\n  }\r\n\r\n  @Override\r\n  public void onError(Throwable t) {\r\n    log.error(\"error : {}\", t.getMessage());\r\n  }\r\n\r\n  @Override\r\n  public void onComplete() {\r\n    log.info(\"=== (complete) ===\");\r\n  }\r\n}","예제-4-complete---complete-시그널-발생시-종료#예제 4) complete - complete 시그널 발생시 종료":"package io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.complete;\r\n\r\nimport io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport reactor.core.publisher.Flux;\r\n\r\n@Slf4j\r\npublic class FluxCompleteClient {\r\n  public static void main(String[] args) {\r\n    log.info(\"main function started\");\r\n    getItems()\r\n        .subscribe(\r\n            new SimpleSubscriber<>(Integer.MAX_VALUE)\r\n        );\r\n    log.info(\"main function end\");\r\n  }\r\n\r\n  public static Flux<Integer> getItems(){\r\n    return Flux.create(fluxSink -> {\r\n      fluxSink.complete();\r\n    });\r\n  }\r\n}\n출력결과\n09:39:21.752 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.complete.FluxCompleteClient -- main function started\r\n09:39:21.845 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- (subscribe) --- \r\n09:39:21.846 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber --  >>> subscriber.request(2147483647)\r\n09:39:21.851 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- === (complete) ===\r\n09:39:21.851 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.complete.FluxCompleteClient -- main function end\nSimpleSubscriber.java\npackage io.chagchagchag.example.foobar.reactive_streams_libraries.reactor;\r\n\r\nimport lombok.RequiredArgsConstructor;\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport org.reactivestreams.Subscriber;\r\nimport org.reactivestreams.Subscription;\r\n\r\n@Slf4j\r\n@RequiredArgsConstructor\r\npublic class SimpleSubscriber<T> implements Subscriber<T> {\r\n  private final Integer requestSize;\r\n  @Override\r\n  public void onSubscribe(Subscription s) {\r\n    log.info(\"(subscribe) --- \");\r\n    s.request(requestSize);\r\n    log.info(\" >>> subscriber.request({})\", requestSize);\r\n  }\r\n\r\n  @SneakyThrows\r\n  @Override\r\n  public void onNext(T t) {\r\n    log.info(\"(next) item : {}\", t);\r\n    Thread.sleep(1000);\r\n  }\r\n\r\n  @Override\r\n  public void onError(Throwable t) {\r\n    log.error(\"error : {}\", t.getMessage());\r\n  }\r\n\r\n  @Override\r\n  public void onComplete() {\r\n    log.info(\"=== (complete) ===\");\r\n  }\r\n}","예제-5-flux--mono--monofromflux#예제 5) Flux → Mono  (Mono.from(Flux))":"Mono.from(Flux) 를 사용할 경우\nFlux 의 첫번째 요소만 Mono 에 전달됩니다.\n예제\npackage io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.flux_to_mono;\r\n\r\nimport io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber;\r\nimport java.util.List;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport reactor.core.publisher.Flux;\r\nimport reactor.core.publisher.Mono;\r\n\r\n@Slf4j\r\npublic class FluxToMonoClient_MonoFrom {\r\n  public static void main(String[] args) {\r\n    log.info(\"main function started\");\r\n    Mono\r\n        .from(getItems())\r\n        .subscribe(\r\n            new SimpleSubscriber<>(Integer.MAX_VALUE)\r\n        );\r\n    log.info(\"main function end\");\r\n  }\r\n\r\n  public static Flux<Integer> getItems(){\r\n    return Flux.fromIterable(List.of(1,2,3,4,5));\r\n  }\r\n}","예제-6-flux--mono-monofromfluxcollectlist#예제 6) Flux → Mono (Mono.from(Flux.collectList()))":"Flux.collectList() 를 사용\nFlux.collectList() 를 사용해서 List 로 변환해서 이것을 Mono<List<T>> 자료형으로 변환한다면 Mono 타입의 List 로 변환이 가능합니다.\npackage io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.flux_to_mono;\r\n\r\nimport io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber;\r\nimport java.util.List;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport reactor.core.publisher.Flux;\r\nimport reactor.core.publisher.Mono;\r\n\r\n@Slf4j\r\npublic class FluxToMonoClient_Flux_collectList {\r\n  public static void main(String[] args) {\r\n    log.info(\"main function started\");\r\n    Mono\r\n        .from(getItems().collectList())\r\n        .subscribe(new SimpleSubscriber<>(Integer.MAX_VALUE));\r\n    log.info(\"main function end\");\r\n  }\r\n\r\n  public static Flux<Integer> getItems(){\r\n    return Flux.fromIterable(List.of(1,2,3,4,5));\r\n  }\r\n}","mono#Mono":"참고 : prjectreactor.io - reference#monoMono 는 0개 또는 1개의 요소를 전달합니다. 에러가 발생할 경우 Error 시그널을 전달한 후에 종료를 합니다. 만약 모든 요소를 전달했을 경우에는 Complete 시그널이 전달되면서 종료됩니다.Mono 를 Flux 로 바꿔야 할 때가 있습니다. 이 경우 아래의 두 가지 방식으로 변환 가능합니다.Mono::flux() 함수를 사용할 경우\nMono<List<T>> 타입일 경우 이것을 flux() 함수를 이용해서 Flux<List<T>> 로 변환 가능합니다.\ne.g. getListItems().flux().subscribe(...)\nMono::flatMapMany() 함수를 사용할 경우\nMono<List<T>> 타입일 경우 이것을 flatMapMany() 를 사용해서 Flux<T> 로 풀어서 사용가능합니다.\ne.g. getListItems().flatMapMany(v -> Flux.fromIterable(v)).subscribe(...)","예제-1-subscriber#예제 1) Subscriber":"Mono 는 1개의 item만 전달하므로 next() 가 한번만 실행되면 바로 complete 가 호출되는 것이 보장됩니다.  그리고 값을 전달하지 않고도 complete 를 할 경우 값이 없다는 것을 의미합니다.\npackage io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.mono;\r\n\r\nimport io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber;\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport reactor.core.publisher.Mono;\r\n\r\n@Slf4j\r\npublic class SimpleMonoClient {\r\n  @SneakyThrows\r\n  public static void main(String[] args) {\r\n    log.info(\"main function started\");\r\n    getITems().subscribe(\r\n        new SimpleSubscriber<>(Integer.MAX_VALUE)\r\n    );\r\n    log.info(\"main function end\");\r\n  }\r\n\r\n  public static Mono<Integer> getITems(){\r\n    return Mono.create(monoSink -> {\r\n      monoSink.success(1);\r\n    });\r\n  }\r\n}\nSimpleSubscriber.java\npackage io.chagchagchag.example.foobar.reactive_streams_libraries.reactor;\r\n\r\nimport lombok.RequiredArgsConstructor;\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport org.reactivestreams.Subscriber;\r\nimport org.reactivestreams.Subscription;\r\n\r\n@Slf4j\r\n@RequiredArgsConstructor\r\npublic class SimpleSubscriber<T> implements Subscriber<T> {\r\n  private final Integer requestSize;\r\n  @Override\r\n  public void onSubscribe(Subscription s) {\r\n    log.info(\"(subscribe) --- \");\r\n    s.request(requestSize);\r\n    log.info(\" >>> subscriber.request({})\", requestSize);\r\n  }\r\n\r\n  @SneakyThrows\r\n  @Override\r\n  public void onNext(T t) {\r\n    log.info(\"(next) item : {}\", t);\r\n    Thread.sleep(1000);\r\n  }\r\n\r\n  @Override\r\n  public void onError(Throwable t) {\r\n    log.error(\"error : {}\", t.getMessage());\r\n  }\r\n\r\n  @Override\r\n  public void onComplete() {\r\n    log.info(\"=== (complete) ===\");\r\n  }\r\n}\n출력결과\n10:40:03.253 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.mono.SimpleMonoClient -- main function started\r\n10:40:03.355 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- (subscribe) --- \r\n10:40:03.356 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber --  >>> subscriber.request(2147483647)\r\n10:40:03.360 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- (next) item : 1\r\n10:40:04.386 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- === (complete) ===\r\n10:40:04.387 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.mono.SimpleMonoClient -- main function end\r\n\r\nProcess finished with exit code 0","예제-2-mono--flux-flux#예제 2) Mono → Flux (flux())":"package io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.mono_to_flux;\r\n\r\nimport io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber;\r\nimport java.util.List;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport reactor.core.publisher.Flux;\r\nimport reactor.core.publisher.Mono;\r\n\r\n@Slf4j\r\npublic class MonoToFluxClient_flux {\r\n  public static void main(String[] args) {\r\n    log.info(\"main function started\");\r\n\r\n    getItems()\r\n        .flux()\r\n        .subscribe(new SimpleSubscriber<>(Integer.MAX_VALUE));\r\n\r\n    log.info(\"main function end\");\r\n  }\r\n\r\n  public static Mono<List<Integer>> getItems(){\r\n    return Mono.just(List.of(1,2,3,4,5));\r\n  }\r\n}\n출력결과\n10:36:36.575 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.mono_to_flux.MonoToFluxClient_flux -- main function started\r\n10:36:36.685 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- (subscribe) --- \r\n10:36:36.685 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber --  >>> subscriber.request(2147483647)\r\n10:36:36.687 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- (next) item : [1, 2, 3, 4, 5]\r\n10:36:37.691 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- === (complete) ===\r\n10:36:37.691 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.mono_to_flux.MonoToFluxClient_flux -- main function end\r\n\r\nProcess finished with exit code 0","예제-3-mono--flux-flatmapmany#예제 3) Mono → Flux (flatMapMany())":"package io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.mono_to_flux;\r\n\r\nimport io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber;\r\nimport java.util.List;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport reactor.core.publisher.Flux;\r\nimport reactor.core.publisher.Mono;\r\n\r\n@Slf4j\r\npublic class MonoToFluxClient_flatMapMany {\r\n  public static void main(String[] args) {\r\n    log.info(\"main function started\");\r\n\r\n    getItems()\r\n        .flatMapMany(\r\n            list -> Flux.fromIterable(list)\r\n        )\r\n        .subscribe(\r\n            new SimpleSubscriber<>(Integer.MAX_VALUE)\r\n        );\r\n\r\n    log.info(\"main function end\");\r\n  }\r\n\r\n  public static Mono<List<Integer>> getItems(){\r\n    return Mono.just(List.of(1,2,3,4,5));\r\n  }\r\n}\n출력결과\n10:37:03.180 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.mono_to_flux.MonoToFluxClient_flatMapMany -- main function started\r\n10:37:03.297 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- (subscribe) --- \r\n10:37:03.298 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber --  >>> subscriber.request(2147483647)\r\n10:37:03.299 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- (next) item : 1\r\n10:37:04.302 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- (next) item : 2\r\n10:37:05.316 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- (next) item : 3\r\n10:37:06.320 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- (next) item : 4\r\n10:37:07.320 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- (next) item : 5\r\n10:37:08.335 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.SimpleSubscriber -- === (complete) ===\r\n10:37:08.335 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.reactor.mono_to_flux.MonoToFluxClient_flatMapMany -- main function end\r\n\r\nProcess finished with exit code 0","rxjava#RxJava":"Netflix에서 개발한 프레임워크입니다. 닷넷 프레임워크에서 지원되던 Reactive Extensions를 Java 버전으로 포팅한 프레임워크입니다. Flowable, Observable, Single, Maybe, Completable 라는 이름의 퍼블리셔 클래스가 있습니다.","flowable#Flowable":"","observable#Observable":"","single#Single":"","maybe#Maybe":"","completable#Completable":"","mutiny#Mutiny":"Mutiny 공식 도큐먼트 : https://smallrye.io/smallrye-mutiny/latest/\nHibernate Reactive 에서 비동기 라이브러리로 제공하는 라이브러리입니다. 대표적인 자료형 및 클래스는 Multi, Uni 라고 하는 퍼블리셔 클래스가 있습니다.","multi-와-uni#Multi 와 Uni":"Multi 는 Reactor 의 Flux 와 유사한 특징을 가지는  Publisher 클래스입니다. Multi 에는 0 ~ n 개의 item 을 전달 가능하고 에러가 발생할 경우 Error 시그널을 전달하면서 종료를 합니다. 만약 모든 item 을 전달했을 경우에는 Complete 시그널을 전달하면서 종료합니다. Multi 역시 Backpressure 를 지원합니다.Uni 는 Reactor 의 Mono 와 유사한 특징을 가지는 Publisher 클래스입니다. Uni 에는 0 ~ 1 개의 item 을 전달 가능하고 에러가 발생할 경우 Error 시그널을 전달하면서 종료를 합니다. 만약 모든 item 을 전달했을 경우에는 Complete 시그널을 전달하면서 종료합니다.","gradle-의존성-1#gradle 의존성":"// mutiny\r\nimplementation(\"io.smallrye.reactive:mutiny:2.5.7\")","multi#Multi":"MultiClient.java\npackage io.chagchagchag.example.foobar.reactive_streams_libraries.mutiny.multi;\r\n\r\nimport io.smallrye.mutiny.Multi;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class MultiClient {\r\n  public static void main(String[] args) {\r\n    getItems()\r\n        .subscribe()\r\n        .withSubscriber(new SimpleMultiSubscriber<>(1024));\r\n  }\r\n\r\n  public static Multi<Integer> getItems(){\r\n    return Multi.createFrom().items(1,2,3,4,5);\r\n  }\r\n}\nSimpleMultiSubscriber.java\npackage io.chagchagchag.example.foobar.reactive_streams_libraries.mutiny.multi;\r\n\r\nimport io.smallrye.mutiny.subscription.MultiSubscriber;\r\nimport java.util.concurrent.Flow.Subscription;\r\nimport lombok.RequiredArgsConstructor;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\n@RequiredArgsConstructor\r\npublic class SimpleMultiSubscriber <T> implements MultiSubscriber<T> {\r\n  private final Integer requestSize;\r\n  @Override\r\n  public void onItem(T t) {\r\n    log.info(\"item == {}\", t);\r\n  }\r\n\r\n  @Override\r\n  public void onFailure(Throwable throwable) {\r\n    log.error(\"fail, mesage = {}\", throwable.getMessage());\r\n  }\r\n\r\n  @Override\r\n  public void onCompletion() {\r\n    log.info(\"complete\");\r\n  }\r\n\r\n  @Override\r\n  public void onSubscribe(Subscription subscription) {\r\n    subscription.request(requestSize);\r\n    log.info(\"subscribe\");\r\n  }\r\n}\n출력결과\n10:54:17.883 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.mutiny.multi.SimpleMultiSubscriber -- item == 1\r\n10:54:17.898 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.mutiny.multi.SimpleMultiSubscriber -- item == 2\r\n10:54:17.898 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.mutiny.multi.SimpleMultiSubscriber -- item == 3\r\n10:54:17.898 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.mutiny.multi.SimpleMultiSubscriber -- item == 4\r\n10:54:17.898 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.mutiny.multi.SimpleMultiSubscriber -- item == 5\r\n10:54:17.898 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.mutiny.multi.SimpleMultiSubscriber -- complete\r\n10:54:17.898 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.mutiny.multi.SimpleMultiSubscriber -- subscribe\r\n\r\nProcess finished with exit code 0","uni#Uni":"UniClient.java\npackage io.chagchagchag.example.foobar.reactive_streams_libraries.mutiny.uni;\r\n\r\nimport io.smallrye.mutiny.Uni;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\npublic class UniClient {\r\n  public static void main(String[] args) {\r\n    getItems()\r\n        .subscribe()\r\n        .withSubscriber(\r\n            new SimpleUniSubscriber<>(1024)\r\n        );\r\n  }\r\n\r\n  public static Uni<Integer> getItems(){\r\n    return Uni.createFrom().item(-1);\r\n  }\r\n}\r\nSimpleUniSubscriber.java\npackage io.chagchagchag.example.foobar.reactive_streams_libraries.mutiny.uni;\r\n\r\nimport io.smallrye.mutiny.subscription.UniSubscriber;\r\nimport io.smallrye.mutiny.subscription.UniSubscription;\r\nimport lombok.RequiredArgsConstructor;\r\nimport lombok.extern.slf4j.Slf4j;\r\n\r\n@Slf4j\r\n@RequiredArgsConstructor\r\npublic class SimpleUniSubscriber<T> implements UniSubscriber<T> {\r\n  private final Integer count;\r\n  private UniSubscription subscription;\r\n  @Override\r\n  public void onSubscribe(UniSubscription uniSubscription) {\r\n    this.subscription = uniSubscription;\r\n    subscription.request(1);\r\n    log.info(\"subscribe\");\r\n  }\r\n\r\n  @Override\r\n  public void onItem(T t) {\r\n    log.info(\"item : {}\", t);\r\n  }\r\n\r\n  @Override\r\n  public void onFailure(Throwable throwable) {\r\n    log.error(\"error, message = {}\", throwable.getMessage());\r\n  }\r\n}\n출력결과\n11:01:35.633 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.mutiny.uni.SimpleUniSubscriber -- subscribe\r\n11:01:35.639 [main] INFO io.chagchagchag.example.foobar.reactive_streams_libraries.mutiny.uni.SimpleUniSubscriber -- item : -1\r\n\r\nProcess finished with exit code 0"}},"/reactive-programming/what-is-epoll":{"title":"What Is Epoll","data":{"epoll-이란#epoll 이란?":"","참고자료#참고자료":"C10K Problem\n고전 돌아보기, C10K 문제 (C10K Problem)\nabout C10K problem\n쉽게 정리한 네트워크 | Apache와 Nginx의 요청 응답 구조\n쉽게 정리한 네트워크 | Apache와 Nginx의 요청 응답 구조\nHow Many Threads Is Too Many?","c10k-problem-client-10k#C10K Problem (Client 10K)":"epoll 을 알아보기 전에 C10K Problem이 어떤 이야기인지 알아야 합니다.\r\n1만개의 클라이언트가 요청을 하는 상황에 대한 문제를 의미하는 C10K Problem은 굉장히 잘 알려진 고전적인 주제입니다. C10K Problem 은 1999년 Dan Kegel 이라는 개발자가 제기한 문제입니다.이것과 관련해서 읽어볼만한 자료들은 아래와 같습니다.\nC10K Problem\n고전 돌아보기, C10K 문제 (C10K Problem)\nabout C10K problem\n쉽게 정리한 네트워크 | Apache와 Nginx의 요청 응답 구조\n1초에 10000개의 클라이언트의 요청이 오는 것을 처리하려 할 때 흔히 처음에는 아래와 같은 생각을 할수도 있습니다.\nthread 를 이용해서 스레드를 request 마다 1개씩 할당한다.\n흔히 이 문제를 설명할 때 Apache 와 Nginx 의 차이점을 들어서 설명합니다.\n참고 : 쉽게 정리한 네트워크 | Apache와 Nginx의 요청 응답 구조\nApache 는 멀티 프로세스 + 멀티 스레드 방식을 사용합니다. 사용자의 요청에 대해 Process/Thread 를 생성하는 방식으로 대응합니다. 항상 여유로운 프로세스/스레드를 생성합니다. 미리 설정해둔 유휴(Idle) 프로세스의 수에 따라 넘어가면 kill 하고, 유휴 스레드가 적으면 kill 을 하는 방식으로 스레드를 관리합니다. Apache 는 일반적으로 요청 하나에 스레드 하나가 대응되도록 구성되어 있습니다. 하나의 프로세스가 관리할 수 있는 스레드의 수는 한정되어 있는데, 따라서 사용자의 접속이 증가하면 프로세스를 새로 fork 합니다. Apache 는 fork 를 할 때마다 CPU와 메모리 사용량이 증가한다는 단점이 있습니다.Nginx 는 멀티 프로세스 + 싱글 스레드 방식을 사용합니다. low memory usage, high concurrency 를 지원하기 위해 async event driven 방식을 채택하고 있고 싱글스레드에서 요청에 응답을 합니다. Nginx 는 master process 가 다수의 worker process 를 관리합니다. master process 는 worker process 를 관리하는 일만을 담당하고 worker process 에서 사용자의 응답에 대응합니다. 각각의 worker 는 초당 수천개의 동시접속, 요청을 처리 가능합니다.Apache, Nginx 의 동시 접속자가 늘어날 때 RPS (Request Per Second) 의 변화 추이는 아래 그림과 같습니다. RPS 는 1초에 처리 가능한 Request 의 개수라고 이해하시면 됩니다. 대표적인 웹 서버인 Apache 와 Nginx 에서의 RPS 처리 성능을 비교한 그래프를 보면 Apache Httpd 의 경우 성능이 급속도로 떨어지는 것을 확인 가능합니다.","10k-의-스레드-실행시-생길수-있는-문제들#10K 의 스레드 실행시 생길수 있는 문제들":"첫번째로 메모리 문제가 발생합니다. thread 각각은 메모리 스택을 가집니다. PCB 보다는 작지만 64Bit JVM 의 경우 1개의 스레드에 대해 1024KByte(1MB)를 사용한다고 합니다. 1만명일 경우 10000MB = 10GB 가 필요하다는 계산에 이르게 됩니다.두번째로 스레드가 많을 경우 Context Switching 시에 경합(Racing Condition)이 발생합니다. 각각의 Thread 가 사용할 CPU 시간을 할당받기 위해 서로 경쟁을 하게 됩니다. 소켓 프로그래밍의 각 커넥션을 10K 의 스레드로 동작할 경우 10K 스레드 각각이 accept(), listen() 동작 등으로 인한 polling 을 하기 위한 경쟁이 발생합니다. 즉 Busy Wait 증상이 나타나기 시작합니다. 채팅창에 텍스트를 입력하지 않더라도 accept(), listen() 을 위한 무한 polling 을 10K의 스레드에서 수행중이기에 10K의 스레드 각각이 서로 CPU 자원을 차지하기 위해 싸우게 됩니다.\nHow Many Threads Is Too Many? 에서는 아래의 그림으로 위 현상으로 인한 결과를 이야기합니다.","가능한-해결책--select-poll-epoll-kqueue-iocp-를-이용한-다중화멀티플렉싱#가능한 해결책 : select, poll, epoll, kqueue, iocp 를 이용한 다중화(멀티플렉싱)":"C10K Problem 에서는 아래와 같이 select(), poll(), kqueue 등의 방법을 제안하고 있습니다. 1990 년도의 linux 에서는 epoll 이 없었기에 BSD OS기반의 서버에서 kqueue 를 사용하거나 select, poll 을 사용하는 것이 주요 방법이었습니다.","select-poll#select, poll":"위 문서에서 보듯 1990년대에 10K 문제는 select, poll 을 통해서 해결했습니다. select, poll 을 쉽게 설명하면 IO 를 멀티플렉싱(다중화)하고 통지하고, 감시할 수 있도록 해주는 기술이라고 생각하면 됩니다.select 함수는 아래의 특징을 갖습니다.\n다중 소켓 관리 : 여러 개의 소켓, 파일 디스크립터를 한번에 감시할 수 있습니다.\n이벤트 기반(Event Driven) : 특정 소켓에서 이벤트가 발생했을 때 알림을 받아 처리할 수 있습니다. 이렇게 함으로써 블로킹 되지 않고 다른 작업을 수행하다가 필요한 소켓에서 이벤트가 발생했을 때에 처리를 할 수 있습니다.\n비동기(Asynchronous) : 비동기적으로 동작하여, 입출력이 준비되지 않아도 다른 작업을 처리 가능합니다.\n1990년대 네트워크 IO 모델은 select(), poll() 이 전부였습니다. select 는 파일디스크립터를 사용하기 때문에 클라이언트 1024개만 처리가 가능합니다. poll() 의 경우 제한이 없습니다. 두 모델 모두 이벤트 발생시 어떤 소켓에서 처리해야 할지 알수 없기에 소켓들을 모두 하나씩 체크합니다. 일일이 소켓들을 하나씩 체크하기에 O(n)의 시간이 소요되는데, 이벤트가 발생할 때마다 소켓을 검색하기 위해 O(n)의 시간이 소요됩니다. 참고) 파일디스크립터\n유닉스 계열의 OS 에서는 일반적인 파일, 네트워크 소켓, 파이프, 블록 디바이스, 캐릭터 디바이스 등의 모든 객체를 파일로 관리합니다.\n열려있는 파일에 접근할 때 fd 를 이용해서 파일을 지정하는데, fd 는 음이 아닌 정수이며, file descriptor table의 index로 사용됩니다.\n파일디스크립터의 수가 클 수록 그 수에 도달하기까지 for 문을 순회해야 한다는 문제도 있고 애플리케이션에서 fd  들을 관리해야 했기 때문에 유지보수가 쉽지 않았다는 문제 역시 있었습니다.또한 select 함수는 커널에 의해 완성되는 기능이 아니라 순수 함수에 의해 동작하기 때문에 select 함수 호출 시 전달된 정보는 운영체제에 등록되지 않고, 따라서 select 호출 시 마다 매번 과련 정보를 전달해줘야 했습니다. 따라서 관찰 대상의 범위, 내용에 변경이 있을 때 변경 사항만 알려줄 수 있으면 한다는 요구사항을 epoll 이 충족시켜줬습니다.","epoll-kqueue-iocp#epoll, kqueue, IOCP":"epoll, kqueue, IOCP는 널리 알려진 I/O 멀티플렉싱(다중화) 기술이며, non-blocking I/O 에 널리 사용되는 방식입니다.리눅스에서 사용되는 epoll() 은 select 의 단점을 보완한 IO 통지 모델입니다. 파일디스크립터를 사용자가 아닌 커널이 관리를 합니다. 파일 디스크립터를 지속적으로 감시할 필요가 없기에 BUSY WAIT 으로 인한 CPU 점유율 문제도 없습니다. select 를 사용시에는 파일 디스크립터를 찾기 위해 전체 파일 디스크립터를 순차검색하기 위햔 FD_ISSET 루프를 돌려야 했지만, epoll 은 이벤트가 발생한 파일 디스크립터만 구조제 배열로 넘겨주기에 메모리 카피 비용이 줄어들었습니다.우리에게 많이 알려진 Node.js 는 내부적으로 epoll() 을 기반으로 구현되어 있습니다. Nginx 는 epoll(), select(), kqueue() 를 기반으로 구현된 웹 서버입니다. Nginx 의 성능이 좋은 이유는 내부적으로 non-blocking I/O 방식의 epoll() 방식으로 구현되어 있었기 때문입니다.자바에서는 NIO 가 JDK4 에서부터 도입되었고 JDK 1.7 에서는 NIO2 라고 불리는 AIO가 도입되었습니다. NIO, AIO 는 모두 Non-Blocking I/O, Zero Copy 기술을 지원합니다. Netty 는 NIO 를 기반으로 동작합니다. NIO 역시 epoll 기반으로 이루어져 있습니다.(윈도우에서는 IOCP 기반, NIO2 에서는 윈도우 JVM 역시 epoll 기반으로 동작)kqueue, IOCP 는 epoll 과 같은 기능을 하는 BSD, MS Window 운영체제의 기능입니다. BSD 에서는 아주 오래전부터 kqueue 가 구현되어 있었습니다.  epoll 은 BSD 보다 늦게 나타났고, linux 2.6 부터 지원하기 시작했습니다. IOCP(Input/Output Completion Port)은 Microsoft Windows 에서 지원하는 기술이며, epoll 보다 먼저 구현되어 있었고 네트워크 성능면에서는 리눅스보다 우월했다는 평가도 존재했습니다.BSD 는 socket 을 처음으로 구현한 유닉스 버전이고, 네트워크 성능을 최대로 사용할 수 있는 유닉스 커널이었습니다. 이런 이유로 초창기 고성능 인터넷 서버는 BSD 기반의 서버가 많았습니다.","epoll#epoll":"epoll 은 리눅스에서 select() 의 단점을 보완해서 사용이 가능하도록 만든 I/O 다중화 (Multiplexing) 모델입니다. select() 를 사용할 때는 프로그래머가 직접 파일 디스크립터 배열을 가지고 있고 select() 함수가 호출될 때마다 전체 파일 디스크립터가 프로그래머가 관리하는 배열로 복사됩니다.하지만 epoll 을 사용할 때는 커널 공간이 파일 디스크립터를 관리하고 변경된 파일디스크립터 들만을 사용자에게 통지해주기 때문에 select 보다는 빠르게 동작할 수 있습니다.epoll 의 주요 함수는 epoll_create, epoll_ctl, epoll_wait 이 잇습니다.  epoll_create 를 이용해서 epoll 구조체를 생성할 수 있고 epoll_ctl 를 사용하면 파일디스크립터를 등록,수정,삭제하는 작업이 가능하며, epoll_wait 을 사용하면 파일 디스크립터의 변화를 감지할 수 있습니다.\nepoll 의 주요 특징은 아래와 같습니다.\nEvent Driven (이벤트 기반) : epoll 은 이벤트가 발생한 소켓에 대해 알림을 받아서 처리합니다. 풀링 작업 업싱 발생한 이벤트에 대해서만 작업을 처리합니다.\nAsynchronous (비동기) : 비동기적으로 동작하고, 입출력이 준비되지 않은 상태에서도 다른 작업을 수행 가능합니다.\nScalability (스케일링 가능성) : epoll 은 연결 수가 증가해도 성능 저하가 적게 발생합니다. 따라서 대규머 네트워크 애플리케이션에서 많은 수의 연결을 관리할 때 효과적입니다.","netty#Netty":"Netty 는 비동기 이벤트 기반의 오픈 소스 네트워크 애플리케이션 프레임워크 입니다.Netty 는 epoll 과 같은 운영체제 수준의 이벤트 루프를 활용해서 네트워크 이벤트를 처리합니다. epoll 은 위에서 살펴봤듯 I/O 멀티플렉싱(다중화) 기술 중 하나입니다. Netty 는 이벤트 기반 아키텍처를 선택하고 있기 때문에 비동기 논 플로킹 기반의 작업 처리가 가능합니다.HTTP 외에도 다양한 프로토콜을 지원하고 Java NIO, Selector 기반으로 적은 리소스로 높은 성능을 보장해줍니다. 불필요한 메모리 copy 를 최소한으로 하며, 이벤트 모델 기반입니다."}},"/reactive-programming/what-is-reactive":{"title":"What Is Reactive","data":{"reactive-란#Reactive 란?":"","reactive-streams-의-발전-이력#Reactive Streams 의 발전 이력":"2011/06\nMS 닷넷 프레임워크에서 Reactive Extensions 배포\n2013/02\nNetflix 기술블로그에서 RxJava 공개 (v0.5)\n2013/09\nReactive manifesto v1 출시\n2013/11\nPivotal Project reactor 1.0.0 배포\n2014/09\nReactive manifesto v2 출시\n2014/11\nNetflix RxJava v1.0 배포\n2015/04\nReactive Streams 1.0.0 이 Java 9 와 함께 배포\nakka stream 1.0 배포\n2017/08\nReactive Streams 1.0.1 배포\n2021/07\nRedhat 에서 mutiny 1.0 배포","reactive-manifesto#Reactive Manifesto":"참고 :\nReactive Manifesto\nReactive Manifesto - ko\nReactive Manifesto - ko 에서 제시하는 4가지의 Reactive 원칙은 아래와 같습니다.\nResponsive (응답성)\n시스템 이 가능한 한 즉각적으로 응답하는 것을 응답성이 있다고 합니다. 응답성은 사용자의 편의성과 유용성의 기초가 되지만, 그것뿐만 아니라 문제를 신속하게 탐지하고 효과적으로 대처할 수 있는 것을 의미합니다. 응답성 있는 시스템은 신속하고 일관성 있는 응답 시간을 제공하고, 신뢰할 수 있는 상한선을 설정하여 일관된 서비스 품질을 제공합니다. 이러한 일관된 동작은 오류 처리를 단순화하고, 일반 사용자에게 신뢰를 조성하고, 새로운 상호작용을 촉진합니다.\n탄력성(Resilient):\n시스템이 장애 에 직면하더라도 응답성을 유지 하는 것을 탄력성이 있다고 합니다. 탄력성은 고가용성 시스템, 미션 크리티컬 시스템에만 적용되지 않습니다. 탄력성이 없는 시스템은 장애가 발생할 경우 응답성을 잃게 됩니다. 탄력성은 복제, 봉쇄, 격리, 위임에 의해 실현됩니다. 장애는 각각의 구성 요소 에 포함되며 구성 요소들은 서로 분리되어 있기 때문에 이는 시스템이 부분적으로 고장이 나더라도, 전체 시스템을 위험하게 하지 않고 복구 할 수 있도록 보장합니다. 각 구성 요소의 복구 프로세스는 다른(외부의) 구성 요소에 위임되며 필요한 경우 복제를 통해 고가용성이 보장됩니다. 구성 요소의 클라이언트는 장애를 처리하는데에 압박을 받지 않습니다.\nElastic (유연성)\n시스템이 작업량이 변화하더라도 응답성을 유지하는 것을 유연성이라고 합니다. 리액티브 시스템은 입력 속도의 변화에 따라 이러한 입력에 할당된 자원을 증가시키거나 감소키면서 변화에 대응합니다. 이것은 시스템에서 경쟁하는 지점이나 중앙 집중적인 병목 현상이 존재하지 않도록 설계하여, 구성 요소를 샤딩하거나 복제하여 입력을 분산시키는 것을 의미합니다. 리액티브 시스템은 실시간 성능을 측정하는 도구를 제공하여 응답성 있고 예측 가능한 규모 확장 알고리즘을 지원합니다. 이 시스템은 하드웨어 상품 및 소프트웨어 플랫폼에 비용 효율이 높은 방식으로 유연성 을 제공합니다.\nMessage Driven (메시지 기반)\n리액티브 시스템은 비동기 메시지 전달 에 의존하여 구성 요소 사이에서 느슨한 결합, 격리, 위치 투명성 을 보장하는 경계를 형성합니다. 이 경계는 장애 를 메시지로 지정하는 수단을 제공합니다. 명시적인 메시지 전달은 시스템에 메시지 큐를 생성하고, 모니터링하며 필요시 배압 을 적용함으로써 유연성을 부여하고, 부하 관리와 흐름제어를 가능하게 합니다. 위치 투명 메시징을 통신 수단으로 사용하면 단일 호스트든 클러스터를 가로지르든 동일한 구성과 의미를 갖고 장애를 관리할 수 있습니다. 논블로킹 통신은 수신자가 활성화가 되어 있을 때만 자원 을 소비할 수 있기 때문에 시스템 부하를 억제할 수 있습니다.\n큰 시스템은 더 작은 규모의 시스템들로 구성되어 있기 때문에 구성 요소의 리액티브 특성에 의존합니다. 즉, 리액티브 시스템은 설계 원칙을 적용하고, 이 특성을 모든 규모에 적용하여, 그 구성 요소를 합성 할 수 있게 하는 것을 의미합니다. 세계에서 가장 거대한 시스템은 이러한 특성에 기반을 둔 아키텍처에 의존하여 매일 수십억명의 요구를 처리합니다. 이러한 설계 원칙을 매번 재발견하는 것을 그만두고 처음부터 의식하여 적용할 때 입니다.","reactive-programming-용어집#Reactive Programming 용어집":"Reactive Manifesto/ko - glossary (용어집) 에서는 Reactive Programming 에서 언급하는 용어들인 비동기, 배압(Back-Pressure), Batching, 컴포넌트, 위임, 탄력성, 장애, 분리, 위치투명성, 메시지 기반(Message Driven), 논블로킹(Non Blocking), 프로토콜, 복제, 자원, 확장성, 시스템, 사용자와 같은 용어들을 설명하고 있습니다. Reactive Manifesto 라는 선언문을 읽을 때보다 용어집을 읽는 것이 오히려 더 이해가 잘 될 수 있기에 이것에 대해 언급하고 넘어갑니다.취업을 준비중인 입장이라 별도의 용어를 설명할 시간이 부족하기에 용어를 정리하는 것은 이번 문서에서는 건너뛰도록 하겠습니다. 추후 시간이 된다면 용어 역시 정리를 하도록 하겠습니다.","명령형-프로그래밍의-단점#명령형 프로그래밍의 단점":"명령형 프로그래밍은 의도가 명확히 보인다는 점과 결과(리턴)값 기반으로 동작한다는 점에서 이해하기 쉽다는 점은 있습니다.하지만, IO 작업이 갈수록 많아질 수록 명령형 처리의 경우 어떤 서비스가 특정 서비스의 결과값에 의존하게 되어야 하거나 특정 함수가 다른 함수의 IO 결과 값에 의존해야 합니다. 이 과정에서 서비스 또는 함수와 함수간의 경계가 모호해집니다. 그리고 독립성이 깨지면서 특정 리턴 값의 결과값에 대해 의존성이 생기게 됩니다.Netflix 의 RxJava 도입기를 보듯 서비스가 커진다면 Reactive Manifesto 기반의 시스템 적용을 고려하게 됩니다.","reactive-manifesto-적용#Reactive Manifesto 적용":"Java 환경에서 Reactive Manifesto 기반의 시스템으로 전환할 때 아래의 3 종류의 선택지를 고려하게 될 가능성이 높습니다. Stream, Future 를 사용할 때 모두 Backpressure 가 관리하는 점이 주요 맹점인데, Stream, Future 를 사용할 경우 이 부분에 대해 별도로 관리할 방안이 없기에 프로그래머가 직접 ExecutorService 등을 활용해서 배압관리를 해줘야 합니다.Stream 기반의 흐름제어 : 적용 불가\n\"비동기적으로 메시지를 주고 받으며 독립적으로 실행됨을 보장해야 한다\"\nStream 은 동기적으로 이루어지기에 비동기적으로 수행해야 한다는 특성에 어긋나게 됩니다.\n하나의 Stream 과 다른 Stream 을 연결해서 사용할 때 서로 결과값을 알아야 하는 동기 방식의 동작을 하게 되고, 최종 결과 포인트인 caller 측면에서는 collect 를 통해서 결과를 조회해야 합니다.\nMessage Driven\nStream 을 메시지 큐 처럼 사용해서 Message Driven 처럼 사용할 수 있습니다.\n배압(Back-Pressure) 관리 - 부하관리\nStream 을 사용할 경우 부하를 관리하지 못합니다.\nFuture 기반의 흐름제어 : 적용 불가\n\"비동기적으로 메시지를 주고 받으며 독립적으로 실행됨을 보장해야 한다\"\nFuture 기반의 흐름제어시 caller 와 callee 는 비동기적으로 동작합니다.\nMessage Driven\nFuture 하나만으로는 메시지 큐의 역할을 할 수 없습니다.\n배압(Back-Pressure) 관리 - 부하관리\nFuture 하나만으로는 부하를 관리하는 배압(Back-Pressure) 를 적용할 수 없습니다.\nReactive Stream : 적용 가능\n\"비동기적으로 메시지를 주고 받으며 독립적으로 실행됨을 보장해야 한다\"\ncallee 는 최종적으로 Publisher 를 반환합니다. caller 는 Subscriber 를 등록합니다. caller 와 callee 는 각각 Publisher, Subscriber 만 바라보면 되고 서로의 결과값을 알고 있을 필요는 없습니다.\nMessage Driven\nPublisher 는 내부적으로 메시지 대기열을 생성해서 관리합니다.\n배압(Back-Pressure) - 부하관리\nReactive Streams 는 Back-Pressure 를 관리할 수 있는 방법이 내부적으로 갖춰져있습니다."}},"/spring-cloud-reactive-circuitbreaker/intro":{"title":"Intro","data":{"intro#Intro":""}},"/server-sent-event/example":{"title":"Example","data":{}},"/server-sent-event/what-is-sse":{"title":"What Is Sse","data":{"server-sent-event#Server Sent Event":"","polling#Polling":"주"}},"/spring-cloud-stream-and-kafka/intro":{"title":"Intro","data":{"":"Spring Cloud Stream\n카프카 기본 개념\nDocker Compose\nSpring Cloud Stream\nSpring Cloud Stream Kafka Binder"}},"/server-sent-event/intro":{"title":"Intro","data":{}},"/spring-cloud-stream-and-kafka/kafka-basic":{"title":"Kafka Basic","data":{"kafka-의-주요-개념들#kafka 의 주요 개념들":"","kafka-의-주요-특징#Kafka 의 주요 특징":"분산 시스템:\nKafka는 여러 브로커(서버)로 구성된 분산 시스템입니다. 이는 확장성을 지원하며 높은 부하와 대량의 데이터를 처리할 수 있도록 합니다.\n고가용성 및 복제:\nKafka는 데이터의 고가용성을 보장하기 위해 데이터를 여러 브로커에 복제합니다. 따라서 하나의 브로커에 장애가 발생하더라도 데이터 손실 없이 서비스를 지속할 수 있습니다.\n데이터의 복제본을 여러 서버에 분산시켜서 저장하기에 서버하나가 실패하더라도 데이터 손실을 방지할 수 있다는 것은 장점입니다.\n고가용성은 시스템이 장애나 오류에 강건하게 대응하고 지속적으로 운영되며 사용가능한 상태를 유지하는 능력을 의미합니다. 고가용성이 높은 시스템은 사용자에게 지속적인 서비스를 제공할 수 있으며 장애 발생 시에도 데이터의 손실을 최소화 하고 빠른 회복을 할 수 있습니다.\n고성능:\nKafka는 대용량 데이터 처리를 목표로 하기 때문에 높은 성능을 제공합니다. 특히 디스크에 기록하면서도 낮은 지연 시간을 유지할 수 있습니다.\n스트림 처리:\nKafka는 데이터를 실시간으로 처리할 수 있도록 스트림 처리를 지원합니다. Kafka Streams API를 사용하면 데이터에 대한 복잡한 연산을 수행하고 결과를 생성할 수 있습니다.\n확장성:\n새로운 브로커를 추가함으로써 Kafka 클러스터의 용량을 쉽게 확장할 수 있습니다. 이는 시스템의 요구 사항이 변할 때 유연하게 대응할 수 있음을 의미합니다.\n유연한 보관 및 보존:\nKafka는 데이터를 보관하고 기간별로 데이터를 보존할 수 있습니다. 이는 영구적인 데이터 저장과 이력 추적에 유용합니다.\n토픽 기반 메시지 시스템:\nKafka는 토픽을 사용하여 메시지를 구분하고 구독하는 방식을 채택합니다. 이를 통해 데이터의 흐름을 조직화하고 특정 주제에 대한 데이터를 관리할 수 있습니다.\n다양한 클라이언트 지원:\nKafka는 다양한 언어로 구현된 클라이언트를 지원하며, 프로듀서 및 컨슈머를 통한 데이터 흐름을 구축하기 위한 다양한 라이브러리를 제공합니다.","토픽#토픽":"메시지를 적재하거나 구독할 수 있는 하나의 메시지 대기열 같은 개념입니다. 토픽은 파티션 1개로만 운영할 수도 있고 여러개의 파티션으로 나누어 운영할 수 도 있습니다. 파티션을 1개로 구성할 경우 컨슈머 랙 증상이 발생할 수 있기 때문에 파티션을 여러개로 구성해서 사용하는 경우가 많습니다.일반적으로는 토픽 하나에 파티션을 여러 개 두어서 컨슈머 랙 증상을 방지하는 편입니다.여러 개의 파티션으로 나눌 경우 각 파티션을 바라봐야 할 컨슈머 개수도 파티션의 개수에 맞춰서 운영합니다. 그런데 파티션의 개수보다 컨슈머의 수가 더 많을 경우 일부 컨슈머는 파티션을 할당받지 못하고 대기 상태가 됩니다. 위의 그림에서는 초록색 배경으로 표시한 컨슈머가 유휴상태에 진입했네요. 컨슈머와 컨슈머 그룹, 컨슈머 리밸런싱에 대해서는 뒤에서 따로 정리합니다.","메시지-프로듀서-컨슈머-컨슈머-그룹#메시지, 프로듀서, 컨슈머, 컨슈머 그룹":"메시지토픽에 적재되는 개별 데이터를 메시지라고 합니다. 메시지는 key, value, timestamp 로 구성됩니다. \n프로듀서토픽에 데이터를 적재하는 역할을 합니다.프로듀서는 여러가지 언어로 작성 가능합니다.\n컨슈머컨슈머는 토픽을 구독해서 메시지를 읽어들이는 역할을 수행합니다. 보통 컨슈머의 개수는 파티션의 개수에 맞춰서 띄웁니다.\n컨슈머 그룹보통 토픽을 파티션 1개로만 운영하는 경우가 없기때문에 여러개의 파티션으로 구성하는데, 이렇게 파티션을 여러개로 나누어 둔 경우 컨슈머 역시 파티션 갯수에 맞춰서 띄웁니다. 그리고 띄운 컨슈머들을 하나의 그룹으로 묶어서 하나의 그룹으로 인식하는데 이것을 컨슈머 그룹이라고 합니다..","컨슈머-랙#컨슈머 랙":"컨슈머는 토픽을 구독해서 메시지를 읽어들입니다.  그런데 프로듀서가 메시지를 발행하는 속도에 비해 컨슈머가 메시지를 읽어서 처리하는 속도가 느릴 경우 점점 컨슈머의 오프셋이 가장 최신 오프셋으로부터 멀어지게 됩니다. 이렇게 컨슈머의 읽기 속도가 메시지 발급속도를 따라가지 못하는 현상을 \"컨슈머 랙(Consumer Lag)\" 이라고 부릅니다.","파티션과-컨슈머-그룹#파티션과 컨슈머 그룹":"컨슈머 랙 증상은 토픽을 여러 개의 파티션으로 구성하고 각각의 파티션을 구독하는 컨슈머들을 파티션 갯수만큼 띄우는 것으로 해결이 가능합니다.파티션파티션은 토픽을 여러개로 나눈 토픽 내부의 메시지 대기열을 의미합니다. 파티션은 프로듀서가 보내는 메시지의 메시지 키 값에 의해 파티션이 선택됩니다. 이 메시지 키 값을 지정하지 않고 메시지를 전송할 경우 내부적으로 라운드 로빈 방식으로 파티션을 선택해서 데이터를 전송하게 됩니다.위의 그림은 파티션 키 알고리즘을 메시지 키가 정수일 때 홀수/짝수인지에 따라서 파티션이 선택되도록 한 경우로 지정했을 경우에 대한 그림입니다. 실무에서는 파티션 키를 제품의 키를 기준으로 한다던가 등등 여러가지 케이스들이 있습니다.\n컨슈머 그룹하나의 토픽 내에 파티션을 각각 하나씩 바라보는 컨슈머들을 하나의 그룹으로 묶을 수 있는데 이것을 컨슈머 그룹이라고 합니다. 컨슈머 그룹은 여러개를 운영하는 것이 가능합니다. 만약 토픽 하나에 대한 파티션 개수보다 컨슈머 그룹내의 컨슈머 개수가 더 많다면 어떻게 될까요? 이런 경우 놀고 있는(유휴(Idle)) 상태의 컨슈머가 생기게 됩니다. 장애로 이어지지는 않지만 자원 낭비가 생기게 됩니다.","순서가-중요한-메시지일-경우#순서가 중요한 메시지일 경우":"순차적인 메시지 처리를 하게끔 해야 하는 경우가 있습니다. 이런 경우 어떻게 하면 문제를 해결할 수 있는지를 정리해봅니다.토픽을 여러 개의 파티션으로 파티셔닝하면 메시지가 순차적으로 처리는 것을 보장하지 못하게 됩니다. 예를 들어서 주문완료 → 결제완료 → 상품준비중 의 순서로 메시지를 보내야 하는 경우가 있습니다.만약 파티션 알고리즘에 따라 처리하거나, 기본 설정인 라운드 로빈 방식으로 처리할 경우 주문완료 메시지는 파티션 1에, 결제완료는 파티션 2에, 상품 준비중 이벤트는 파티션1에 쌓이게 되어서 메시지가 순차적으로 전달되지 않을 수 있습니다.이런 경우 특정 상품을 장바구니에서 주문/결제 하는 기능에 대해서는 특정 파티션을 선택해서 메시지를 전송하게끔 하는 것으로 이런 문제를 해결 가능합니다.","카프카-브로커#카프카 브로커":"카프카 브로커는 토픽들과 파티션들을 가지고 운영하고 있는 하나의 물리적인 서버를 의미합니다.\n어쩌다 보니 그림이 너무 크게 추출되었는데 그림 사이즈 수정하는 도구를 찾아서 문제를 해결하겠습니다!!!","카프카-브로커-클러스터링#카프카 브로커 클러스터링":"몽고DB의 레플리카셋, 샤드 클러스터를 구성해보셨거나 k8s 앱을 작성해보신 분들이라면 클러스터링이라는 것이 무엇을 의미하는지 아실 겁니다. 카프카 브로커 역시 클러스터링이 가능합니다.위의 그림에서 보듯 주키퍼(zookeeper)를 통해서 브로커들의 상태를 관리하고, 리더파티션 선출, 메타데이터 관리 등의 역할을 합니다. 주키퍼(zookeeper) 역시 클러스터링이 가능합니다.","카프카-브로커-장애-발생시-리더-파티션-재선출#카프카 브로커 장애 발생시 리더 파티션 재선출":"위의 그림에서는 1번 브로커 에서 장애가 생겼습니다. 브로커 1 에는 파티션 1을 리더 파티션으로 운영되고 있었습니다. 이렇게 장애가 생긴 경우 주키퍼(zookeeper)가 브로커들의 상태를 체크하고 있다가 장애를 파악하면 리더 파티션을 투표를 통해서 선출하게 되는데요. 위의 그림에서는 2번 브로커 내의 1번 파티션이 리더로 선출된 것을 확인 가능합니다.참고로 주키퍼(zookeeper) 역시 클러스터링이 가능합니다."}},"/spring-cloud-stream-and-kafka/kafka-docker-compose":{"title":"Kafka Docker Compose","data":{"kafka-docker-compose#kafka docker-compose":"카프카를 클라우드 플랫폼에 설치를 하면 과금이 많이 됩니다. 또는 개발 버전을 테스트 시에 실제 물리적인 개발 서버에 테스트하기에는 부담스러울 경우가 많습니다. 이런 경우 docker-compose 로 zookeeper, broker, kafka-ui 등을 띄워서 동작을 확인하는 편입니다.이번 문서에서는 카프카 브로커 클러스터를 두가지 버전으로 구성합니다. 첫번째 버전은 간소화된 버전으로 브로커 3기, 주키퍼, kafka-ui 를 띄운 버전이고 두번째 버전은 주키퍼, schema-registry, kafka connector, 카프카 브로커 3기, kafka-ui 이렇게 구성합니다.\n첫번째 버전 : kafka broker (3EA), zookeeper, kafka-ui\n두번째 버전 : schema-registry, kafka-connector, zookeeper, kafka broker(3EA), kafka-ui","첫번째-버전--kafka-broker-3ea-zookeeper-kafka-ui#첫번째 버전 : kafka broker (3EA), zookeeper, kafka-ui":"간소화된 버전입니다. 설명은 생략하고 docker-compose 파일만 남겨둡니다.\nversion: '3.8'\r\nservices:\r\n  zookeeper-1:\r\n    image: confluentinc/cp-zookeeper:7.2.6\r\n    ports:\r\n      - '32181:32181'\r\n    environment:\r\n      ZOOKEEPER_CLIENT_PORT: 32181\r\n      ZOOKEEPER_TICK_TIME: 2000\r\n  kafka-1:\r\n    image: confluentinc/cp-kafka:7.2.6\r\n    ports:\r\n      - '9092:9092'\r\n    depends_on:\r\n      - zookeeper-1\r\n    environment:\r\n      KAFKA_BROKER_ID: 1\r\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:32181\r\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT\r\n      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL\r\n      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-1:29092,EXTERNAL://localhost:9092\r\n      KAFKA_DEFAULT_REPLICATION_FACTOR: 3\r\n      KAFKA_NUM_PARTITIONS: 3\r\n  kafka-2:\r\n    image: confluentinc/cp-kafka:7.2.6\r\n    ports:\r\n      - '9093:9093'\r\n    depends_on:\r\n      - zookeeper-1\r\n    environment:\r\n      KAFKA_BROKER_ID: 2\r\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:32181\r\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT\r\n      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL\r\n      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-2:29093,EXTERNAL://localhost:9093\r\n      KAFKA_DEFAULT_REPLICATION_FACTOR: 3\r\n      KAFKA_NUM_PARTITIONS: 3\r\n  kafka-3:\r\n    image: confluentinc/cp-kafka:7.2.6\r\n    ports:\r\n      - '9094:9094'\r\n    depends_on:\r\n      - zookeeper-1\r\n    environment:\r\n      KAFKA_BROKER_ID: 3\r\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:32181\r\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT\r\n      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL\r\n      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-3:29094,EXTERNAL://localhost:9094\r\n      KAFKA_DEFAULT_REPLICATION_FACTOR: 3\r\n      KAFKA_NUM_PARTITIONS: 3\r\n  kafka-ui:\r\n    image: provectuslabs/kafka-ui\r\n    container_name: kafka-ui\r\n    ports:\r\n      - \"9000:8080\"\r\n    restart: always\r\n    environment:\r\n      - KAFKA_CLUSTERS_0_NAME=local\r\n      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka-1:29092,kafka-2:29093,kafka-3:29094\r\n      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper-1:22181","두번째-버전--schema-registry-kafka-connector-zookeeper-kafka-broker3ea-kafka-ui#두번째 버전 : schema-registry, kafka-connector, zookeeper, kafka broker(3EA), kafka-ui":"이번에도 자세한 설명은 생략하겠습니다.","env#.env":"KAFKA_VERSION=7.0.1\r\nGLOBAL_NETWORK=kafka-local-all-hello-world\r\nDEBEZIUM_VERSION=2.1","docker-composeyml#docker-compose.yml":"version: '3.7'\r\nservices:\r\n  schema-registry:\r\n    image: confluentinc/cp-schema-registry:${KAFKA_VERSION}\r\n    container_name: kafka-schema-registry\r\n    hostname: schema-registry\r\n    depends_on:\r\n      - kafka-broker-1\r\n      - kafka-broker-2\r\n      - kafka-broker-3\r\n    ports:\r\n      - \"9397:9397\"\r\n    environment:\r\n      SCHEMA_REGISTRY_HOST_NAME: schema-registry\r\n      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper:2181'\r\n      SCHEMA_REGISTRY_LISTENERS: http://schema-registry:9397\r\n      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka-broker-2:9092,LISTENER_LOCAL://kafka-broker-2:29092\r\n      SCHEMA_REGISTRY_DEBUG: 'true'\r\n    networks:\r\n      - kafka-local-all\r\n  kafka-connector:\r\n    image: confluentinc/cp-kafka-connect:${KAFKA_VERSION}\r\n    container_name: kafka-connector\r\n    ports:\r\n      - 9398:9398\r\n    environment:\r\n      CONNECT_BOOTSTRAP_SERVERS: PLAINTEXT://kafka-broker-2:9092,LISTENER_LOCAL://kafka-broker-2:29092\r\n      CONNECT_REST_PORT: 8083\r\n      CONNECT_GROUP_ID: \"quickstart-avro\"\r\n      CONNECT_CONFIG_STORAGE_TOPIC: \"quickstart-avro-config\"\r\n      CONNECT_OFFSET_STORAGE_TOPIC: \"quickstart-avro-offsets\"\r\n      CONNECT_STATUS_STORAGE_TOPIC: \"quickstart-avro-status\"\r\n      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1\r\n      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1\r\n      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1\r\n      CONNECT_KEY_CONVERTER: \"org.apache.kafka.connect.json.JsonConverter\"\r\n      CONNECT_VALUE_CONVERTER: \"org.apache.kafka.connect.json.JsonConverter\"\r\n      CONNECT_INTERNAL_KEY_CONVERTER: \"org.apache.kafka.connect.json.JsonConverter\"\r\n      CONNECT_INTERNAL_VALUE_CONVERTER: \"org.apache.kafka.connect.json.JsonConverter\"\r\n      CONNECT_REST_ADVERTISED_HOST_NAME: \"kafka-connector\"\r\n      CONNECT_LOG4J_ROOT_LOGLEVEL: DEBUG\r\n      CONNECT_PLUGIN_PATH: \"/usr/share/java,/etc/kafka-connect/jars\"\r\n    depends_on:\r\n      - kafka-broker-1\r\n      - kafka-broker-2\r\n      - kafka-broker-3\r\n      - schema-registry\r\n    volumes:\r\n      - \"./kafka-connect/connectors:/etc/kafka-connect/jars\"\r\n    networks:\r\n      - kafka-local-all\r\n  kafka-broker-1:\r\n    image: confluentinc/cp-kafka:${KAFKA_VERSION}\r\n    container_name: kafka-broker-1\r\n    hostname: kafka-broker-1\r\n    ports:\r\n      - \"19092:19092\"\r\n    environment:\r\n      KAFKA_BROKER_ID: 1\r\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\r\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker-1:9092,LISTENER_LOCAL://kafka-broker-1:19092\r\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,LISTENER_LOCAL:PLAINTEXT\r\n      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT\r\n      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3\r\n      KAFKA_COMPRESSION_TYPE: producer\r\n    volumes:\r\n      - \"./volumes/kafka/broker-1:/var/lib/kafka/data\"\r\n    networks:\r\n      - kafka-local-all\r\n  kafka-broker-2:\r\n    image: confluentinc/cp-kafka:${KAFKA_VERSION}\r\n    container_name: kafka-broker-2\r\n    hostname: kafka-broker-2\r\n    ports:\r\n      - \"29092:29092\"\r\n    environment:\r\n      KAFKA_BROKER_ID: 2\r\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\r\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker-2:9092,LISTENER_LOCAL://kafka-broker-2:29092\r\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,LISTENER_LOCAL:PLAINTEXT\r\n      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT\r\n      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3\r\n      KAFKA_COMPRESSION_TYPE: producer\r\n    volumes:\r\n      - \"./volumes/kafka/broker-2:/var/lib/kafka/data\"\r\n    networks:\r\n      - kafka-local-all\r\n  kafka-broker-3:\r\n    image: confluentinc/cp-kafka:${KAFKA_VERSION}\r\n    container_name: kafka-broker-3\r\n    hostname: kafka-broker-3\r\n    ports:\r\n      - \"39092:39092\"\r\n    environment:\r\n      KAFKA_BROKER_ID: 3\r\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\r\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker-3:9092,LISTENER_LOCAL://kafka-broker-3:39092\r\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,LISTENER_LOCAL:PLAINTEXT\r\n      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT\r\n      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3\r\n      KAFKA_COMPRESSION_TYPE: producer\r\n    volumes:\r\n      - \"./volumes/kafka/broker-3:/var/lib/kafka/data\"\r\n    networks:\r\n      - kafka-local-all\r\n  kafka-manager:\r\n    image: hlebalbau/kafka-manager:stable\r\n    restart: always\r\n    ports:\r\n      - \"9090:9090\"\r\n    environment:\r\n      ZK_HOSTS: \"zookeeper:2181\"\r\n    networks:\r\n      - kafka-local-all\r\nnetworks:\r\n  kafka-local-all:\r\n    driver: bridge\r\n#    external: true # network 가 이미 있을 경우에 삭제 안하고 할 경우에 사용"}},"/spring-cloud-reactive-circuitbreaker/reactive-circuit-breaker-basic":{"title":"Reactive Circuit Breaker Basic","data":{"reactive-circuit-breaker#Reactive Circuit Breaker":"","참고자료#참고자료":"Service resiliency with Spring Boot and Resilience4j\nCircuitbreaker를 사용한 장애 전파 방지","plain-msa#Plain MSA":"Spring Cloud 와 API 통신 추상화 계층이 없는 MSA의 구조는 아래와 같습니다.\r\n클라이언트와 API간의 통신 복잡성\nMSA#1, MSA#2, ... MSA#n 의 IP 주소, 호스트 네임, fqdn 등을 모두 알고 있어야 하고 MSA#1, MSA#2, ... MSA#n의 네트워크 주소, FQDN 등이 변경될때마다 클라이언트(AOS/IOS/WEB)에 모두 반영해줘야 합니다.\nMSA API 간의 통신 안정성 확보 불가\nAPI 간의 통신 시에 단절이 어떻게 되는지 판정할 방법과 Healthcheck 를 할 방법, Client 측의 Loadbalancing 등에 대한 대책이 분명하지 않습니다.\n메시지 큐와의 통신 구현 라이브러리 종속\n각각의 MSA는 메시지 큐와 통신할 때에는 메시지 큐의 구체적인 종류에 따라 구현이 계속 달라지게 되고, 메시지 큐의 종류를 바꾸는 것 역시 쉽지 않습니다.\n즉 메시지 큐의 종류에 종속됩니다.","spring-cloud-circuit-breaker-를-적용하면#Spring Cloud Circuit Breaker 를 적용하면":"MSA 구조에 Spring Cloud Circuit Breaker 를 적용하면 아래와 같은 방식으로 통신이 이루어집니다.\r\nClient와 MSA API 간의 통신\nClient 와 MSA API 가 통신을 할 때 Client 는 모든 MSA API 의 주소를 알고 있을 필요가 없습니다. Spring Cloud Gateway 서버의 주소만 알고 있으면 됩니다.\n각각의 개별 MSA 들이 주소가 바뀌거나 도메인 호스팅이 바뀌거나 FQDN 등이 변경되는 것은 Spring Cloud Gateway 내에서 설정을 바꿔주면 되고, Client 는 Spring Cloud Gateway 내에서 제공하는 주소만 알고 있으면 됩니다.\nMSA API 간의 통신 안정성 확보\nMSA간 통신을 할 때 통신이 확보되지 않는 경우에 대한 구현은 Spring Cloud Circuit Breaker 에 추상화되어 있습니다. 만약 Circuit Breaker 를 사용하지 않는다면, 개발자가 직접 heartbeat, API 상태체크, 실패율 측정 등의 기능을 직접 개발해야 합니다.\n장애가 격리됩니다. 모놀리딕 구조에서는 모든 서비스가 하나의 애플리케이션에서 동작하는데 이때 특정 장애가 발생하면 전체 서비스가 장애가 날 수 있습니다. 하지만, MSA 구조로 분해를 하면 장애가 격리된다는 점에서 장점을 가집니다. 하지만, 장애 발생할 경우에 특정 API에서 잘못된 결과를 낼 수 있는 가능성 역시 남아있게 되는데 여기에 대해서는 Circuit Breaker 의 장애감지, 회로 차단 등의 기능을 통해서 미연에 트래픽을 차단하는 등의 기능을 제공하는게 가능하게 됩니다.\nSpring Cloud Stream 을 이용한 메시징 라이브러리 추상화\nSpring Cloud Stream 을 사용하면 메시지 큐의 종류에 종속되는 정도가 대폭 줄어듭니다. 따라서 서비스 성격,운영 비용에 따라 메시지 큐의 종류를 바꾸는 것이 조금 더 자유로워지게 됩니다.\nSpring Cloud Config Server 사용시 설정 변경 사항 즉시 반영\nGateway, Circuit Breaker 의 세부적인 모니터링 주기라든지, Filter 관련 내용들을 변경해서 새로 적용할 때 Spring Cloud Config Server 에서 property를 관리하고 있다면 서버의 재기동 없이 상태가 반영될 수 있습니다.","spring-cloud-release#Spring Cloud Release":"github.com - spring-cloud-release\nSpring Cloud Release - Supported Release\nspring.io/projects/spring-cloud#overivew","resilience4j-circuit-breaker#Resilience4j Circuit Breaker":"Spring Cloud Circuit Breaker 는 추상화된 라이브러리이고, 구현되어 있는 구현체가 필요합니다. 이 중 Reactor 기반의 Circuit Breaker 를 지원하는 것은 현재 Resilience4j 의 Cricuit Breaiker 뿐 입니다.\nResilience4j Circuit Breaker\ngithub.com/resilience4j/resilience4j","circuit-breaker-의-3가지-상태#Circuit Breaker 의 3가지 상태":"Circuit Breaker 는 Closed, Half Open, Open 상태를 그림을 보고 이해해야 합니다. \n참고\nService resiliency with Spring Boot and Resilience4j\nCircuitbreaker를 사용한 장애 전파 방지","closed#Closed":"정상적으로 요청을 받을 수 있는 상태입니다.\n처음 보거나 오랜만에 봤다면  Closed 라는 단어를 보고 차단되었다고 착각하기 쉽습니다. 주의해야 합니다.\nClosed 는 회로차단기의 스위치를 닫아(Closed)서 스위치가 붙어있는 상태를 기억하면 이해가 쉽습니다.","half-open#Half Open":"트래픽을 어느 정도 흘려본 후 Open 을 유지할지 Closed 로 변경할지 결정하는 상태입니다.","open#Open":"Circuit Breaker 가 회로를 끊어둔 상태입니다.\n회로 차단기가 켜져있는 상태입니다.\n특정 목적지로 가는 트래픽을 차단하고 있는 상태입니다.\nResilience4j 의 로고 역시 이와 같은 3종류의 상태를 잘 표현하고 있습니다. 검은색 원은 Closed, 반정도 차있는 원은 Half Open, 비어있는 원은 Open 상태를 의미합니다.","상태-변이-state-transition#상태 변이 (State Transition)":"출처 : resilience4j.readme.io/docs/circuitbreaker#introduction","closed--open#Closed → Open":"Closed 에서는 Open 으로만 상태 변화가 가능합니다.통신이 열려있는 상태에서는 차단 하는 것만 가능하다는 것으로 이해하면 기억하기 쉽습니다.","half-open--open-half-open--closed#Half Open → Open, Half Open → Closed":"Half Open 상태에서는 Open, Closed 상태로만 변화가 가능합니다.","open--half-open#Open → Half Open":"회로가 차단되어 있는 Open 상태에서는 Half Open 상태로만 진입이 가능합니다.Half Open 으로 전환하는 방법은 코드로 실행시키는 방식, 일정시간 대기 후 Open 으로 전환되도록 하는 방식이 있습니다. 일반적으로 코드 레벨에서 하드코딩으로 Half Open 으로 전환되도록 하는 방식은 추천되는 방식은 아닙니다.가급적이면 일정 시간 이후에 Half Open 이 되도록 delay 시간을 주어야 합니다.\nenableAutomaticTransitionFromOpenToHalfOpen()\nwaitDurationInOpenState()\n위의 두 함수를 통해서 이 설정을 활성화하는 것이 가능합니다. 아래의 yml 설정으로도 이 설정을 지정할 수 있습니다.\nautomatic-transition-from-open-to-half-open-enabled\nopen 에서 halfopen 으로 자동으로 전환하게끔 enable 하는 메서드입니다.\n기본값은 false 이지만 위에서는 enable 시켜서 true 가 되었습니다.\nwait-duration-in-open-state\nopen 에서 half open 으로 전환할 때 까지 필요한 시간(Duration)입니다.\n설정하지 않으면 기본값으로 설정되며 기본값은 60초 입니다.","sliding-window#Sliding Window":"슬라이딩 윈도우는 위와 같은 방식으로 동작합니다. circular array 처럼 동작합니다.슬라이딩 윈도우는 실패, 성공 여부를 sliding window size 만큼 쌓아두고 실패율(failure rate)을 측정하기 위해 사용합니다. circuit breaker 를 이용해서 통신을 차단하거나 허용할 때는 이 실패율을 기준으로 판단합니다.sliding window 로 측정을 할 때에는 sliding Window Size 에 도달할 때 까지 계속해서 측정을 합니다. 그리고 측정한 개수가 n개에 도달했을 경우 가장 최초에 저장했던 결과를 제거한 후 새로운 결과를 저장합니다.","sliding-window-를-이용한-failure-rate-측정#Sliding Window 를 이용한 Failure Rate 측정":"failure rate 는 실패횟수를 Sliding Window 사이즈로 나눈 수치를 Failure Rate 라고 합니다.\nfailure rate = 실패한 호출 수 / Sliding Window size\n슬라이딩 윈도우 측정 시에 새로운 측정 값이 추가될 때 Sliding Window 전체의 실패 갯수를 측정하는 방식으로 측정하지 않습니다. O(n) 의 시간이 걸리기 때문입니다. 새로운 측정 값이 들어왔을 때 새로운 측정 결과는 더하고 이전 측정 결과는 뺀 후에 이것을 슬라이딩 윈도우 사이즈로 나누어서 새로운 failure rate 를 측정하게 됩니다.","의존성#의존성":"의존성은 아래와 같습니다.\nrepositories {\r\n  mavenCentral()\r\n}\r\n\r\nextra[\"springCloudVersion\"] = \"2023.0.0\"\r\n\r\ndependencies {\r\n  implementation(\"org.springframework.cloud:spring-cloud-starter-circuitbreaker-resilience4j\")\r\n  testImplementation(\"org.springframework.boot:spring-boot-starter-test\")\r\n}\r\n\r\ndependencyManagement {\r\n  imports {\r\n    mavenBom(\"org.springframework.cloud:spring-cloud-dependencies:${property(\"springCloudVersion\")}\")\r\n  }\r\n}","설정#설정":"Circuit Breaker 와 같은 모니터링이나 장애 탐지를 위한 성격의 코드들은 가급적 Java 코드 보다는 yaml 파일에 따로 분리해서 관리해두는 편입니다. 이렇게 yaml 파일을 따로 분리해둔 후 Spring Cloud Config Server 에서 관리하게끔 하면, 실제 서비스의 기능 릴리즈가 아닌 Circuit Breaker 설정 변경만 해야 할 경우에 Spring Cloud Config Server 내에 yml 파일의 속성을 변경해주면 반영되기 때문입니다.이번 문서에서는 Java Bean 설정방법과 yaml 설정 방식 모두 어떤 필드가 있는지 이런 것들을 정리해봅니다.","java-bean-설정#Java Bean 설정":"Java 설정 시에는 ReactiveResilience4JCircuitBreakerFactory 객체를 바로 생성하지 않고 Customizer<ReactiveResilience4JCircuitBreakerFactory> 타입의 람다 구문을 생성해서 Bean 으로 등록합니다. 즉, 객체를 생성하지 않고 식을 인스턴스화 해서 넘기는 지연(lazy) 초기화 방식입니다.\n@Bean\r\npublic Customizer<ReactiveResilience4JCircuitBreakerFactory> foobarCircuitBreaker(){\r\n  var circuitBreakerConfig = CircuitBreakerConfig\r\n      .custom()\r\n      .slidingWindowSize(10)\r\n      .failureRateThreshold(75)\r\n      .enableAutomaticTransitionFromOpenToHalfOpen()\r\n      .waitDurationInOpenState(Duration.ofSeconds(5))\r\n      .permittedNumberOfCallsInHalfOpenState(6)\r\n      .ignoreExceptions(ArithmeticException.class)\r\n      .maxWaitDurationInHalfOpenState(Duration.ofSeconds(30))\r\n      .build();\r\n\r\n  var timeLimiterConfig = TimeLimiterConfig.custom()\r\n      .cancelRunningFuture(true)\r\n      .timeoutDuration(Duration.ofSeconds(3))\r\n      .build();\r\n\r\n  var circuitBreakerId = \"foobar\";\r\n\r\n  return factory -> {\r\n    factory.addCircuitBreakerCustomizer(loggingCustomizer(), circuitBreakerId);\r\n    factory.configure(builder -> {\r\n      builder\r\n          .circuitBreakerConfig(circuitBreakerConfig)\r\n          .timeLimiterConfig(timeLimiterConfig);\r\n    }, circuitBreakerId);\r\n  };\r\n}","circuitbreakerconfig#CircuitBreakerConfig":"CircuitBreakerConfig 를 설정하는 코드는 아래와 같습니다.\n  var circuitBreakerConfig = CircuitBreakerConfig\r\n      .custom()\r\n      .slidingWindowSize(10)\r\n      .failureRateThreshold(75)\r\n      .enableAutomaticTransitionFromOpenToHalfOpen()\r\n      .waitDurationInOpenState(Duration.ofSeconds(5))\r\n      .permittedNumberOfCallsInHalfOpenState(6)\r\n      .ignoreExceptions(ArithmeticException.class)\r\n      .maxWaitDurationInHalfOpenState(Duration.ofSeconds(30))\r\n      .build();\nslidingWindowSize : 호출 결과를 저장할 sliding window 입니다. 기본 사이즈는 100 입니다.\nfailureRateThreshold : 몇번 실패해야 실패로 인정할지에 대한 백분율 비율입니다. 기본 값은 50 (퍼센트)입니다.\nenableAutomaticTransitionFromOpenToHalfOpen\nopen 에서 halfopen 으로 자동으로 전환하게끔 enable 하는 메서드입니다.\n기본값은 false 이지만 enableAutomaticTransitionFromOpenToHalfOpen () 메서드를 호출하면 true 로 설정됩니다.\nwaitDurationInOpenState\nopen 에서 half open 으로 전환할 때 까지 필요한 시간(Duration)입니다.\n설정하지 않으면 기본값으로 설정되며 기본값은 60초 입니다.\npermittedNumberOfCallsInHalfOpenState\nhalf open 상태에서 허용할 호출 수 입니다.\n기본값은 10 입니다.\nignoreExceptions\n서비스에서 exception 을 던지더라도 차단을 걸지 않고 허용할 exceptions 목록입니다.\nmaxWaitDurationInHalfOpenState\nhalf open 상태에서 대기할 수 있는 최대시간 입니다.\n기본값은 0 입니다.","timelimiterconfig#TimeLimiterConfig":"var timeLimiterConfig = TimeLimiterConfig.custom()\r\n        .cancelRunningFuture(true)\r\n        .timeoutDuration(Duration.ofSeconds(3))\r\n        .build();\ncancelRunningFuture\nFuture 가 진행중일 경우 cancel 할지 여부를 결정합니다. 기본 값은 true 입니다.\ntimeoutDuration\ntimeout 기준 시간입니다. 기본 값은 1초 입니다.","customizert-설정#Customizer<T> 설정":"Customizer 타입의 람다를 생성해서 리턴 값으로 넘기는 방식으로 Bean 을 생성합니다. 객체를 생성하지 않고 식을 인스턴스화 해서 넘기는 지연(lazy) 초기화 방식입니다.\n  return factory -> {\r\n    factory.addCircuitBreakerCustomizer(loggingCustomizer(), circuitBreakerId);\r\n    factory.configure(builder -> {\r\n      builder\r\n          .circuitBreakerConfig(circuitBreakerConfig)\r\n          .timeLimiterConfig(timeLimiterConfig);\r\n    }, circuitBreakerId);\r\n  };\nconfigure(builder, circuitBreaker Id)\ncircuit breaker 의 id 를 전달해서 특정 id 에 대한 circuit breaker 에 대한 설정을 합니다.\n일반적인 모든 circuit breaker 에 설정을 적용하려면 configureDefault()  메서드를 사용하면 됩니다.","yaml-설정#yaml 설정":"resilience4j:\r\n  circuitbreaker:\r\n    instances:\r\n      basic:\r\n        sliding-window-size: 10\r\n        failure-rate-threshold: 70\r\n        automatic-transition-from-open-to-half-open-enabled: true\r\n        wait-duration-in-open-state:\r\n          seconds: 5s\r\n        permitted-number-of-calls-in-half-open-state: 6\r\n        ignore-exceptions:\r\n          - java.lang.IllegalCallerException\r\n        max-wait-duration-in-half-open-state:\r\n          seconds: 30s\r\n    configs:\r\n      default:\r\n        register-health-indicator: true\r\n        sliding-window-size: 50\r\n  timelimiter:\r\n    instances:\r\n      basic:\r\n        timeout-duration:\r\n          seconds: 1\r\n        cancel-running-future: true","resilience4jcircuitbreakerinstances#resilience4j.circuitbreaker.instances":"개별 circuitbreaker 들ㅇ르 설정합니다. 아래 코드에서는 basic 이라는 circuitbreaker 를 설정하고 있습니다.\nresilience4j:\r\n  circuitbreaker:\r\n    instances:\r\n      basic:\r\n        sliding-window-size: 10\r\n        failure-rate-threshold: 70\r\n        automatic-transition-from-open-to-half-open-enabled: true\r\n        wait-duration-in-open-state:\r\n          seconds: 5s\r\n        permitted-number-of-calls-in-half-open-state: 6\r\n        ignore-exceptions:\r\n          - java.lang.IllegalCallerException\r\n        max-wait-duration-in-half-open-state:\r\n          seconds: 30s\r\n    configs:\r\n    # ... \r\n  timelimiter:\r\n    # ... \nsliding-window-size : 호출 결과를 저장할 sliding window 입니다. 기본 사이즈는 100 입니다.\nfailure-rate-threshold : 몇번 실패해야 실패로 인정할지에 대한 백분율 비율입니다. 기본 값은 50 (퍼센트)입니다.\nautomatic-transition-from-open-to-half-open-enabled\nopen 에서 halfopen 으로 자동으로 전환하게끔 enable 하는 메서드입니다.\n기본값은 false 이지만 위에서는 enable 시켜서 true 가 되었습니다.\nwait-duration-in-open-state\nopen 에서 half open 으로 전환할 때 까지 필요한 시간(Duration)입니다.\n설정하지 않으면 기본값으로 설정되며 기본값은 60초 입니다.\npermitted-number-of-calls-in-half-open-state\nhalf open 상태에서 허용할 호출 수 입니다.\n기본값은 10 입니다.\nignore-exceptions\n서비스에서 exception 을 던지더라도 차단을 걸지 않고 허용할 exceptions 목록입니다.\nmax-wait-duration-in-half-open-state\nhalf open 상태에서 대기할 수 있는 최대시간 입니다.\n기본값은 0 입니다.","resilience4jtimelimiterinstances#resilience4j.timelimiter.instances":"resilience4j:\r\n  circuitbreaker:\r\n    # ... \r\n  timelimiter:\r\n    instances:\r\n      basic:\r\n        timeout-duration:\r\n          seconds: 1\r\n        cancel-running-future: true\ncancelRunningFuture\nFuture 가 진행중일 경우 cancel 할지 여부를 결정합니다. 기본 값은 true 입니다.\ntimeoutDuration\ntimeout 기준 시간입니다. 기본 값은 1초 입니다.","resilience4jcircuitbreakerconfigsdefault#resilience4j.circuitbreaker.configs.default":"resilience4j:\r\n  circuitbreaker:\r\n    # ...\r\n    configs:\r\n      default:\r\n        register-health-indicator: true\r\n        sliding-window-size: 50\r\n  timelimiter:\r\n    # ...\n이미 정의해둔 instance 들 중 매칭되는 것이 없을 경우 resilience4j.circuitbreaker.configs.default 에 설정해둔 속성을 사용하게 됩니다.","테스트-코드#테스트 코드":"","reactivehealthcheckservicejava#ReactiveHealthcheckService.java":"코드 : ReactiveHealthcheckService.java\n이번 테스트 코드에서 사용할 기능은 ReactiveHealthcheckService 내의 ready() 함수 기능입니다.장애가 걸리는 상황을 가정해서 테스트하 위해 인자값으로 delayMs 를 사용했습니다.자세한 설명은 주석으로 추가해두었습니다.흔히 백엔드 애플리케이션에서 actuator 또는 probe 를 위해 \"OK\" 등과 같은 문자열을 내보내는 ready(), readyWithId(...), readyWithException(...) 을 서킷브레이커로 감싼 클래스입니다.\npackage io.chagchagchag.example.foobar.reactive_circuit_breaker;\r\n\r\nimport io.chagchagchag.example.foobar.reactive_circuit_breaker.common.Ready;\r\nimport java.time.Duration;\r\nimport lombok.RequiredArgsConstructor;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport org.springframework.cloud.client.circuitbreaker.ReactiveCircuitBreakerFactory;\r\nimport org.springframework.stereotype.Service;\r\nimport reactor.core.publisher.Mono;\r\n\r\n@Slf4j\r\n@RequiredArgsConstructor\r\n@Service\r\npublic class ReactiveHealthcheckService {\r\n  private final ReactiveCircuitBreakerFactory healthCheckCircuitBreaker;\r\n  private final Ready ready;\r\n\r\n  private final String fallbackMessage = \"FoobarHealthCircuitBreaker Fallback\";\r\n\r\n  /**\r\n   * health 체크를 위한 \"OK (ServiceName)\" 문자열을 Mono 기반의 동시성 코드로 생성하는 공통 코드입니다.\r\n   * @param from SERVICE 명\r\n   * @param delayMs 지연할 시간\r\n   * @return\r\n   */\r\n  public Mono<String> delayedOk(String from, Long delayMs){\r\n    var duration = Duration.ofMillis(delayMs);\r\n    return Mono.delay(duration)\r\n        .then()\r\n        .then(Mono.fromCallable(() -> ready.ok(from)));\r\n  }\r\n\r\n  /**\r\n   * 다른 설정이 되지 않은 기본설정이 되어 있는 circuitBreaker 를 기반으로 ready() 함수에 대해 회로차단기를 걸어두었습니다.\r\n   * \"OK\" 신호를 내보내는 데에 delayMs 로 들어온 지연 시간이 걸리도록 합니다.\r\n   * 이때 CircuitBreaker 내의 허용된 지연시간, 실패 횟수, 슬라이딩윈도우, 실패율 등에 따라\r\n   * CircuitBreaker 가 이 기능을 차단할지, 차단하지 않을지를 결정하게 됩니다.\r\n   * @param from SERVICE 명\r\n   * @param delayMs 지연할 시간\r\n   * @return\r\n   */\r\n  public Mono<String> ready(String from, Long delayMs){\r\n    return delayedOk(from, delayMs)\r\n        .transform(it -> {\r\n          var cb = healthCheckCircuitBreaker.create(\"normal\");\r\n          return cb.run(it, throwable -> Mono.just(fallbackMessage));\r\n        });\r\n  }\r\n\r\n  /**\r\n   * \"OK\"신호를 내보낼 때 exception 이 발생하는 경우를 가정합니다.\r\n   * @param from SERVICE 명\r\n   * @return\r\n   */\r\n  public Mono<String> readyWithException(String from){\r\n    Mono<String> mono = Mono.error(new RuntimeException(\"Err\"));\r\n\r\n    return mono.transform(it -> {\r\n      var circuitBreaker = healthCheckCircuitBreaker.create(\"exception\");\r\n      return circuitBreaker\r\n          .run(it, throwable -> Mono.just(fallbackMessage));\r\n    });\r\n  }\r\n\r\n  /**\r\n   * \"OK\" 신호를 내보내는 기능을 특정 ID를 가진 서킷브레이커로 감쌉니다.\r\n   * @param id\r\n   * @param from SERVICE 명\r\n   * @param delayMs 지연할 시간\r\n   * @return\r\n   */\r\n  public Mono<String> readyWithId(String id, String from, Long delayMs){\r\n    return delayedOk(from, delayMs)\r\n        .transform(it -> {\r\n          var cb = healthCheckCircuitBreaker.create(id);\r\n          return cb.run(it, throwable -> Mono.just(fallbackMessage));\r\n        });\r\n  }\r\n\r\n  public Mono<String> readyWithIdAndGroup(\r\n      String id, String group, String from, Long delayMs\r\n  ){\r\n    return delayedOk(from, delayMs)\r\n        .transform(it -> {\r\n          var cb = healthCheckCircuitBreaker.create(id, group);\r\n          return cb.run(it, throwable -> Mono.just(fallbackMessage));\r\n        });\r\n  }\r\n}","testcircuitbreakerconfig#TestCircuitBreakerConfig":"서킷 브레이커 설정들을 모아둔 클래스입니다. 예제를 위한 용도여서 자바 기반 코드로 작성했습니다. yaml 기반 코드로 작성하는 것이 더 효율적인 경우도 있습니다. 이번 문서에서는 자바 설정 코드로 예제 테스트를 진행합니다.\npackage io.chagchagchag.example.foobar.reactive_circuit_breaker;\r\n\r\nimport io.github.resilience4j.circuitbreaker.CircuitBreaker;\r\nimport io.github.resilience4j.circuitbreaker.CircuitBreakerConfig;\r\nimport io.github.resilience4j.timelimiter.TimeLimiterConfig;\r\nimport java.time.Duration;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport org.springframework.boot.test.context.TestConfiguration;\r\nimport org.springframework.cloud.circuitbreaker.resilience4j.ReactiveResilience4JCircuitBreakerFactory;\r\nimport org.springframework.cloud.circuitbreaker.resilience4j.Resilience4JConfigBuilder;\r\nimport org.springframework.cloud.client.circuitbreaker.Customizer;\r\nimport org.springframework.context.annotation.Bean;\r\n\r\n@Slf4j\r\n@TestConfiguration\r\npublic class TestCircuitBreakerConfig {\r\n  @Bean\r\n  public Customizer<ReactiveResilience4JCircuitBreakerFactory> healthCheck(){\r\n    var circuitBreakerConfig = CircuitBreakerConfig.custom()\r\n        .slidingWindowSize(10)\r\n        .failureRateThreshold(75)\r\n        .enableAutomaticTransitionFromOpenToHalfOpen()\r\n        .waitDurationInOpenState(Duration.ofSeconds(5))\r\n        .permittedNumberOfCallsInHalfOpenState(6)\r\n        .ignoreExceptions(ArithmeticException.class)\r\n        .maxWaitDurationInHalfOpenState(Duration.ofSeconds(30))\r\n        .build();\r\n\r\n    var timeLimiterConfig = TimeLimiterConfig.custom()\r\n        .cancelRunningFuture(true)\r\n        .timeoutDuration(Duration.ofSeconds(3))\r\n        .build();\r\n\r\n    var circuitBreakerId = \"healthCheck\";\r\n\r\n    return factory -> {\r\n      factory.addCircuitBreakerCustomizer(loggingCustomizer(), circuitBreakerId);\r\n      factory.configure(builder -> {\r\n        builder\r\n            .circuitBreakerConfig(circuitBreakerConfig)\r\n            .timeLimiterConfig(timeLimiterConfig);\r\n      }, circuitBreakerId);\r\n    };\r\n  }\r\n\r\n  private Customizer<CircuitBreaker> loggingCustomizer(){\r\n    return Customizer.once(circuitBreaker -> {\r\n      var cbName = circuitBreaker.getName();\r\n      circuitBreaker.getEventPublisher()\r\n          .onSuccess(event -> log.info(\"circuit breaker ({}) success\", cbName))\r\n          .onError(event -> log.info(\"circuit breaker ({}) error ===> {}\", cbName, event.getThrowable().toString()))\r\n          .onStateTransition(event -> {\r\n            log.info(\"circuit breaker ({}) changed from {} to {}\",\r\n                cbName,\r\n                event.getStateTransition().getFromState(),\r\n                event.getStateTransition().getToState());\r\n          })\r\n          .onSlowCallRateExceeded(event ->\r\n              log.info(\"circuit breaker ({}) slow call rate exceeded ===> {}\",\r\n                  cbName, event.getSlowCallRate()))\r\n          .onFailureRateExceeded(event ->\r\n              log.info(\"circuit breaker ({}) failure rate exceeded ===> {}\",\r\n                  cbName, event.getFailureRate()));\r\n\r\n    }, CircuitBreaker::getName);\r\n  }\r\n\r\n  @Bean\r\n  public Customizer<ReactiveResilience4JCircuitBreakerFactory> defaultCustomizer(){\r\n    return factory -> {\r\n      factory.configureDefault(id -> {\r\n        factory.addCircuitBreakerCustomizer(loggingCustomizer(), id);\r\n        return new Resilience4JConfigBuilder(id)\r\n            .circuitBreakerConfig(CircuitBreakerConfig.ofDefaults())\r\n            .build();\r\n      });\r\n    };\r\n  }\r\n\r\n  @Bean\r\n  public Customizer<ReactiveResilience4JCircuitBreakerFactory> tinyCustomizer(){\r\n    var cbConfig = CircuitBreakerConfig.custom()\r\n        .failureRateThreshold(50)\r\n        .slidingWindowSize(3)\r\n        .build();\r\n\r\n    var targets = new String[]{\"tiny\"};\r\n    return factory -> {\r\n      factory.addCircuitBreakerCustomizer(loggingCustomizer(), targets);\r\n      factory.configure(\r\n          builder -> builder.circuitBreakerConfig(cbConfig),\r\n          targets\r\n      );\r\n    };\r\n  }\r\n\r\n  @Bean\r\n  public Customizer<ReactiveResilience4JCircuitBreakerFactory> autoHalf(){\r\n    var cbConfig = CircuitBreakerConfig.custom()\r\n        .failureRateThreshold(50)\r\n        .slidingWindowSize(3)\r\n        .enableAutomaticTransitionFromOpenToHalfOpen() // auto half 설정\r\n        .waitDurationInOpenState(Duration.ofSeconds(5))\r\n        .build();\r\n\r\n    var targets = new String[]{\"autoHalf\"};\r\n    return factory -> {\r\n      factory.addCircuitBreakerCustomizer(\r\n          loggingCustomizer(), targets);\r\n      factory.configure(builder -> {\r\n        builder.circuitBreakerConfig(cbConfig);\r\n      }, targets);\r\n    };\r\n  }\r\n\r\n  @Bean\r\n  public Customizer<ReactiveResilience4JCircuitBreakerFactory> halfOpen() {\r\n    var cbConfig = CircuitBreakerConfig.custom()\r\n        .failureRateThreshold(50)\r\n        .slidingWindowSize(3)\r\n        .enableAutomaticTransitionFromOpenToHalfOpen()\r\n        .waitDurationInOpenState(Duration.ofSeconds(3))\r\n        .permittedNumberOfCallsInHalfOpenState(6) //\r\n        .build();\r\n\r\n    var targets = new String[]{\"halfOpen\"};\r\n\r\n    return factory -> {\r\n      factory.addCircuitBreakerCustomizer(loggingCustomizer(), targets);\r\n      factory.configure(\r\n          builder -> builder.circuitBreakerConfig(cbConfig),\r\n          targets\r\n      );\r\n    };\r\n  }\r\n}","delay-없을-때-circuitbreaker-가-구동되는지-테스트#Delay 없을 때 CircuitBreaker 가 구동되는지 테스트":"간단한 몸풀기 용도의 예제입니다.\n@Slf4j\r\n@Import(TestCircuitBreakerConfig.class)\r\n@ImportAutoConfiguration(\r\n    classes = {\r\n        ReactiveResilience4JAutoConfiguration.class,\r\n        Resilience4JAutoConfiguration.class,\r\n        CircuitBreakerAutoConfiguration.class,\r\n        TimeLimiterAutoConfiguration.class\r\n    }\r\n)\r\n@SpringBootTest\r\npublic class HealthCheckCircuitBreakerTest {\r\n  @Autowired\r\n  private ReactiveHealthcheckService reactiveHealthcheckService;\r\n  @Autowired\r\n  private CircuitBreakerRegistry circuitBreakerRegistry;\r\n  @SpyBean\r\n  private Ready ready;\r\n\r\n  String fallbackMessage = \"FoobarHealthCircuitBreaker Fallback\";\r\n    \r\n  @DisplayName(\"READY_WITHOUT_DELAY\")\r\n  @Test\r\n  public void TEST_READY_WITHOUT_DELAY(){\r\n    // given\r\n    var serviceName = \"order-service\";\r\n    var expectedMessage = String.format(\"OK (%s)\", serviceName);\r\n\r\n    // when\r\n    var mono = reactiveHealthcheckService.ready(serviceName, 0L);\r\n\r\n    // then\r\n    StepVerifier.create(mono)\r\n        .expectNext(expectedMessage)\r\n        .verifyComplete();\r\n\r\n    Mockito.verify(ready).ok(serviceName);\r\n  }\r\n  \r\n  // ...\r\n\r\n}","close--open#Close → Open":"테스트로 사용한 서킷브레이커의 설정은 아래와 같습니다.\n@Slf4j\r\n@TestConfiguration\r\npublic class TestCircuitBreakerConfig {\r\n  // ...\r\n  \r\n  @Bean\r\n  public Customizer<ReactiveResilience4JCircuitBreakerFactory> tinyCustomizer(){\r\n    var cbConfig = CircuitBreakerConfig.custom()\r\n        .failureRateThreshold(50)\r\n        .slidingWindowSize(3)\r\n        .build();\r\n\r\n    var targets = new String[]{\"tiny\"};\r\n    return factory -> {\r\n      factory.addCircuitBreakerCustomizer(loggingCustomizer(), targets);\r\n      factory.configure(\r\n          builder -> builder.circuitBreakerConfig(cbConfig),\r\n          targets\r\n      );\r\n    };\r\n  }\r\n    \r\n  // ...\r\n    \r\n}\ntiny 라는 이름의 CircuitBreaker 를 이용해서 ready() 기능을 호출합니다. 주석으로 설명을 추가해두었기 때문에 자세한 설명은 생략하겠습니다.\n@Slf4j\r\n@Import(TestCircuitBreakerConfig.class)\r\n@ImportAutoConfiguration(\r\n    classes = {\r\n        ReactiveResilience4JAutoConfiguration.class,\r\n        Resilience4JAutoConfiguration.class,\r\n        CircuitBreakerAutoConfiguration.class,\r\n        TimeLimiterAutoConfiguration.class\r\n    }\r\n)\r\n@SpringBootTest\r\npublic class HealthCheckCircuitBreakerTest {\r\n  @Autowired\r\n  private ReactiveHealthcheckService reactiveHealthcheckService;\r\n  @Autowired\r\n  private CircuitBreakerRegistry circuitBreakerRegistry;\r\n  @SpyBean\r\n  private Ready ready;\r\n\r\n  String fallbackMessage = \"FoobarHealthCircuitBreaker Fallback\";\r\n  \r\n  // ...\r\n  \r\n  // tiny 회로차단기 ON 되는 테스트 케이스\r\n  @DisplayName(\"READY_METHOD_MAKE_CB_STATE_OPEN\")\r\n  @Test\r\n  public void TEST_READY_METHOD_MAKE_CB_STATE_OPEN(){\r\n    // given\r\n    String serviceName = \"order-service\";\r\n    String successMessage = String.format(\"OK (%s)\", serviceName);\r\n    String expectedMessage = fallbackMessage;\r\n\r\n    // when (delay 없는 call 은 성공, 3개의 call 실행, Sliding Window 채우기 위한 용도)\r\n    for(int i=0; i<3; i++){\r\n      StepVerifier.create(reactiveHealthcheckService.readyWithId(\"tiny\", serviceName, 0L))\r\n          .expectNext(successMessage)\r\n          .verifyComplete();\r\n    }\r\n\r\n    // then (5s delay call 을 2번 실행 -> 50% 실패 -> circuit breaker closed)\r\n    for(int i=0; i<2; i++){\r\n      StepVerifier\r\n          .withVirtualTime(()->reactiveHealthcheckService.readyWithId(\"tiny\", serviceName, 7000L))\r\n          .thenAwait(Duration.ofSeconds(2))\r\n          .expectNext(expectedMessage)\r\n          .verifyComplete();\r\n    }\r\n\r\n    for(int i=0; i<100; i++){\r\n      StepVerifier\r\n          .create(reactiveHealthcheckService.readyWithId(\"tiny\", serviceName, 0L))\r\n          .expectNext(expectedMessage)\r\n          .verifyComplete();\r\n    }\r\n\r\n    Mockito.verify(ready, Mockito.times(3)).ok(serviceName);\r\n  }\r\n  \r\n  // ...\r\n\r\n}","open--half-open-1#Open → Half Open":"","수동전환-하드코딩으로-half-state-로-전환#(수동전환) 하드코딩으로 Half State 로 전환":"추천되는 방식은 아닙니다.테스트에서 사용하는 서킷브레이커 설정은 아래와 같습니다.\n@Slf4j\r\n@TestConfiguration\r\npublic class TestCircuitBreakerConfig {\r\n  // ...\r\n  \r\n  @Bean\r\n  public Customizer<ReactiveResilience4JCircuitBreakerFactory> tinyCustomizer(){\r\n    var cbConfig = CircuitBreakerConfig.custom()\r\n        .failureRateThreshold(50)\r\n        .slidingWindowSize(3)\r\n        .build();\r\n\r\n    var targets = new String[]{\"tiny\"};\r\n    return factory -> {\r\n      factory.addCircuitBreakerCustomizer(loggingCustomizer(), targets);\r\n      factory.configure(\r\n          builder -> builder.circuitBreakerConfig(cbConfig),\r\n          targets\r\n      );\r\n    };\r\n  }\r\n    \r\n  // ...\r\n    \r\n}\n테스트 코드는 아래와 같습니다.\n@Slf4j\r\n@Import(TestCircuitBreakerConfig.class)\r\n@ImportAutoConfiguration(\r\n    classes = {\r\n        ReactiveResilience4JAutoConfiguration.class,\r\n        Resilience4JAutoConfiguration.class,\r\n        CircuitBreakerAutoConfiguration.class,\r\n        TimeLimiterAutoConfiguration.class\r\n    }\r\n)\r\n@SpringBootTest\r\npublic class HealthCheckCircuitBreakerTest {\r\n  @Autowired\r\n  private ReactiveHealthcheckService reactiveHealthcheckService;\r\n  @Autowired\r\n  private CircuitBreakerRegistry circuitBreakerRegistry;\r\n  @SpyBean\r\n  private Ready ready;\r\n\r\n  String fallbackMessage = \"FoobarHealthCircuitBreaker Fallback\";\r\n  \r\n  // ...\r\n  \r\n  // 회로차단기 OPEN (ON) 상태 -> HALF OPEN 상태 테스트 케이스\r\n  @DisplayName(\"\")\r\n  @Test\r\n  public void (){\r\n    // given\r\n    String serviceName = \"order-service\";\r\n    String successMessage = String.format(\"OK (%s)\", serviceName);\r\n\r\n    // 차단(OPEN, ON) 된 차단기 준비\r\n    for(int i=0; i<3; i++){\r\n      StepVerifier.withVirtualTime(()->reactiveHealthcheckService.readyWithId(\"tiny\", serviceName, 5000L))\r\n          .thenAwait(Duration.ofSeconds(2))\r\n          .expectNext(fallbackMessage)\r\n          .verifyComplete();\r\n    }\r\n\r\n    // when\r\n    var tinyCb = circuitBreakerRegistry.circuitBreaker(\"tiny\");\r\n    tinyCb.transitionToHalfOpenState();\r\n    log.info(\"Half Open 상태로 전환 완료\");\r\n\r\n    // then\r\n    var state = circuitBreakerRegistry.circuitBreaker(\"tiny\").getState();\r\n    Assertions.assertThat(state).isEqualTo(CircuitBreaker.State.HALF_OPEN);\r\n\r\n    StepVerifier.create(reactiveHealthcheckService.readyWithId(\"tiny\", serviceName, 0L))\r\n        .expectNext(successMessage)\r\n        .verifyComplete();\r\n  }\r\n  \r\n  // ...\r\n\r\n}","자동전환-일정-시간-동안-circuitbreaker-가-기다린-후-체크하도록-하는-방식#(자동전환) 일정 시간 동안 CircuitBreaker 가 기다린 후 체크하도록 하는 방식":"CircuitBreaker 설정 코드에서는 autoHalf 라는 설정이 있는데 아래와 같이 설정했습니다.\n@Slf4j\r\n@TestConfiguration\r\npublic class TestCircuitBreakerConfig {\r\n  // ...\r\n  \r\n  @Bean\r\n  public Customizer<ReactiveResilience4JCircuitBreakerFactory> autoHalf(){\r\n    var cbConfig = CircuitBreakerConfig.custom()\r\n        .failureRateThreshold(50)\r\n        .slidingWindowSize(3)\r\n        .enableAutomaticTransitionFromOpenToHalfOpen() // auto half 설정\r\n        .waitDurationInOpenState(Duration.ofSeconds(5))\r\n        .build();\r\n\r\n    var targets = new String[]{\"autoHalf\"};\r\n    return factory -> {\r\n      factory.addCircuitBreakerCustomizer(\r\n          loggingCustomizer(), targets);\r\n      factory.configure(builder -> {\r\n        builder.circuitBreakerConfig(cbConfig);\r\n      }, targets);\r\n    };\r\n  }\n테스트 코드는 아래와 같습니다.\n@Slf4j\r\n@Import(TestCircuitBreakerConfig.class)\r\n@ImportAutoConfiguration(\r\n    classes = {\r\n        ReactiveResilience4JAutoConfiguration.class,\r\n        Resilience4JAutoConfiguration.class,\r\n        CircuitBreakerAutoConfiguration.class,\r\n        TimeLimiterAutoConfiguration.class\r\n    }\r\n)\r\n@SpringBootTest\r\npublic class HealthCheckCircuitBreakerTest {\r\n  @Autowired\r\n  private ReactiveHealthcheckService reactiveHealthcheckService;\r\n  @Autowired\r\n  private CircuitBreakerRegistry circuitBreakerRegistry;\r\n  @SpyBean\r\n  private Ready ready;\r\n    \r\n  // ...\r\n    \r\n  @SneakyThrows\r\n  @DisplayName(\"\")\r\n  @Test\r\n  public void (){\r\n    // given\r\n    String serviceName = \"order-service\";\r\n    String successMessage = String.format(\"OK (%s)\", serviceName);\r\n\r\n    // 회로차단기가 ON (OPEN) 되도록 지연을 유발하는 CALL 호출 3회 수행\r\n    for(int i=0; i<3; i++){\r\n      StepVerifier\r\n          .withVirtualTime(()-> reactiveHealthcheckService.readyWithId(\"autoHalf\", serviceName, 5000L))\r\n          .thenAwait(Duration.ofSeconds(3))\r\n          .expectNext(fallbackMessage)\r\n          .verifyComplete();\r\n    }\r\n\r\n    // when\r\n    log.info(\"7초 대기\");\r\n    Thread.sleep(7000);\r\n\r\n    // then\r\n    var state = circuitBreakerRegistry.circuitBreaker(\"autoHalf\").getState();\r\n    Assertions.assertThat(state).isEqualTo(CircuitBreaker.State.HALF_OPEN);\r\n\r\n    StepVerifier.create(reactiveHealthcheckService.readyWithId(\"autoHalf\", serviceName, 0L))\r\n        .expectNext(successMessage)\r\n        .verifyComplete();\r\n  }\r\n \r\n  // ...\r\n}","half-open--close#Half Open → Close":"테스트를 위해 사용하는 서킷브레이커 설정은 아래와 같습니다.\n@Slf4j\r\n@TestConfiguration\r\npublic class TestCircuitBreakerConfig {\r\n  // ...\r\n  \r\n  @Bean\r\n  public Customizer<ReactiveResilience4JCircuitBreakerFactory> halfOpen() {\r\n    var cbConfig = CircuitBreakerConfig.custom()\r\n        .failureRateThreshold(50)\r\n        .slidingWindowSize(3)\r\n        .enableAutomaticTransitionFromOpenToHalfOpen()\r\n        .waitDurationInOpenState(Duration.ofSeconds(3))\r\n        .permittedNumberOfCallsInHalfOpenState(6) //\r\n        .build();\r\n\r\n    var targets = new String[]{\"halfOpen\"};\r\n\r\n    return factory -> {\r\n      factory.addCircuitBreakerCustomizer(loggingCustomizer(), targets);\r\n      factory.configure(\r\n          builder -> builder.circuitBreakerConfig(cbConfig),\r\n          targets\r\n      );\r\n    };\r\n  }\r\n  \r\n  // ...   \r\n}\n테스트코드입니다.\n@Slf4j\r\n@Import(TestCircuitBreakerConfig.class)\r\n@ImportAutoConfiguration(\r\n    classes = {\r\n        ReactiveResilience4JAutoConfiguration.class,\r\n        Resilience4JAutoConfiguration.class,\r\n        CircuitBreakerAutoConfiguration.class,\r\n        TimeLimiterAutoConfiguration.class\r\n    }\r\n)\r\n@SpringBootTest\r\npublic class HealthCheckCircuitBreakerTest {\r\n  @Autowired\r\n  private ReactiveHealthcheckService reactiveHealthcheckService;\r\n  @Autowired\r\n  private CircuitBreakerRegistry circuitBreakerRegistry;\r\n  @SpyBean\r\n  private Ready ready;\r\n\r\n  String fallbackMessage = \"FoobarHealthCircuitBreaker Fallback\";\r\n  \r\n  // ...\r\n\r\n  // half open -> close (차단기 OFF)\r\n  @SneakyThrows\r\n  @DisplayName(\"\")\r\n  @Test\r\n  public void (){\r\n    // given\r\n    String serviceName = \"order-service\";\r\n    String successMessage = String.format(\"OK (%s)\", serviceName);\r\n    String cbId = \"halfOpen\";\r\n\r\n    for(int i=0; i<3; i++){\r\n      StepVerifier.withVirtualTime(() -> reactiveHealthcheckService.readyWithId(cbId, serviceName, 5000L))\r\n          .thenAwait(Duration.ofSeconds(2))\r\n          .expectNext(fallbackMessage)\r\n          .verifyComplete();\r\n    }\r\n\r\n    log.info(\"3초 대기\");\r\n    Thread.sleep(3000);\r\n\r\n    // when\r\n    var successCnt = 4;\r\n    var failCnt = 2;\r\n    var total = successCnt + failCnt;\r\n\r\n    // 1) 4번 성공시킴\r\n    for(int i=0; i<successCnt; i++){\r\n      StepVerifier.withVirtualTime(() -> reactiveHealthcheckService.readyWithId(cbId, serviceName, 0L))\r\n          .expectNext(successMessage)\r\n          .verifyComplete();\r\n    }\r\n    // 2) 2번 실패 시킴\r\n    for(int i=0; i<failCnt; i++){\r\n      StepVerifier.withVirtualTime(() -> reactiveHealthcheckService.readyWithId(cbId, serviceName, 5000L))\r\n          .thenAwait(Duration.ofSeconds(2))\r\n          .expectNext(fallbackMessage)\r\n          .verifyComplete();\r\n    }\r\n\r\n    // then\r\n    var state = circuitBreakerRegistry\r\n        .circuitBreaker(cbId)\r\n        .getState();\r\n\r\n    Assertions.assertThat(state).isEqualTo(CircuitBreaker.State.CLOSED);\r\n  }\r\n\r\n  // ...\r\n  \r\n}","half-open--open#Half Open → Open":"테스트를 위해 사용하는 서킷브레이커 설정은 아래와 같습니다.\n@Slf4j\r\n@TestConfiguration\r\npublic class TestCircuitBreakerConfig {\r\n  // ...\r\n  \r\n  @Bean\r\n  public Customizer<ReactiveResilience4JCircuitBreakerFactory> halfOpen() {\r\n    var cbConfig = CircuitBreakerConfig.custom()\r\n        .failureRateThreshold(50)\r\n        .slidingWindowSize(3)\r\n        .enableAutomaticTransitionFromOpenToHalfOpen()\r\n        .waitDurationInOpenState(Duration.ofSeconds(3))\r\n        .permittedNumberOfCallsInHalfOpenState(6) //\r\n        .build();\r\n\r\n    var targets = new String[]{\"halfOpen\"};\r\n\r\n    return factory -> {\r\n      factory.addCircuitBreakerCustomizer(loggingCustomizer(), targets);\r\n      factory.configure(\r\n          builder -> builder.circuitBreakerConfig(cbConfig),\r\n          targets\r\n      );\r\n    };\r\n  }\r\n  \r\n  // ...   \r\n}\n테스트코드입니다.\n@Slf4j\r\n@Import(TestCircuitBreakerConfig.class)\r\n@ImportAutoConfiguration(\r\n    classes = {\r\n        ReactiveResilience4JAutoConfiguration.class,\r\n        Resilience4JAutoConfiguration.class,\r\n        CircuitBreakerAutoConfiguration.class,\r\n        TimeLimiterAutoConfiguration.class\r\n    }\r\n)\r\n@SpringBootTest\r\npublic class HealthCheckCircuitBreakerTest {\r\n  @Autowired\r\n  private ReactiveHealthcheckService reactiveHealthcheckService;\r\n  @Autowired\r\n  private CircuitBreakerRegistry circuitBreakerRegistry;\r\n  @SpyBean\r\n  private Ready ready;\r\n\r\n  String fallbackMessage = \"FoobarHealthCircuitBreaker Fallback\";\r\n  \r\n  // ...\r\n  \r\n  // half open -> open (차단기 ON)\r\n  @SneakyThrows\r\n  @DisplayName(\"READY_METHOD_MAKE_CB_STATE_FROM_HALF_OPEN_TO_OPEN\")\r\n  @Test\r\n  public void (){\r\n    // given\r\n    String serviceName = \"order-service\";\r\n    String successMessage = String.format(\"OK (%s)\", serviceName);\r\n    String cbId = \"halfOpen\";\r\n\r\n    for(int i=0; i<3; i++){\r\n      StepVerifier\r\n          .withVirtualTime(() -> reactiveHealthcheckService.readyWithId(cbId, serviceName, 5000L))\r\n          .thenAwait(Duration.ofSeconds(2))\r\n          .expectNext(fallbackMessage)\r\n          .verifyComplete();\r\n    }\r\n\r\n    log.info(\"3초 대기\");\r\n    Thread.sleep(3000);\r\n\r\n    // when (실패율 50% 로 조정)\r\n    var successCnt = 3;\r\n    var failCnt = 3;\r\n    var total = successCnt + failCnt;\r\n\r\n    for(int i=0; i<successCnt; i++){\r\n      StepVerifier\r\n          .create(reactiveHealthcheckService.readyWithId(cbId, serviceName, 0L))\r\n          .expectNext(successMessage)\r\n          .verifyComplete();\r\n    }\r\n\r\n    for(int i=0; i<failCnt; i++){\r\n      StepVerifier\r\n          .withVirtualTime(() -> reactiveHealthcheckService.readyWithId(cbId, serviceName, 5000L))\r\n          .thenAwait(Duration.ofSeconds(2))\r\n          .expectNext(fallbackMessage)\r\n          .verifyComplete();\r\n    }\r\n\r\n    // then\r\n    var state = circuitBreakerRegistry.circuitBreaker(cbId)\r\n        .getState();\r\n    Assertions.assertThat(state).isEqualTo(CircuitBreaker.State.OPEN);\r\n  }\r\n}"}},"/spring-cloud-stream-and-kafka/spring-cloud-stream-kafka-binder":{"title":"Spring Cloud Stream Kafka Binder","data":{"spring-cloud-stream-kafka-binder#Spring Cloud Stream Kafka Binder":"","참고#참고":"Spring Cloud Stream Reference Guide\ndocs.spring.io - spring cloud stream / Spring Cloud Function Support\ndocs.spring.io - Producing and Consuming Messages\nspring-cloud-stream/Spring Cloud Stream Reference Documentation/Testing\nStreaming with Spring Cloud\nIntroduction to Spring Cloud Stream\nGuide to Spring Cloud Stream with Kafka, Apache Avro and Confluent Schema Registry","spring-cloud-stream-kafka-binder-란#Spring Cloud Stream Kafka Binder 란?":"설명 추가 예정","도커-구동#도커 구동":"개발 용도의 카프카를 로컬에서 구동해서 결과를 확인하시려면 Docker Compose 을 참고해주세요.","예제-시나리오#예제 시나리오":"설명 추가 예정","의존성-추가#의존성 추가":"extra[\"springCloudVersion\"] = \"2023.0.0\"\r\n\r\ndependencies {\r\n    // spring-cloud-stream\r\n    implementation(\"org.springframework.cloud:spring-cloud-stream\")\r\n    testImplementation(\"org.springframework.cloud:spring-cloud-stream-test-binder\")\r\n    \r\n\t// spring-cloud-stream-binder-kafka\r\n    implementation(\"org.springframework.cloud:spring-cloud-stream-binder-kafka\")\r\n    \r\n    // ...\r\n}\r\n\r\ndependencyManagement {\r\n  imports {\r\n    mavenBom(\"org.springframework.cloud:spring-cloud-dependencies:${property(\"springCloudVersion\")}\")\r\n  }\r\n}","applicationyml#application.yml":"위의 그림과 같은 입력 출력을 갖도록 하기 위해 Spring Cloud Stream 의 bindings 를 작성해주고 kakfa 에 대한 binder 와 bindings 를 작성해줍니다.아래 3개의 속성들에 대해 세부 속성들을 설정합니다.\nspring.cloud.stream.kafka.binder\nspring.cloud.stream.kafka.bindings\nspring.cloud.stream.bindings\nspring:\r\n  cloud:\r\n    function:\r\n      definition: livenessCheck;appendCurrTime;logLiveness\r\n    stream:\r\n      kafka:\r\n        binder:\r\n          brokers: localhost:9092,localhost:9093,localhost:9094\r\n        bindings:\r\n          appendCurrTime-in-0:\r\n            consumer:\r\n              start-offset: latest\r\n          logLiveness-in-0:\r\n            consumer:\r\n              start-offset: earliest\r\n      bindings:\r\n        livenessCheck-out-0:\r\n          binder: kafka\r\n          destination: liveness\r\n          content-type: text/plain\r\n        appendCurrTime-in-0:\r\n          binder: kafka\r\n          destination: liveness\r\n          content-type: text/plain\r\n        appendCurrTime-out-0:\r\n          binder: kafka\r\n          destination: liveness_history\r\n          content-type: text/plain\r\n        logLiveness-in-0:\r\n          binder: kafka\r\n          destination: liveness\r\n          content-type: text/plain","springcloudfunctiondefinition#spring.cloud.function.definition":"spring:\r\n  cloud:\r\n    function:\r\n      definition: livenessCheck;appendCurrTime;logLiveness\r\n    stream:\r\n      kafka:\r\n        binder:\r\n          # ...\r\n        bindings:\r\n          # ...\r\n      bindings:\r\n        # ...","springcloudstreamkafkabinder#spring.cloud.stream.kafka.binder":"설명 추가 예정\nspring:\r\n  cloud:\r\n  \tfunction:\r\n      definition: # ...\r\n    stream:\r\n      kafka:\r\n        binder:\r\n          brokers: localhost:9092,localhost:9093,localhost:9094\r\n        # ...\r\n      bindings:\r\n        # ...","springcloudstreamkafkabindings#spring.cloud.stream.kafka.bindings":"설명 추가 예정\nspring:\r\n  cloud:\r\n  \tfunction:\r\n      definition: # ...\r\n    stream:\r\n      kafka:\r\n        binder:\r\n          # ...\r\n        bindings:\r\n          appendCurrTime-in-0:\r\n            consumer:\r\n              start-offset: latest\r\n          logLiveness-in-0:\r\n            consumer:\r\n              start-offset: earliest\r\n      bindings:\r\n        # ...","springcloudstreambindings#spring.cloud.stream.bindings":"설명 추가 예정\nspring:\r\n  cloud:\r\n  \tfunction:\r\n      definition: # ...\r\n    stream:\r\n      kafka:\r\n        binder:\r\n          # ...\r\n        bindings:\r\n          # ...\r\n      bindings:\r\n        livenessCheck-out-0:\r\n          binder: kafka\r\n          destination: liveness\r\n          content-type: text/plain\r\n        appendCurrTime-in-0:\r\n          binder: kafka\r\n          destination: liveness\r\n          content-type: text/plain\r\n        appendCurrTime-out-0:\r\n          binder: kafka\r\n          destination: liveness_history\r\n          content-type: text/plain\r\n        logLiveness-in-0:\r\n          binder: kafka\r\n          destination: liveness\r\n          content-type: text/plain","streamfunctionconfigjava#StreamFunctionConfig.java":"위의 그림과 같은 입력, 출력을 위한 Supplier, Function, Consumer 정의입니다.\npackage io.chagchagchag.example.foobar.spring_cloud_stream_kafka.config;\r\n\r\nimport io.chagchagchag.example.foobar.spring_cloud_stream_kafka.LogComponent;\r\nimport java.time.Duration;\r\nimport java.time.LocalDateTime;\r\nimport java.util.function.Consumer;\r\nimport java.util.function.Function;\r\nimport java.util.function.Supplier;\r\nimport lombok.RequiredArgsConstructor;\r\nimport org.springframework.context.annotation.Bean;\r\nimport org.springframework.context.annotation.Configuration;\r\nimport reactor.core.publisher.Flux;\r\nimport reactor.core.publisher.Mono;\r\n\r\n@RequiredArgsConstructor\r\n@Configuration\r\npublic class StreamFunctionsConfig {\r\n  private final LogComponent logComponent;\r\n  @Bean\r\n  public Supplier<Flux<String>> livenessCheck(){\r\n    return () -> Mono\r\n        .delay(Duration.ofSeconds(10))\r\n        .thenMany(Flux.just(\"OK\"));\r\n  }\r\n\r\n  @Bean\r\n  public Function<Flux<String>, Flux<String>> appendCurrTime(){\r\n    return fluxString -> fluxString.handle((str, sink) -> {\r\n      try{\r\n        var currTime = LocalDateTime.now().toString();\r\n        sink.next(String.format(\"%s ####### %s\", currTime, str));\r\n      }\r\n      catch (Exception e){\r\n        e.printStackTrace();\r\n        sink.error(new IllegalStateException(\"stringToBigDecimal Error\"));\r\n      }\r\n    });\r\n  }\r\n\r\n  @Bean\r\n  public Consumer<Flux<String>> logLiveness(){\r\n    return strFlux -> strFlux.subscribe(str -> logComponent.info(str));\r\n  }\r\n\r\n}","logcomponentjava#LogComponent.java":"위의 코드에서 주입받았던 LogComponent 코드는 아래와 같습니다.\npackage io.chagchagchag.example.foobar.spring_cloud_stream_kafka;\r\n\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport org.springframework.stereotype.Component;\r\n\r\n@Slf4j\r\n@Component\r\npublic class LogComponent {\r\n  public void info(String msg){\r\n    log.info(msg);\r\n  }\r\n}","애플리케이션-실행--동작-확인#애플리케이션 실행 & 동작 확인":"","springcloudstreamkafkaapplication#SpringCloudStreamKafkaApplication":"애플리케이션 코드를 실행합니다.\npackage io.chagchagchag.example.foobar.spring_cloud_stream_kafka;\r\n\r\nimport org.springframework.boot.SpringApplication;\r\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\r\n\r\n@SpringBootApplication\r\npublic class SpringCloudStreamKafkaApplication {\r\n  public static void main(String[] args) {\r\n    SpringApplication.run(SpringCloudStreamKafkaApplication.class, args);\r\n  }\r\n}","ok-로그-확인#ok 로그 확인":"애플리케이션 로그가 로딩 시에 아래와 같이 잘 나타나는지 확인합니다.","카프카-토픽-확인#카프카 토픽 확인":"","토픽-생성-확인#토픽 생성 확인":"","liveness-토픽-확인#liveness 토픽 확인":"","livenss_history-토픽-확인#livenss_history 토픽 확인":"데이터가 정상적으로 저장되어 있음을 확인 가능합니다."}},"/spring-webflux/codec":{"title":"Codec","data":{"codec#Codec":"Codec 은 어떤 타입의 객체를 다른 타입의 객체로 변환해주는 기능을 의미합니다. 주로 -Encoder, -Decoder 라는 접두사가 붙는 경우가 많습니다. Spring Webflux 외에도 Spring MVC, JPA, Spring Reactive MongoDB, Spring Dat aR2DBC, 메시징 등에서 커스텀 자료형 변환을 위해 널리 인식되는 개념들입니다.","내부-동작#내부 동작":"이전 문서에서 살펴봤듯 DispatchHandler 는 HandlerAdapter 의 handle() 메서드를 호출해서 요청을 처리합니다. 만약 일반적인 웹 요청이라면 일반적으로 HttpWebHandlerAdapter 의 handle() 메서드를 사용하게 됩니다.그리고 handle() 메서드 내부에서는 createExchange(req, resp) 메서드를 호출해서 ServerWebExchange 객체를 생성합니다. 객체 생성시에 DefaultServerWebExchange 객체로 생성하는데 이때 HttpWebHandlerAdapter 내부의 codecConfigurer 를 인자값으로 전달해주는 것을 확인 가능합니다.\nDefaultServerWebExchange 에서는 객체 생성의 생성자는 아래와 같습니다.Form Data 또는 Multipart Data 에 대해서 codecConfigurer 와 request 를 기반으로 Mono<MultiValueMap<String, String>> 객체로 만들어서 formDataMono, multipartDataMono 와 같은 필드들을 초기화합니다.\ninitFormData() 메서드의 내부를 보면 적절한 Reader 객체로 만들고 이것을 기반으로 Mono<MultiValueMap<String, String>> 타입의 데이터를 만들어서 return 하고 있습니다.\nDefaultServerWebExchange 클래스 내의 getReader() 메서드 내의 구현을 보면 아래와 같습니다. configurer 내에 등록된 여러 종류의 Reader 를 순회하면서 원하는 타입을 읽을수 있는지 없는지를 체크 후 찾았다면 해당 Reader 를 반환하는 방식입니다. 이 코드를 통해 알 수 있는 것은 \"각각의 개별 CodecConfigurer는 자기 자신에 맞는 Reader 들을 여러 종류로 가지고 있다.\" 라는 것을 확인 가능합니다.","decoder-reader#Decoder, Reader":"Spring Webflux 에서 자주 쓰이는 대표적인 Decoder, Reader 들을 정리해봅니다.","기본자료형-decoder#기본자료형 Decoder":"ByteArrayDecoder : DataBuffer 를 byte array 로 decode 하는 decoder 입니다.\nByteBufferDecoder : DataBuffer 를 java.nio.ByteBuffer 로 decode 하는 decoder 입니다.\nDataBufferDecoder : DataBuffer 를 DataBuffer 로 decode 하는 decoder 입니다.\nNettyByteBufDecoder : DataBuffer 를 io.netty.buffer.ByteBuf 로 decode 하는 decoder 입니다.\nResourceDecoder : DataBuffer 를 Spring 의 Resource 로 decode 하는 decoder 입니다.\nStringDecoder : DataBuffer 를 String 으로 decode 하는 decoder 입니다.\nProtobufDecoder : DataBuffer 를 com.google.protobuf.Message 로 decode 하는 decoder 입니다. decode.google.protobuf 라이브러리가 있을 때에만 등록됩니다.","객체-serialization-관련-decoder#객체 Serialization 관련 Decoder":"Jackson2JsonDecoder : jackson 라이브러리로 json 형태의 DataBuffer 를 객체로 decode 하는 Decoder 입니다. jackson 라이브러리가 있을 때에만 등록됩니다.\nKotlinSerializationJsonDecoder : kotlinx.serialization 라이브러리를 사용해서 json 형태의 DataBuffer 를 특정 객체 타입으로 decode 하는 decoder 입니다. kotlinx.serialization 라이브러리가 잇을 때에만 등록됩니다.\nJackson2SmileDecoder : jackson 라이브러리를 사용해서 smail 형태의 DataBuffer 를 객체로 decode 하는 Decoder 입니다. jackson-smile 라이브러리가 있을 경우에만 등록됩니다.\nJaxb2XmlDecoder : jaxb 를 사용해서 xml 형태의 DataBuffer 를 객체로 decode 하는 Decoder 입니다. jaxb 라이브러리가 있을 경우에만 등록됩니다.","reader#Reader":"FormHttpMessaeReader : application/x-www-form-urlencoded 인 MediaType 에 대해 form 을 MultiValueMap<String, String> 형태로 읽어들이는 Reader 입니다.\nDefaultPartHttpMessageReader : multipart/form-data 인 MediaType 에 대해 Part 를 stream 형태로 읽어들이는 Reader 입니다.\nMultipartHttpMessageReader : multipart/form-data 인 MediaType 에 대해 MultiValueMap<String, String> 형태로 읽어들이는 Reader 입니다.","encoder-writer#Encoder, Writer":"Spring Webflux 에서 자주 쓰이는 대표적인 Encoder, Writer 들을 정리해봅니다.","기본자료형-encoder#기본자료형 Encoder":"ByteArrayEncoder : byte array 를 DataBuffer 로 encode 하는 Encoder 입니다.\nByteBufferEncoder : java.nio.ByteBuffer 를 DataBuffer 로 encode 하는 Encoder 입니다.\nDataBufferEncoder : DataBuffer 를 DataBuffer 로 encode 하는 Encoder 입니다.\nNettyByteBufEncoder : io.netty.buffer.ByteBuf 를 DataBuffer 로 encode 하는 Encoder 입니다.\nCharSequenceEncoder : CharSequence 를 DataBuffer 로 encode 하는 Encoder 입니다.","객체-serializaion-관련-encoder#객체 Serializaion 관련 Encoder":"Jackson2JsonEncoder : jackson 라이브러리를 사용해서 객체를 json 형태의 DataBuffer 로 encode 하는 encoder 입니다. jackson 라이브러리가 있을 때에만 등록됩니다.\nKotlinSerializationJsonEncoder : kotlinx.serialization 라이브러리를 활용해서 객체를 json 형태의 DataBuffer 로 encode 하는 encoder 입니다. kotlinx.serialization 라이브러리가 있을 경우에만 등록됩니다.\nJackson2SmailEncoder : jackson 라이브러리로 객체를 smile 형태의 DataBuffer 로 encode 하는 encoder 입니다. jackson-smile 라이브러리가 있을 때에만 등록됩니다.\nJaxb2XmlEncoder : jaxb 를 사용해서 객체를 xml 형태의 DataBuffer 로 encode 하는 encoder 입니다. jaxb 라이브러리가 있을 때에만 등록됩니다.","기본-웹-응답-writer#기본 웹 응답 Writer":"ResourceHttpMessageWriter : HTTP 응답으로 리소스를 쓰는 역할을 수행합니다. canWrite(), writeResource(), write(), getWritableMediaTypes(), addHeaders(), addDefaultHeaders() 등과 같은 메서드를 제공합니다.\nProtobufHttpMessageWriter : Protocol Buffers 형식으로 직렬화된 데이터를 HTTP 응답으로 전송하는 역할을 합니다. Protocol Buffers는 구조화된 데이터를 효율적으로 직렬화하고 파싱하기 위한 바이너리 형식입니다.","객체-응답-writer#객체 응답 Writer":"ServerSentEventHttpMessageWriter : Server-Sent Events (SSE) 프로토콜을 통해 객체를 ServerSentEvent 로 encode 해서 write 하는 역할을 수행","http-요청응답-구조#HTTP 요청,응답 구조":"","json#JSON":"","webhandler-코드#webHandler 코드":"Json 응답형식 테스트를 위해 간단한 WebHandler 코드를 작성했습니다. Content-Type 이 application/json 일 경우에 대한 코드입니다.JsonDataWebHandlerExample1.java\npackage io.chagchagchag.example.foobar.spring_webflux.codec;\r\n\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport org.springframework.core.io.buffer.DataBuffer;\r\nimport org.springframework.http.codec.ServerCodecConfigurer;\r\nimport org.springframework.http.server.reactive.ReactorHttpHandlerAdapter;\r\nimport org.springframework.web.reactive.function.server.ServerRequest;\r\nimport org.springframework.web.server.ServerWebExchange;\r\nimport org.springframework.web.server.WebHandler;\r\nimport org.springframework.web.server.adapter.WebHttpHandlerBuilder;\r\nimport reactor.core.publisher.Mono;\r\nimport reactor.netty.http.server.HttpServer;\r\n\r\n@Slf4j\r\npublic class JsonDataWebHandlerExample1 {\r\n  private static record TickerQuery(\r\n      String ticker\r\n  ){}\r\n\r\n  @SneakyThrows\r\n  public static void main(String[] args) {\r\n    log.info(\"main function started\");\r\n\r\n    var webHandler = new WebHandler(){\r\n      @Override\r\n      public Mono<Void> handle(ServerWebExchange exchange) {\r\n        ServerCodecConfigurer codecConfigurer = ServerCodecConfigurer.create();\r\n        var request = ServerRequest.create(\r\n            exchange, codecConfigurer.getReaders()\r\n        );\r\n\r\n        var response = exchange.getResponse();\r\n\r\n        var bodyMono = request.bodyToMono(TickerQuery.class);\r\n        return bodyMono.flatMap(query -> {\r\n          String tickerQuery = query.ticker();\r\n          String ticker = tickerQuery == null ? \"MSFT\" : tickerQuery;\r\n\r\n          String content = \"You picked \" + ticker;\r\n          log.info(\"content = {}\", content);\r\n\r\n          Mono<DataBuffer> responseBody = Mono.just(\r\n              response.bufferFactory().wrap(content.getBytes())\r\n          );\r\n\r\n          response.getHeaders()\r\n              .add(\"Content-Type\", \"text/plain\");\r\n\r\n          return response.writeWith(responseBody);\r\n        });\r\n      }\r\n    };\r\n\r\n    var httpHandler = WebHttpHandlerBuilder\r\n        .webHandler(webHandler)\r\n        .build();\r\n\r\n    var handlerAdapter = new ReactorHttpHandlerAdapter(httpHandler);\r\n\r\n    HttpServer.create()\r\n        .host(\"localhost\").port(8080)\r\n        .handle(handlerAdapter)\r\n        .bindNow()\r\n        .channel().closeFuture().sync();\r\n\r\n    log.info(\"main function end\");\r\n  }\r\n}","http-요청-intellij-http#http 요청 (intellij http)":"POST http://localhost:8080\r\nContent-Type: application/json\r\n\r\n{\r\n  \"ticker\": \"SMCI\"\r\n}\r\n\r\n###","응답#응답":"HTTP/1.1 200 OK\r\nContent-Type: text/plain\r\ncontent-length: 15\r\n\r\nYou picked SMCI","form#Form":"","webhandler-코드-1#webhandler 코드":"Form Data 응답 형식 테스트를 위해 WebHandler 코드를 작성했습니다. Content-Type 이 x-www-form-urlencoded 일 경우 exchange 객체 내의 getFormData() 메서드를 통해서 Form Data 를 MultiValueMap 형식으로 추출가능합니다.FormDataWebHandlerExample1.java\npackage io.chagchagchag.example.foobar.spring_webflux.codec;\r\n\r\n// ..\r\n\r\n@Slf4j\r\npublic class FormDataWebHandlerExample1 {\r\n  @SneakyThrows\r\n  public static void main(String[] args) {\r\n    log.info(\"main function started\");\r\n\r\n    var webHandler = new WebHandler(){\r\n      @Override\r\n      public Mono<Void> handle(ServerWebExchange exchange) {\r\n        var request = exchange.getRequest();\r\n        var response = exchange.getResponse();\r\n\r\n        // 여기\r\n        return exchange.getFormData()\r\n            .flatMap(multiValueMap -> {\r\n              String tickerQuery = multiValueMap.getFirst(\"ticker\");\r\n              String ticker = tickerQuery == null ? \"NVDA\" : tickerQuery;\r\n\r\n              String content = \"You picked \" + ticker;\r\n              log.info(\"content = {}\", content);\r\n\r\n              Mono<DataBuffer> responseBody = Mono.just(\r\n                  response.bufferFactory()\r\n                      .wrap(content.getBytes())\r\n              );\r\n\r\n              response.addCookie(ResponseCookie.from(\"ticker\", ticker).build());\r\n              response.getHeaders().add(\"Content-Type\", \"text/plain\");\r\n              return response.writeWith(responseBody);\r\n            });\r\n      }\r\n    };\r\n\r\n    var httpHandler = WebHttpHandlerBuilder\r\n        .webHandler(webHandler)\r\n        .build();\r\n\r\n    var handlerAdapter = new ReactorHttpHandlerAdapter(httpHandler);\r\n\r\n    HttpServer.create()\r\n            .host(\"localhost\").port(8080)\r\n            .handle(handlerAdapter)\r\n            .bindNow()\r\n            .channel().closeFuture().sync();\r\n\r\n    log.info(\"main function end\");\r\n  }\r\n}","http-요청-intellij-http-1#http 요청 (intellij http)":"POST http://localhost:8080/\r\nContent-Type: application/x-www-form-urlencoded\r\n\r\nticker=AMZN","응답-1#응답":"HTTP/1.1 200 OK\r\nContent-Type: text/plain\r\nset-cookie: ticker=AMZN\r\ncontent-length: 15\r\n\r\nYou picked AMZN","multipart#Multipart":"","webhandler-코드-2#webhandler 코드":"간단한 테스트를 위해 multipart 데이터 요청을 처리하는 webHandler 코드를 작성했습니다.MultipartDataWebHandlerExample1.java\npackage io.chagchagchag.example.foobar.spring_webflux.codec;\r\n\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport org.springframework.core.io.buffer.DataBuffer;\r\nimport org.springframework.http.ResponseCookie;\r\nimport org.springframework.http.codec.multipart.FormFieldPart;\r\nimport org.springframework.http.server.reactive.ReactorHttpHandlerAdapter;\r\nimport org.springframework.web.server.ServerWebExchange;\r\nimport org.springframework.web.server.WebHandler;\r\nimport org.springframework.web.server.adapter.WebHttpHandlerBuilder;\r\nimport reactor.core.publisher.Mono;\r\nimport reactor.netty.http.server.HttpServer;\r\n\r\n@Slf4j\r\npublic class MultipartDataWebHandlerExample1 {\r\n  @SneakyThrows\r\n  public static void main(String[] args) {\r\n    log.info(\"main function started\");\r\n\r\n    var webHandler = new WebHandler(){\r\n      @Override\r\n      public Mono<Void> handle(ServerWebExchange exchange) {\r\n        return exchange.getMultipartData()\r\n            .map(multiValueMap -> {\r\n              return ((FormFieldPart) multiValueMap.getFirst(\"ticker\")).value();\r\n            })\r\n            .flatMap(tickerQuery -> {\r\n              String ticker = tickerQuery == null ? \"MSFT\" : tickerQuery;\r\n              String content = \"You picked \" + ticker;\r\n              log.info(\"content = {}\", content);\r\n\r\n              Mono<DataBuffer> responseBody = Mono.just(\r\n                  exchange.getResponse()\r\n                      .bufferFactory()\r\n                      .wrap(content.getBytes())\r\n              );\r\n\r\n              exchange.getResponse().addCookie(\r\n                  ResponseCookie.from(\"ticker\", ticker).build()\r\n              );\r\n\r\n              exchange.getResponse().getHeaders()\r\n                  .add(\"Content-Type\", \"text/plain\");\r\n\r\n              return exchange.getResponse().writeWith(responseBody);\r\n            });\r\n      }\r\n    };\r\n\r\n    var httpHandler = WebHttpHandlerBuilder\r\n        .webHandler(webHandler)\r\n        .build();\r\n\r\n    var handlerAdapter = new ReactorHttpHandlerAdapter(httpHandler);\r\n\r\n    HttpServer.create()\r\n        .host(\"localhost\").port(8080)\r\n        .handle(handlerAdapter)\r\n        .bindNow()\r\n        .channel().closeFuture().sync();\r\n\r\n    log.info(\"main function end\");\r\n  }\r\n}","http-요청-intellij-http-2#http 요청 (intellij http)":"POST http://localhost:8080\r\nContent-Type: multipart/form-data; boundary=WebAppBoundary\r\n\r\n--WebAppBoundary\r\nContent-Disposition: form-data; name=\"ticker\"\r\nContent-Type: text/plain\r\n\r\nSMCI\r\n--WebAppBoundary--\r\n###","응답-2#응답":"HTTP/1.1 200 OK\r\nContent-Type: text/plain\r\nset-cookie: ticker=SMCI\r\ncontent-length: 15\r\n\r\nYou picked SMCI"}},"/spring-webflux/annotated-controller":{"title":"Annotated Controller","data":{"annoatated-controller#Annoatated Controller":""}},"/spring-cloud-stream-and-kafka/spring-cloud-stream":{"title":"Spring Cloud Stream","data":{"spring-cloud-stream#Spring Cloud Stream":"","참고#참고":"Spring Cloud Stream Reference Guide\ndocs.spring.io - spring cloud stream / Spring Cloud Function Support\ndocs.spring.io - Producing and Consuming Messages\nspring-cloud-stream/Spring Cloud Stream Reference Documentation/Testing\nStreaming with Spring Cloud\nIntroduction to Spring Cloud Stream\nGuide to Spring Cloud Stream with Kafka, Apache Avro and Confluent Schema Registry","spring-cloud-stream-이란#Spring Cloud Stream 이란?":"Spring Cloud Stream 은 추상화된 binder 를 제공합니다. 그리고 애플리케이션은 binder 를 통해서 input, output 을 주고 받습니다. kafka 를 사용할 경우 kafka 로부터의 메시지를 Consume 할 때에는 kafka-binder 를 이용해서 input을 통해서 접근 가능하고, 메시지를 Produce 할 경우에는 kafka-binder 의 output 기능을 통해서 데이터를 접근 가능합니다.","의존성#의존성":"// ...\r\n\r\nrepositories {\r\n  mavenCentral()\r\n}\r\n\r\nextra[\"springCloudVersion\"] = \"2023.0.0\"\r\n\r\ndependencies {\r\n  implementation(\"org.springframework.cloud:spring-cloud-stream\")\r\n  testImplementation(\"org.springframework.boot:spring-boot-starter-test\")\r\n  testImplementation(\"org.springframework.cloud:spring-cloud-stream-test-binder\")\r\n}\r\n\r\ndependencyManagement {\r\n  imports {\r\n    mavenBom(\"org.springframework.cloud:spring-cloud-dependencies:${property(\"springCloudVersion\")}\")\r\n  }\r\n}\r\n\r\n// ...","springcloudfunction-등록#spring.cloud.function 등록":"application-stream-function.yaml\nspring:\r\n  cloud:\r\n    function:\r\n      definition: increment;livenessCheck;stringToBigDecimal","input-output-bind-컨벤션#input, output bind 컨벤션":"위에서 살펴본 spring.cloud.function 에 등록된 함수에 입력인자명, 출력값은 아래의 컨벤션에 따라 binding 이 생성됩니다.입력(input) 인자값\n{cloud function bean 이름}-in-{argument index}\ne.g. consumeMessage-in-0\nspring.cloud.function 에 등록한 consumeMessage 함수의 0번째 입력인자 를 의미합니다.\n출력(output) 컨벤션\n{cloud function bean 이름}-out-{return index}\ne.g. supplyReady-out-0\nspring.cloud.function 에 등록한 supplyReady 함수의 0번째 출력(return)값을 의미합니다.\n예를 들면 위와 같은 binding 컨벤션으로 생성한 입력, 출력 명세에 따라 아래와 같은 방식으로 데이터를 주고 받을 수 있습니다.\npackage io.chagchagchag.example.foobar.spring_cloud_stream;\r\n\r\n// ...\r\n\r\n@Import(TestChannelBinderConfiguration.class)\r\n@ActiveProfiles(\"stream-function\")\r\n@SpringBootTest(classes = SpringCloudStreamApplication.class)\r\npublic class SpringCloudFunctionTest {\r\n\r\n  @Autowired\r\n  InputDestination inputDestination;\r\n\r\n  @Autowired\r\n  OutputDestination outputDestination;\r\n\r\n  @Autowired\r\n  ConcurrentHashMap counterMap;\r\n\r\n  @BeforeEach\r\n  public void reset(){\r\n    counterMap.clear();\r\n  }\r\n\r\n  @DisplayName(\"COUNTER_STREAM_MESSAGING\")\r\n  @Test\r\n  public void TEST_COUNTER_STREAM_MESSAGING(){\r\n    // given\r\n    var ticker = \"MSFT\";\r\n    var input = new GenericMessage<>(ticker);\r\n    var inputBinding = \"increment-in-0\";\r\n\r\n    // when\r\n    inputDestination.send(input, inputBinding);\r\n\r\n    // then\r\n    assertThat(counterMap.getOrDefault(ticker, 0)).isEqualTo(1);\r\n  }\r\n  \r\n  // ...\r\n\r\n}\n간단한 블랙박스 테스트입니다. Spring Cloud Function 의 내용이 무엇인지 전혀 모르는 상태로 메시지를 InputDestination 을 이용해서 Message를 보낼 경우 정상적으로 상태가 반영되었는지를 체크합니다.Spring Cloud Function 으로 등록한 increment Bean 의 Consumer 의 입력값 인자값에 해당하는 increment-in-0 을 inputBinding 으로 지정해줬기에 해당 Consumer 를 잘 찾아서 원하는 상태값으로 변경시켜준 것을 확인 가능합니다.","inputdestination-outputdestination#InputDestination, OutputDestination":"참고로 InputDestination, OutputDestination 클래스들은 test 패키지 아래에 있는 클래스 들이기에 Application 레벨에서 호출하는 것이 불가능합니다. 보통 통합 테스트를 위해 InputDestination, OutputDestination 기반 코드를 작성하는 편입니다.","inputdestination#InputDestination":"InputDestination 클래스는 아래와 같이 정의되어 있습니다.\npackage org.springframework.cloud.stream.binder.test;\r\n\r\nimport org.springframework.messaging.Message;\r\n\r\npublic class InputDestination extends AbstractDestination {\r\n  public InputDestination() {\r\n  }\r\n\r\n  public void send(Message<?> message) {\r\n    this.getChannel(0).send(message);\r\n  }\r\n\r\n  public void send(Message<?> message, String destinationName) {\r\n    this.getChannelByName(destinationName).send(message);\r\n  }\r\n}\nInputDestination 에서 사용되는 Message 는 interface 이고, InputDestination 에 주로 바인딩하는 구현체는 GenericMessage 인데, GenericMessage 의 정의는 아래와 같습니다.\npackage org.springframework.messaging.support;\r\n\r\n// ...\r\npublic class GenericMessage<T> implements Message<T>, Serializable {\r\n  private static final long serialVersionUID = 4268801052358035098L;\r\n  private final T payload;\r\n  private final MessageHeaders headers;\r\n\r\n  public GenericMessage(T payload) {\r\n    this(payload, new MessageHeaders((Map)null));\r\n  }\r\n\r\n  public GenericMessage(T payload, Map<String, Object> headers) {\r\n    this(payload, new MessageHeaders(headers));\r\n  }\r\n\r\n  public GenericMessage(T payload, MessageHeaders headers) {\r\n    Assert.notNull(payload, \"Payload must not be null\");\r\n    Assert.notNull(headers, \"MessageHeaders must not be null\");\r\n    this.payload = payload;\r\n    this.headers = headers;\r\n  }\r\n    \r\n  // ...\r\n}","outputdestination#OutputDestination":"package org.springframework.cloud.stream.binder.test;\r\n\r\n// ...\r\n\r\npublic class OutputDestination extends AbstractDestination {\r\n  private final Log log = LogFactory.getLog(OutputDestination.class);\r\n  private final ConcurrentHashMap<String, BlockingQueue<Message<byte[]>>> messageQueues = new ConcurrentHashMap();\r\n\r\n  public OutputDestination() {\r\n  }\r\n\r\n  public Message<byte[]> receive(long timeout, String bindingName) {\r\n    try {\r\n      bindingName = bindingName.endsWith(\".destination\") ? bindingName : bindingName + \".destination\";\r\n      return (Message)this.outputQueue(bindingName).poll(timeout, TimeUnit.MILLISECONDS);\r\n    } catch (InterruptedException var5) {\r\n      Thread.currentThread().interrupt();\r\n      return null;\r\n    }\r\n  }\r\n    \r\n  // ...\r\n\r\n  public Message<byte[]> receive() {\r\n    return this.receive(0L, 0);\r\n  }\r\n\r\n  public Message<byte[]> receive(long timeout) {\r\n    return this.receive(timeout, 0);\r\n  }\r\n\r\n  // ...\r\n}","consumer-supplier-function#Consumer, Supplier, Function":"","consumer-구현-테스트#Consumer 구현, 테스트":"ConcurrentHashMap<String, Integer> 타입의 counterMap 을 Bean 으로 등록하고 이것을 기반으로 여러가지 키가 몇번 조회되었는지 카운트하는 간단한 예제를 살펴보겠습니다.","설정-streamfunctionsconfigjava#설정) StreamFunctionsConfig.java":"package io.chagchagchag.example.foobar.spring_cloud_stream.config;\r\n// ...\r\n\r\n@Slf4j\r\n@Configuration\r\npublic class StreamFunctionsConfig {\r\n  @Bean\r\n  public ConcurrentHashMap<String, Integer> counterMap(){\r\n    return new ConcurrentHashMap<>();\r\n  }\r\n\r\n  @Bean\r\n  public Consumer<Flux<String>> increment(ConcurrentHashMap<String, Integer> counterMap){\r\n    return fluxKey -> {\r\n      fluxKey.subscribe(key -> {\r\n        counterMap.computeIfPresent(key, (k, v) ->v+1);\r\n        counterMap.computeIfAbsent(key, v -> 1);\r\n      });\r\n    };\r\n  }\r\n  \r\n  // ...\r\n\r\n}\r\n그리고 위의 설정을 통해서 카운팅이 잘 이뤄지는지 테스트하는 코드는 아래와 같습니다.","단위테스트-incrementtestjava#단위테스트) IncrementTest.java":"package io.chagchagchag.example.foobar.spring_cloud_stream.config;\r\n\r\n// ...\r\n\r\n@Import(TestChannelBinderConfiguration.class)\r\n@ActiveProfiles(\"stream-function\")\r\n@SpringBootTest(classes = SpringCloudStreamApplication.class)\r\npublic class IncrementTest {\r\n\r\n  StreamFunctionsConfig streamFunctionsConfig = new StreamFunctionsConfig();\r\n\r\n  ConcurrentHashMap<String, Integer> counterMap = new ConcurrentHashMap<>();\r\n\r\n  @DisplayName(\"INCREMENT_TEST\")\r\n  @Test\r\n  public void TEST_INCREMENT_TEST(){\r\n    // given\r\n    var tickersFlux = Flux.just(\"NVDA\",\"SMCI\",\"MSFT\", \"NVDA\");\r\n\r\n    // when\r\n    streamFunctionsConfig\r\n        .increment(counterMap)\r\n        .accept(tickersFlux);\r\n\r\n    // then\r\n    Assertions.assertEquals(counterMap.get(\"NVDA\"), 2);\r\n    Assertions.assertEquals(counterMap.get(\"SMCI\"), 1);\r\n    Assertions.assertEquals(counterMap.get(\"MSFT\"), 1);\r\n  }\r\n\r\n}","통합테스트-springcloudfunctiontestjava#통합테스트) SpringCloudFunctionTest.java":"참고로 InputDestination, OutputDestination 클래스들은 test 패키지 아래에 있는 클래스 들이기에 Application 레벨에서 호출하는 것이 불가능합니다. 보통 통합 테스트를 위해 InputDestination, OutputDestination 기반 코드를 작성하는 편입니다.\n이번에는 블랙박스 테스트입니다. Spring Cloud Function 의 내용이 무엇인지 전혀 모르는 상태로 메시지를 InputDestination 을 이용해서 Message를 보낼 경우 정상적으로 상태가 반영되었는지를 체크합니다.Spring Cloud Function 으로 등록한 increment Bean 의 Consumer 의 입력값 인자값에 해당하는 increment-in-0 을 inputBinding 으로 지정해줬기에 해당 Consumer 를 잘 찾아서 원하는 상태값으로 변경시켜준 것을 확인 가능합니다.\npackage io.chagchagchag.example.foobar.spring_cloud_stream;\r\n\r\n// ...\r\n\r\n@Import(TestChannelBinderConfiguration.class)\r\n@ActiveProfiles(\"stream-function\")\r\n@SpringBootTest(classes = SpringCloudStreamApplication.class)\r\npublic class SpringCloudFunctionTest {\r\n\r\n  @Autowired\r\n  InputDestination inputDestination;\r\n\r\n  @Autowired\r\n  OutputDestination outputDestination;\r\n\r\n  @Autowired\r\n  ConcurrentHashMap counterMap;\r\n\r\n  @BeforeEach\r\n  public void reset(){\r\n    counterMap.clear();\r\n  }\r\n\r\n  @DisplayName(\"COUNTER_STREAM_MESSAGING\")\r\n  @Test\r\n  public void TEST_COUNTER_STREAM_MESSAGING(){\r\n    // given\r\n    var ticker = \"MSFT\";\r\n    var input = new GenericMessage<>(ticker);\r\n    var inputBinding = \"increment-in-0\";\r\n\r\n    // when\r\n    inputDestination.send(input, inputBinding);\r\n\r\n    // then\r\n    assertThat(counterMap.getOrDefault(ticker, 0)).isEqualTo(1);\r\n  }\r\n  \r\n  // ...\r\n\r\n}","supplier-구현-테스트#Supplier 구현, 테스트":"","설정-streamfunctionsconfigjava-1#설정) StreamFunctionsConfig.java":"package io.chagchagchag.example.foobar.spring_cloud_stream.config;\r\n\r\n// ...\r\n\r\n@Slf4j\r\n@Configuration\r\npublic class StreamFunctionsConfig {\r\n  // ...\r\n  \r\n  @Bean\r\n  public Supplier<Flux<String>> livenessCheck(){\r\n    return () -> Flux.just(\"OK\");\r\n  }\r\n    \r\n  // ...\r\n\r\n}","단위테스트-livenesschecktestjava#단위테스트) LivenessCheckTest.java":"package io.chagchagchag.example.foobar.spring_cloud_stream.config;\r\n\r\n// ...\r\n\r\n@Import(TestChannelBinderConfiguration.class)\r\n@ActiveProfiles(\"stream-function\")\r\n@SpringBootTest(classes = SpringCloudStreamApplication.class)\r\npublic class LivenessCheckTest {\r\n  StreamFunctionsConfig streamFunctionsConfig = new StreamFunctionsConfig();\r\n\r\n  @DisplayName(\"LIVENESS_CHECK\")\r\n  @Test\r\n  public void TEST_LIVENESS_CHECK(){\r\n    // given\r\n\r\n    // when\r\n    var livenessCheckFlux = streamFunctionsConfig.livenessCheck().get();\r\n\r\n    // then\r\n    StepVerifier.create(livenessCheckFlux)\r\n        .expectNext(\"OK\")\r\n        .verifyComplete();\r\n  }\r\n\r\n}","통합테스트-springcloudfunctiontestjava-1#통합테스트) SpringCloudFunctionTest.java":"참고로 InputDestination, OutputDestination 클래스들은 test 패키지 아래에 있는 클래스 들이기에 Application 레벨에서 호출하는 것이 불가능합니다. 보통 통합 테스트를 위해 InputDestination, OutputDestination 기반 코드를 작성하는 편입니다.\npackage io.chagchagchag.example.foobar.spring_cloud_stream;\r\n// ...\r\n\r\n@Import(TestChannelBinderConfiguration.class)\r\n@ActiveProfiles(\"stream-function\")\r\n@SpringBootTest(classes = SpringCloudStreamApplication.class)\r\npublic class SpringCloudFunctionTest {\r\n\r\n  @Autowired\r\n  InputDestination inputDestination;\r\n\r\n  @Autowired\r\n  OutputDestination outputDestination;\r\n\r\n  @Autowired\r\n  ConcurrentHashMap counterMap;\r\n\r\n  @BeforeEach\r\n  public void reset(){\r\n    counterMap.clear();\r\n  }\r\n  \r\n  // ...\r\n  \r\n  // Supplier (livenessCheck)\r\n  @DisplayName(\"LIVENESS_CHECK_STREAM_MESSAGING\")\r\n  @Test\r\n  public void TEST_LIVENESS_CHECK_STREAM_MESSAGING(){\r\n    // given\r\n    var outputBinding = \"livenessCheck-out-0\";\r\n    var expectedMsg = List.of(\"OK\");\r\n\r\n    for(var name: expectedMsg){\r\n      // when\r\n      var received = outputDestination.receive(300, outputBinding);\r\n      String outputMessage = new String(received.getPayload());\r\n\r\n      // then\r\n      assertThat(outputMessage.equals(name)).isTrue();\r\n    }\r\n  }\r\n  \r\n  // ...\r\n\r\n}","function-구현-테스트#Function 구현, 테스트":"","설정-streamfunctionsconfigjava-2#설정) StreamFunctionsConfig.java":"package io.chagchagchag.example.foobar.spring_cloud_stream.config;\r\n// ...\r\n\r\n@Slf4j\r\n@Configuration\r\npublic class StreamFunctionsConfig {\r\n  // ...\r\n  @Bean\r\n  public Function<Flux<String>, Flux<BigDecimal>> stringToBigDecimal(){\r\n    return fluxString -> fluxString.handle((str, sink) -> {\r\n      try{\r\n        Number parse = NumberFormat.getNumberInstance(Locale.US).parse(str);\r\n        sink.next(new BigDecimal(parse.toString()));\r\n      }\r\n      catch (ParseException e){\r\n        e.printStackTrace();\r\n        sink.error(new IllegalStateException(\"Number Format is not supported.\"));\r\n      }\r\n    });\r\n  }\r\n\r\n}","단위테스트-stringtobigdecimaltest#단위테스트) StringToBigDecimalTest":"package io.chagchagchag.example.foobar.spring_cloud_stream.config;\r\n// ...\r\n\r\n@Import(TestChannelBinderConfiguration.class)\r\n@ActiveProfiles(\"stream-function\")\r\n@SpringBootTest(classes = SpringCloudStreamApplication.class)\r\npublic class StringToBigDecimalTest {\r\n  StreamFunctionsConfig streamFunctionsConfig = new StreamFunctionsConfig();\r\n\r\n  @DisplayName(\"STRING_TO_BIG_DECIMAL\")\r\n  @Test\r\n  public void TEST_STRING_TO_BIG_DECIMAL(){\r\n    // given\r\n    var strNumbers = Flux.just(\"28.39\");\r\n    var expected = BigDecimal.valueOf(28.39);\r\n\r\n    Predicate<BigDecimal> equals = d -> {\r\n      if(d.equals(expected)) return true;\r\n      else return false;\r\n    };\r\n\r\n    // when\r\n    var bigDeciamlFlux = streamFunctionsConfig.stringToBigDecimal().apply(strNumbers);\r\n\r\n    // then\r\n    StepVerifier.create(bigDeciamlFlux)\r\n        .expectNextMatches(equals)\r\n        .verifyComplete();\r\n  }\r\n\r\n}","통합테스트-springcloudfunctiontestjava-2#통합테스트) SpringCloudFunctionTest.java":"참고로 InputDestination, OutputDestination 클래스들은 test 패키지 아래에 있는 클래스 들이기에 Application 레벨에서 호출하는 것이 불가능합니다. 보통 통합 테스트를 위해 InputDestination, OutputDestination 기반 코드를 작성하는 편입니다.\npackage io.chagchagchag.example.foobar.spring_cloud_stream;\r\n// ...\r\n\r\n@Import(TestChannelBinderConfiguration.class)\r\n@ActiveProfiles(\"stream-function\")\r\n@SpringBootTest(classes = SpringCloudStreamApplication.class)\r\npublic class SpringCloudFunctionTest {\r\n\r\n  @Autowired\r\n  InputDestination inputDestination;\r\n\r\n  @Autowired\r\n  OutputDestination outputDestination;\r\n\r\n  @Autowired\r\n  ConcurrentHashMap counterMap;\r\n\r\n  // ...\r\n  \r\n  // Function (stringToBigDecimal)\r\n  @DisplayName(\"STRING_TO_BIG_DECIMAL\")\r\n  @Test\r\n  public void TEST_STRING_TO_BIG_DECIMAL() throws ParseException {\r\n    // given\r\n    var inputBinding = \"stringToBigDecimal-in-0\";\r\n    var outputBinding = \"stringToBigDecimal-out-0\";\r\n    var input = new GenericMessage<>(\"28.39\");\r\n    var expected = BigDecimal.valueOf(28.39);\r\n\r\n    // when\r\n    // 먼저 값을 보낸다.\r\n    inputDestination.send(input, inputBinding);\r\n\r\n    // then\r\n    // 치리되어 반환하는 값을 받는다.\r\n    var received = outputDestination.receive(30, outputBinding);\r\n    var receivedStr = new String(received.getPayload());\r\n    var receivedDecimal = new BigDecimal(receivedStr);\r\n    assertThat(receivedDecimal).isEqualTo(expected);\r\n  }\r\n\r\n}","streambridge#StreamBridge":"지금까지 위에서 살펴봤던 InputDestination, OutputDestination 은 모두 org.springframework.cloud.stream.binder.test 패키지 아래에 있는 클래스였습니다. InputDestination, OutputDestination 클래스들은 test 패키지 아래에 있는 클래스 들이기에 Application 레벨에서 호출하는 것이 불가능합니다.만약 Spring Cloud Function 을 애플리케이션 레벨에서 호출해서 사용해야 할 경우에는 StreamBridge 를 사용합니다.이번 예제는 새로 Spring Cloud Function 을 작성하고 REST API 에 요청이 왔을 때 실제로 Spring Cloud Function 이 호출되고 recevie 하는 측에서는 올바른 결과를 받는지를 체크하는 기능을 테스트해봅니다. 결과를 리턴받아야하므로 Function<T,R> 타입의 Spring Cloud Function 을 작성합니다.","application-stream-functionyaml#application-stream-function.yaml":"이 파일은 src/test/resources, srs/main/resources 에 모두 추가해줍니다. 조금 전의 예제와 달라진 점은 ;toLengthList 가 추가되었다는 점 입니다.\nspring:\r\n  cloud:\r\n    function:\r\n      definition: increment;livenessCheck;stringToBigDecimal;toLengthList","streamfunctionsconfigjava#StreamFunctionsConfig.java":"StreamFunctionsConfig 에는 아래와 같이 Function<T,R> 타입의 Bean 을 추가해주었습니다. 꼭 Bean 이 아니어도 @Component 로 추가해주어도 됩니다.\npackage io.chagchagchag.example.foobar.spring_cloud_stream.config;\r\n\r\n// ...\r\n\r\n@Slf4j\r\n@Configuration\r\npublic class StreamFunctionsConfig {\r\n  // ...\r\n  @Bean\r\n  public Function<Flux<String>, Flux<Integer>> toLengthList(){\r\n    return strFlux -> strFlux.map(String::length);\r\n  }\r\n}","numberscontrollerjava#NumbersController.java":"NumbersController 는 아래와 같이 추가해줬습니다. 특정 문자열을 받으면 이 문자열에 대해 streamBridge 를 이용해서 toLengthList 함수를 호출하는 기능입니다. input Binding 과 입력값을 연결해준 모습이 보입니다.\npackage io.chagchagchag.example.foobar.spring_cloud_stream;\r\n\r\n// ...\r\n\r\n@RequiredArgsConstructor\r\n@RequestMapping(\"/numbers\")\r\n@RestController\r\npublic class NumbersController {\r\n  private final StreamBridge streamBridge;\r\n\r\n  @GetMapping(\"/to-list\")\r\n  public void toList(@RequestParam(\"word\") String word){\r\n    streamBridge.send(\"toLengthList-in-0\", word);\r\n  }\r\n}","단위테스트-tolengthlisttestjava#단위테스트) ToLengthListTest.java":"실제로 기능의 내부는 정상적으로 동작하는지 단위테스트를 작성했습니다.\npackage io.chagchagchag.example.foobar.spring_cloud_stream.config;\r\n\r\nimport io.chagchagchag.example.foobar.spring_cloud_stream.SpringCloudStreamApplication;\r\nimport org.junit.jupiter.api.DisplayName;\r\nimport org.junit.jupiter.api.Test;\r\nimport org.springframework.boot.test.context.SpringBootTest;\r\nimport org.springframework.cloud.stream.binder.test.TestChannelBinderConfiguration;\r\nimport org.springframework.context.annotation.Import;\r\nimport org.springframework.test.context.ActiveProfiles;\r\nimport reactor.core.publisher.Flux;\r\nimport reactor.test.StepVerifier;\r\n\r\n@Import(TestChannelBinderConfiguration.class)\r\n@ActiveProfiles(\"stream-function\")\r\n@SpringBootTest(classes = SpringCloudStreamApplication.class)\r\npublic class ToLengthListTest {\r\n  StreamFunctionsConfig streamFunctionsConfig = new StreamFunctionsConfig();\r\n\r\n  @DisplayName(\"TO_LENGTH_LIST\")\r\n  @Test\r\n  public void TEST_TO_LENGTH_LIST(){\r\n    // given\r\n    var strWords = Flux.just(\"hello\", \"world\", \"java\");\r\n\r\n    // when\r\n    var resultFlux = streamFunctionsConfig.toLengthList().apply(strWords);\r\n\r\n    // then\r\n    StepVerifier.create(resultFlux)\r\n        .expectNext(\"hello\".length())\r\n        .expectNext(\"world\".length())\r\n        .expectNext(\"java\".length())\r\n        .verifyComplete();\r\n  }\r\n}","통합테스트-numberscontrollertestjava#통합테스트) NumbersControllerTest.java":"이번에는 REST API 로 locahost:8080/numbers/to-list?word=hello 호출 시에 내부적으로 Stream Function 이 호출되어서 receive 시에 돌려받는 값이 실제로 hello 라는 단어의 길이를 리턴하는지를 확인하는 테스트 코드입니다.\npackage io.chagchagchag.example.foobar.spring_cloud_stream;\r\n\r\nimport java.util.concurrent.ConcurrentHashMap;\r\nimport org.assertj.core.api.Assertions;\r\nimport org.junit.jupiter.api.DisplayName;\r\nimport org.junit.jupiter.api.Test;\r\nimport org.springframework.beans.factory.annotation.Autowired;\r\nimport org.springframework.boot.test.autoconfigure.web.reactive.AutoConfigureWebTestClient;\r\nimport org.springframework.boot.test.context.SpringBootTest;\r\nimport org.springframework.cloud.stream.binder.test.InputDestination;\r\nimport org.springframework.cloud.stream.binder.test.OutputDestination;\r\nimport org.springframework.cloud.stream.binder.test.TestChannelBinderConfiguration;\r\nimport org.springframework.context.annotation.Import;\r\nimport org.springframework.test.context.ActiveProfiles;\r\nimport org.springframework.test.web.reactive.server.WebTestClient;\r\n\r\n@AutoConfigureWebTestClient\r\n@Import(TestChannelBinderConfiguration.class)\r\n@ActiveProfiles(\"stream-function\")\r\n@SpringBootTest(classes = SpringCloudStreamApplication.class)\r\npublic class NumbersControllerTest {\r\n  @Autowired\r\n  InputDestination inputDestination;\r\n\r\n  @Autowired\r\n  OutputDestination outputDestination;\r\n\r\n  @Autowired\r\n  ConcurrentHashMap counterMap;\r\n\r\n  @Autowired\r\n  WebTestClient webTestClient;\r\n\r\n  @DisplayName(\"TO_LIST_FUNCTION\")\r\n  @Test\r\n  public void TEST_TO_LIST_FUNCTION(){\r\n    // given\r\n    var expected = \"hello\".length();\r\n    var outputBinding = \"toLengthList-out-0\";\r\n\r\n    // when\r\n    webTestClient.get()\r\n        .uri(\"/numbers/to-list?word=\"+\"hello\")\r\n        .exchange()\r\n        .expectStatus().isOk();\r\n\r\n    // then\r\n    var result = outputDestination.receive(30, outputBinding);\r\n    String resultMessage = new String(result.getPayload());\r\n    Assertions.assertThat(expected).isEqualTo(Integer.parseInt(resultMessage));\r\n  }\r\n\r\n}"}},"/spring-webflux/intro":{"title":"Intro","data":{}},"/spring-webflux/dispatcher-handler-communication-spring-webflux":{"title":"Dispatcher Handler Communication Spring Webflux","data":{"dispatcherhandler-와-spring-webflux#DispatcherHandler 와 Spring Webflux":"우리는 Servlet 기반의 Spring 을 개발할 때에는 보통 DispatcherServlet의 개념과 HandlerMapping 이 어떻게 매핑되고 요청이 응답되는지를 스터디해왔습니다.Project Reactor 또는 RxJava, Mutiny 등과 같은 Reactive Manifesto 를 따르는 Reactive Streams 계열의 브러리는 Reactor Netty 환경에서 동작가능합니다.그리고 Reactor Netty 환경에서는 DispatcherServlet 이 아닌 DispatcherHandler 를 중심으로 Request 와 Response 의 상호작용을 해결합니다.","참고자료#참고자료":"An introduction to Reactive Web","dispatcherhandler-의-requestresponse-처리-흐름#DispatcherHandler 의 request,response 처리 흐름":"DispatcherHandler 가 Resquest, Response 를 응답하기 위해 다른 객체들과 상호작용하는 그림을 그려보면 아래와 같습니다. DispatcherServlet 에서 보던 그림과 어느 정도는 유사하기에 친숙하게 느껴집니다.\n1.\n외부로부터 요청이 Reactor Netty 에 도착합니다.\nReact Netty 는 이 요청을 DispatcherHandler 에 전달합니다.\n2. 3.\nDispatcherHandler 는 요청의 파라미터 등을 파악해서 이 요청은 어떤 HandlerMapping 에 맞는 것인지를 조회해서 적절한 HandlerMapping 을 찾아냅니다.\n4. 5.\nDispatcherHandler 는 HandlerMapping 을 처리하기에 알맞는 HandlerAdapter 를 HandlerAdapter 목록에서 찾습니다.\n6. 7. 8. 9.\nDispatcherHandler 는 4.5. 에서 찾아낸 HandlerAdapter 객체의 handle() 메서드를 실행합니다. 이 HandlerAdapter 는 interface 인데, 이 것을 구현하고 있는 구현체 들 중 하나로부터 적절한 Controller 등을 찾아내서 Request 에 대한 처리를 수행합니다. 이 때 결과값은 HandlerResult 로 전달받게 됩니다.\n10. 11.\n위에서 구한 HandlerResult 를 처리할 수 있는 객체는 HandlerResultHandler 타입의 객체인데 보통 이런 HandlerResultHandler 는 여러개입니다. 이 중 적절한 HandlerResultHandler 를 찾아냅니다.\n12.\nDispatcherHandler 는 찾아낸 HandlerResultHandler 객체 내의 handleResult() 메서드를 실행합니다.\n13.\n그리고 DispatcherHandler 는 handleResult() 메서드로 실행한 결과를 Response 로 해서 Reactor Netty 에게 반환해줍니다.\n예를 들면 WebHandler 는 직접 작성한다면 아래와 같이 작성할 수 있습니다.\npackage io.chagchagchag.example.foobar.spring_webflux;\r\n\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport org.springframework.core.io.buffer.DataBuffer;\r\nimport org.springframework.http.ResponseCookie;\r\nimport org.springframework.http.server.reactive.HttpHandler;\r\nimport org.springframework.http.server.reactive.ReactorHttpHandlerAdapter;\r\nimport org.springframework.http.server.reactive.ServerHttpRequest;\r\nimport org.springframework.http.server.reactive.ServerHttpResponse;\r\nimport reactor.core.publisher.Mono;\r\nimport reactor.netty.http.server.HttpServer;\r\n\r\n@Slf4j\r\npublic class HttpHandlerExample1 {\r\n  @SneakyThrows\r\n  public static void main(String[] args) {\r\n    log.info(\"main function started\");\r\n    var httpHandler = new HttpHandler(){\r\n      @Override\r\n      public Mono<Void> handle(\r\n          ServerHttpRequest request, ServerHttpResponse response\r\n      ) {\r\n        String tickerQueryParam = request.getQueryParams().getFirst(\"ticker\");\r\n        String ticker = tickerQueryParam == null ? \"MSFT\" : tickerQueryParam;\r\n\r\n        String content = \"You picked \" + ticker;\r\n        log.info(\"responseBody = {}\", content);\r\n\r\n        Mono<DataBuffer> responseBody = Mono.just(\r\n            response.bufferFactory().wrap(content.getBytes())\r\n        );\r\n\r\n        response.addCookie(ResponseCookie.from(\"ticker\", ticker).build());\r\n        response.getHeaders().add(\"Content-Type\", \"text/plain\");\r\n        return response.writeWith(responseBody);\r\n      }\r\n    };\r\n\r\n    var adapter = new ReactorHttpHandlerAdapter(httpHandler);\r\n    HttpServer.create()\r\n        .host(\"localhost\").port(8080)\r\n        .handle(adapter)\r\n        .bindNow()\r\n        .channel().closeFuture().sync();\r\n\r\n    log.info(\"main function end\");\r\n  }\r\n}\r\nHttpHandler 는 HttpHandlerAdapter 에 주입 가능합니다. 그리고 HttpServer 는 HttpHandlerAdapter 를 주입받아서 처리할 수 있도록 로직을 작성합니다.","functional-endpoint-annotated-controller-의-동작#Functional Endpoint, Annotated Controller 의 동작":"Spring Webflux 에서는 함수형 엔드포인트, 선언형 컨트롤러(Annotated Controller) 가 있습니다. 두 방식 모두 잘 쓰이는 방식입니다. 개인적으로는 선언형 컨트롤러 (Annotated Controller) 를 선호합니다.Functional Endpoint 와 Annotated Controller 는 DispatcherServlet 내에서 아래와 같이 동작합니다.함수형 엔드포인트를 사용할 경우에는 RouterFunction 을 사용한다는 점과 선언형 컨트롤러 (Annotated Controller) 를 사용할 때에는 @RequestMapping 을 사용한다는 점을 기억하면 이해가 쉽습니다.예를 들어 함수형 엔드포인트는 아래와 같이 Router 를 작성해서 어떤 REST API 의 어떤 METHOD 를 처리할 지를 명시하고 이 Router 를 처리할 Handler 를 정의하는 방식으로 작성합니다.e.g.\n예제 코드는 [https://github.com/chagchagchag/stock-cells-kr/tree/main/backend/stock-cells-kr-backend/src/main/java/io/stock/evaluation/web/price/api] 에서 확인 가능합니다.\nPriceApiRouter.java\npackage io.stock.evaluation.web.price.api;\r\n\r\n// ...\r\n\r\n@Configuration\r\npublic class PriceApiRouter {\r\n\r\n    @Bean\r\n    public RouterFunction<ServerResponse> stockPriceByTickerRouter(PriceApiHandler priceApiHandler){\r\n        return RouterFunctions\r\n                .route().GET(\r\n                        \"/stock/price\",\r\n                        RequestPredicates.queryParam(\"ticker\", v -> true),\r\n                        priceApiHandler::getPriceBasicValuation\r\n                ).build();\r\n    }\r\n}\nPriceApiHandler.java\npackage io.stock.evaluation.web.price.api;\r\n\r\nimport io.stock.evaluation.web.crawling.stock.price.application.CrawlingValuationService;\r\nimport org.springframework.http.MediaType;\r\nimport org.springframework.stereotype.Component;\r\nimport org.springframework.web.reactive.function.BodyInserters;\r\nimport org.springframework.web.reactive.function.server.ServerRequest;\r\nimport org.springframework.web.reactive.function.server.ServerResponse;\r\nimport reactor.core.publisher.Mono;\r\n\r\nimport static org.springframework.web.reactive.function.server.ServerResponse.notFound;\r\nimport static org.springframework.web.reactive.function.server.ServerResponse.ok;\r\n\r\n@Component\r\npublic class PriceApiHandler {\r\n    private final CrawlingValuationService crawlingValuationService;\r\n\r\n    public PriceApiHandler(CrawlingValuationService crawlingValuationService){\r\n        this.crawlingValuationService = crawlingValuationService;\r\n    }\r\n\r\n    public Mono<ServerResponse> getPriceBasicValuation (ServerRequest serverRequest){\r\n        return serverRequest.queryParam(\"ticker\")\r\n                .map(ticker -> {\r\n                    return crawlingValuationService.getPriceBasicValuationData(ticker)\r\n                            .flatMap(cdata -> ok()\r\n                                        .contentType(MediaType.APPLICATION_JSON)\r\n                                        .body(BodyInserters.fromValue(cdata))\r\n                                        .switchIfEmpty(notFound().build())\r\n                            );\r\n                })\r\n                .orElse(notFound().build());\r\n    }\r\n}","serverwebexchange#ServerWebExchange":"ServerWebExchange 는 ServerHttpRequest, ServerHttpResponse 와 같은 요청객체, 응답객체를 접근가능하도록 하는 메서드를 제공하는 interface 입니다. 그리고 mulitpartData, formData 등을 모두 접근할 수 있는 메서드 역시 추상화 되어 있는 interface 입니다. ServerWebExchange 자체는 interface 이며 구현체로는 DefaultServerWebExchange, MockServerWebExchange, ServerWebExchangeDecorator 가 있습니다.Servlet 기반의 Spring 환경에서는 HttpServletRequest, HttpServletResponse 객체를 사용했었습니다. Reactor Netty 기반의 Spring 환경에서는 HttpServerRequest, HttpServerResponse 객체를 요청/응답 객체로 사용한다는 사실을 기억해주시기 바랍니다.일반적으로 Router 나 Controller 메서드에서 ServerHttpRequest, ServerHttpResponse 를 개별적으로 주입받아서 사용 가능하지만 ServerWebExchange 자체를 주입받아서 사용하는 경우도 있습니다.ServerWebExchange.java\npublic interface ServerWebExchange {\r\n\tString LOG_ID_ATTRIBUTE = ServerWebExchange.class.getName() + \".LOG_ID\";\r\n\tServerHttpRequest getRequest();\r\n\tServerHttpResponse getResponse();\r\n\r\n\tMap<String, Object> getAttributes();\r\n\r\n\t@SuppressWarnings(\"unchecked\")\r\n\t@Nullable\r\n\tdefault <T> T getAttribute(String name) {\r\n\t\treturn (T) getAttributes().get(name);\r\n\t}\r\n\t@SuppressWarnings(\"unchecked\")\r\n\tdefault <T> T getRequiredAttribute(String name) {\r\n\t\tT value = getAttribute(name);\r\n\t\tAssert.notNull(value, () -> \"Required attribute '\" + name + \"' is missing\");\r\n\t\treturn value;\r\n\t}\r\n\t@SuppressWarnings(\"unchecked\")\r\n\tdefault <T> T getAttributeOrDefault(String name, T defaultValue) {\r\n\t\treturn (T) getAttributes().getOrDefault(name, defaultValue);\r\n\t}\r\n\tMono<WebSession> getSession();\r\n\t<T extends Principal> Mono<T> getPrincipal();\r\n\tMono<MultiValueMap<String, String>> getFormData();\r\n\tMono<MultiValueMap<String, Part>> getMultipartData();\r\n    \r\n\tdefault Mono<Void> cleanupMultipart() {\r\n\t\treturn getMultipartData()\r\n\t\t\t\t.onErrorComplete()  // ignore errors reading multipart data\r\n\t\t\t\t.flatMapIterable(Map::values)\r\n\t\t\t\t.flatMapIterable(Function.identity())\r\n\t\t\t\t.flatMap(part -> part.delete().onErrorComplete())\r\n\t\t\t\t.then();\r\n\t}\r\n    \r\n\tLocaleContext getLocaleContext();\r\n    \r\n\t@Nullable\r\n\tApplicationContext getApplicationContext();\r\n\tboolean isNotModified();\r\n\tboolean checkNotModified(Instant lastModified);\r\n\tboolean checkNotModified(String etag);\r\n\tboolean checkNotModified(@Nullable String etag, Instant lastModified);\r\n\tString transformUrl(String url);\r\n\tvoid addUrlTransformer(Function<String, String> transformer);\r\n\tString getLogPrefix();\r\n\tdefault Builder mutate() {\r\n\t\treturn new DefaultServerWebExchangeBuilder(this);\r\n\t}\r\n\r\n\tinterface Builder {\r\n\t\tBuilder request(Consumer<ServerHttpRequest.Builder> requestBuilderConsumer);\r\n\t\tBuilder request(ServerHttpRequest request);\r\n\t\tBuilder response(ServerHttpResponse response);\r\n\t\tBuilder principal(Mono<Principal> principalMono);\r\n\t\tServerWebExchange build();\r\n\t}\r\n\r\n}\n주요 메서드들을 정리해보면 아래와 같습니다.\ngetRequest(), getResponse : ServerHttpRequest, ServerHttpResponse\ngetAttributes() : 요청 중 추가/변경 가능한 key/value 형태의 Map을 접근하는 함수.\ngetSession() : Session 정보를 담고 있는 WebSessions Publisher를 반환\ngetPrincipal() : Security 정보와 관련된 Principal Publisher를 반환\ngetFormData() : Content-Type 이 application/x-www-form-urlencoded 인 데이터에 대해 MultiValueMap 의 형태의 데이터를 제공하는 Publisher 를 반환\ngetMultipartData() : Content-Type 이 multipart/form-data 인 데이터에 대해 body 를 MultiValueMap 형태로 제공\ngetApplicationContext() : Spring 환경에서 구동된 경우 applicationContext 를 반환. Spring 환경에서 구동된 것이 아닐 경우에는 null 을 리턴","webhandler#WebHandler":"ServerWebExchange 단위로 요청을 받으며, WebHandler 내에서 ServerWebExchanbe 객체를 통해 request, response 에 접근 가능합니다.WebHandler 는 외부로부터 요청이 왔을 때 Reactor Netty와 Dispatcher Handler 를 거쳐서 DispatcherHandler 가 HandlerAdapter 를 찾습니다. 이후 해당 HandlerAdapter의 handle() 메서드 호출시 WebHandlerAdapter 가 적절한 WebHandler를 찾은 후 WebHandler 의 handle() 메서드를 호출하는데, 여기에서 WebHandler의 handle() 메서드를 호출하기 전에 WebFilter의 filter() 가 호출됩니다. 그리고 익셉션 등이 발생할 경우에는 WebExceptionHandler 의 handle() 메서드를 호출하게 됩니다.","httphandler#HttpHandler":"HttpHandler 는 WebHandler 보다 row level 에서 동작하는 Handler 입니다. 그래서 httpHandler 내에서 조금더 상위 버전인 webHandler 를 바인딩해서 기능을 확장했습니다. 자세한 내용은 An introduction to Reactive Web 을 참고하시기 바랍니다.\n예를 들어서 HttpHandler 를 직접 작성해서 ReactiveHttpHandlerAdapter 에 바인딩한 후 HttpServer 에 이 HandlerAdapter 를 지정해서 서버를 직접 구동하는 코드는 아래와 같습니다.\npackage io.chagchagchag.example.foobar.spring_webflux;\r\n\r\n// ...\r\n\r\n\r\n@Slf4j\r\npublic class WebHandlerExample1_AcceptOnlyJson {\r\n  private static record TickerRecord(\r\n      String ticker\r\n  ){\r\n\r\n  }\r\n\r\n  @SneakyThrows\r\n  public static void main(String[] args) {\r\n    var codecConfigurer = ServerCodecConfigurer.create();\r\n    var webHandler = new WebHandler(){\r\n      @Override\r\n      public Mono<Void> handle(ServerWebExchange exchange) {\r\n        final ServerRequest request = ServerRequest.create(exchange, codecConfigurer.getReaders());\r\n        final ServerHttpResponse response = exchange.getResponse();\r\n\r\n        var bodyToMono = request.bodyToMono(TickerRecord.class);\r\n        return bodyToMono.flatMap(tickerRecord -> {\r\n          String tickerQuery = tickerRecord.ticker();\r\n          String ticker = tickerQuery == null ? \"NVDA\" : tickerQuery;\r\n\r\n          String content = \"You picked \" + ticker;\r\n          log.info(\"responseBody : {}\", content);\r\n\r\n          Mono<DataBuffer> responseBody = Mono.just(\r\n              response.bufferFactory().wrap(content.getBytes())\r\n          );\r\n\r\n          response.getHeaders().add(\"Content-Type\", \"text/plain\");\r\n          return response.writeWith(responseBody);\r\n        });\r\n      }\r\n    };\r\n\r\n    final HttpHandler httpHandler = WebHttpHandlerBuilder\r\n        .webHandler(webHandler)\r\n        .build();\r\n\r\n    final var adapter = new ReactorHttpHandlerAdapter(httpHandler);\r\n    HttpServer.create()\r\n        .host(\"localhost\").port(8080)\r\n        .handle(adapter)\r\n        .bindNow()\r\n        .channel().closeFuture().sync();\r\n  }\r\n}\r\n코드를 요약해보면 이렇습니다.WebHandler 를 생성한 후 HttpHandler에 바인딩했습니다. 그리고 생성한 HttpHandler 는 ReactiveHttpHandlerAdapter 내에 바인딩했고, 이렇게 생성한 adapter 는 HttpServer 객체 내에 handle() 메서드를 통해 HttpHandler 를 바인딩합니다.","serverhttprequest-serverhttpresponse#ServerHttpRequest, ServerHttpResponse":"ServerWebExchange 객체로 접근할 수 있는 요청/응답 객체인 ServerHttpRequest, ServerHttpResponse 객체에 대해서 알아봅니다.위에서 이야기했듯 Reactor Netty 기반의 Spring 환경에서는 HttpServerRequest, HttpServerResponse 객체를 요청/응답 객체로 사용합니다. ServerHttpRequest, ServerHttpResponse interface 는 아래와 같이 상위타입인 HttpMessage  interface 로 대체가 가능합니다.","serverhttprequest#ServerHttpRequest":"ServerHttpRequest 로 접근 가능한 메서드들은 아래와 같습니다.\ngetCookies() : 클라이언트가 전달하는 read only 쿠키를 Map 으로 제공\ngetPath() : query 를 포함되지 않은 path 를 리턴\ngetQueryParams() : decoded 된 query parameter map 을 return\nmutate() :\ndefault 로 선언된 메서드.\nuri, path, header 등을 변경할 수 있는 ServerHttpRequest Builder 를 제공\nServerHttpRequest 자신을 Builder로 변경할수 있도록 제공되는 메서드\nServerHttpRequest 에 접근할 수 있는 ServerWebExchange 타입 역시 Builder로 변경할 수 있는 메서드인 mutate() 함수를 제공합니다.\ngetBody() :\n상위타입인 ReactiveHttpInputMessage 타입에서 제공되는 메서드입니다.\n클라이언트가 전달하는 request body를 Flux<DataBuffer> 형태로 수신합니다. Flux 이므로 DataBuffer 가 여러번에 걸쳐서 전달됨을 유추 가능합니다.\ngetMethod()\n상위타입인 HttpRequest 타입에서 제공하는 메서드 입니다.\nHTTP 요청 메서드를 파악할 때 사용합니다.\ngetURI()\n상위타입인 HttpRequest 에서 제공하는 메서드 입니다.\nquery param 이 모두 포함된 전체 URI 정보를 return\ngetHeaders()\n상위타입인 HttpMessage 타입에서 제공하는 메서드입니다.\nHttpHeaders 객체에 접근하는 메서드. HttpHeaders 클래스는 헤더 추가, 삭제 등 헤더에 관련된 유용한 메서드 들이 존재합니다.","uri#URI":"URI 객체는 아래와 같이 구성됩니다.","requestpath#RequestPath":"RequestPath 를 사용하면 contextPath(), pathWithinApplication() 과 같은 메서드 들을 사용할 수 있습니다. Spring Webflux 는 기본적으로 Root Context Path 를 \"/\" 으로 갖습니다. 이 값은 spring.webflux.base-path 프로퍼티를 제공해서 변경 가능합니다.e.g.\nspring.webflux.base-path=/wow\ne.g.\npackage io.chagchagchag.example.foobar.spring_webflux;\r\n\r\nimport java.net.URI;\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport org.springframework.http.server.RequestPath;\r\n\r\n@Slf4j\r\npublic class URIExample1 {\r\n  @SneakyThrows\r\n  public static void main(String[] args) {\r\n    URI uri = new URI(\"http://localhost:8080/order/coffee?number=1#detail\");\r\n    RequestPath requestPath = RequestPath.parse(uri, \"/order\");\r\n    log.info(\"requestPath.pathWithinApplication() : {}\", requestPath.pathWithinApplication());\r\n    log.info(\"requestPath.contextPath() : {}\", requestPath.contextPath());\r\n  }\r\n}\n출력결과\n00:52:32.353 [main] INFO io.chagchagchag.example.foobar.spring_webflux.URIExample1 -- requestPath.pathWithinApplication() : /coffee\r\n00:52:32.367 [main] INFO io.chagchagchag.example.foobar.spring_webflux.URIExample1 -- requestPath.contextPath() : /order","serverhttpresponse#ServerHttpResponse":"ServerHttpResponse 로 접근 가능한 주요 메서드 들은 아래와 같습니다.\naddCookie(ResponseCode) : Cookie 를 추가하는 데에 사용합니다.\nsetStatusCode(HttpStatusCode) : status 를 지정할 때 사용합니다.\ngetStatusCode() : status 를 받아올때 사용합니다.\nsetComplete() : Response 의 Content 를 추가하기 전에 complete 하도록 하는 메서드 입니다.\ngetHeaders() : HttpHeaders 를 return 합니다. HttpHeaders 를 사용하면 header 추가/수정/삭제를 수행가능합니다."}},"/spring-webflux/servlet-stack-vs-reactive-stack":{"title":"Servlet Stack Vs Reactive Stack","data":{"servlet-stack-vs-reactive-stack#Servlet Stack vs Reactive Stack":"","servlet-stack#Servlet Stack":"Servlet Stack 은 대표적으로 위와 같이 구성되어 있습니다. 스레드를 무분별하게 사용하는 것으로 문제되는 부분은 Servlet Container, Spring Security, Spring Data 스택입니다.\nServlet Container\nSpring Security\nSpring Data","servlet-container#Servlet Container":"Servlet Container 를 지원하는 대표적인 컨테이너는 Tomcat, Jetty, JBoss 가 있습니다. Servet Container 는 request-per-thread 모델을 사용하는데, 요청이 들어올 때마다 스레드를 할당하는 방식으로 클라이언트의 요청 처리에 동시성을 부여합니다.\nConnector 가 제일 앞단에서 HTTP 통신을 수행하고 Filter 가 Servlet 의 앞단에서 각 요청의 앞/뒤에서 미리 등록해둔 동작을 수행합니다. 그리고 request, response 는 Servlet 의 service() 에 전달 됩니다.이 Connector 는 request 하나에 대해 하나의 thread 를 사용하며, tomcat 의 기본 설정 스레드 풀 사이즈는 200 개입니다.전통적인 웹 서비스에서는 이런 모델이 어느 정도는 통했습니다. 하지만 최근의 트래픽 처리 모델에서는 IO 가 많고, 여러가지 http 요청 등을 수행하고 Security Context 관리, MVC 동작 수행등을 하면서 조금씩 요청 하나에 드는 비용이 커지기 시작했습니다.따라서 하나의 스레드가 회수 되는 데에 예전보다 더 긴 시간이 소요되게 되었고, 스레드를 지나치게 낭비한다는 측면에서 단점이 있습니다.","spring-security#Spring Security":"Spring Security 는 인증 (Authentication), 인가(Authorization) 를 위한 유용한 기능들을 많이 제공합니다. 하지만 Servlet Stack 기반의 Spring Security 역시 Thread 모델로 인한 단점들이 존재합니다.예를 들어 Spring Security 를 사용하다보면,  SecurityContextHolder 를 이용해서 authentication 을 set 하게 됩니다.\npackage org.springframework.security.core.context;\r\n\r\n// ...\r\npublic class SecurityContextHolder {\r\n  // ...\r\n\r\n  private static void initializeStrategy() {\r\n    if (\"MODE_PRE_INITIALIZED\".equals(strategyName)) {\r\n      Assert.state(strategy != null, \"When using MODE_PRE_INITIALIZED, setContextHolderStrategy must be called with the fully constructed strategy\");\r\n    } else {\r\n      if (!StringUtils.hasText(strategyName)) {\r\n        strategyName = \"MODE_THREADLOCAL\";\r\n      }\r\n\r\n      if (strategyName.equals(\"MODE_THREADLOCAL\")) {\r\n        strategy = new ThreadLocalSecurityContextHolderStrategy();\r\n      } else if (strategyName.equals(\"MODE_INHERITABLETHREADLOCAL\")) {\r\n        strategy = new ();\r\n      } else if (strategyName.equals(\"MODE_GLOBAL\")) {\r\n        strategy = new GlobalSecurityContextHolderStrategy();\r\n      } else {\r\n        try {\r\n          Class<?> clazz = Class.forName(strategyName);\r\n          Constructor<?> customStrategy = clazz.getConstructor();\r\n          strategy = (SecurityContextHolderStrategy)customStrategy.newInstance();\r\n        } catch (Exception var2) {\r\n          ReflectionUtils.handleReflectionException(var2);\r\n        }\r\n\r\n      }\r\n    }\r\n  }\r\n  \r\n  // ...\r\n\r\n}\nSecurityContextHolder 가 사용하는 기본 공유 전략은 MODE_THREADLOCAL 입니다. 위 코드를 보면 ThreadLocal 을 사용하기에 reactive 환경 처럼 스레드가 계속 바뀌는 환경에서는 Spring Security 를 사용하기에는 쉽지 않습니다. SecurityContextHolder 의 공유 전략에 대해서는 아래의 자료들을 참고해주시기 바랍니다.\nSpringContext 공유 전략\nSecurityContextHolder 의 내부를 파헤쳐보자","spring-data#Spring Data":"Spring Data 의 연산은 블로킹 방식의 동기연산을 수행합니다. 그리고 DB 요청 하나당 하나의 스레드를 사용합니다. 하나의 스레드가 블로킹 기반의 동기연산을 수행하는데, DB 연산의 비용(시간)이 꽤 높은 편에 속하기에 스레드를 어느 정도는 비싼 값을 치뤄서 사용합니다.","c10k-problem-client-10k#C10K Problem (Client 10K)":"1만개의 클라이언트가 요청을 하는 상황에 대한 문제를 의미하는 C10K Problem은 굉장히 잘 알려진 고전적인 주제입니다. C10K Problem 은 1999년 Dan Kegel 이라는 개발자가 제기한 문제입니다.이것과 관련해서 읽어볼만한 자료들은 아래와 같습니다.\nC10K Problem\n고전 돌아보기, C10K 문제 (C10K Problem)\nabout C10K problem\n쉽게 정리한 네트워크 | Apache와 Nginx의 요청 응답 구조\n1초에 10000개의 클라이언트의 요청이 오는 것을 처리하려 할 때 흔히 처음에는 아래와 같은 생각을 할수도 있습니다.\nthread 를 이용해서 스레드를 request 마다 1개씩 할당한다.\n흔히 이 문제를 설명할 때 Apache 와 Nginx 의 차이점을 들어서 설명합니다.\n참고 : 쉽게 정리한 네트워크 | Apache와 Nginx의 요청 응답 구조\nApache 는 멀티 프로세스 + 멀티 스레드 방식을 사용합니다. 사용자의 요청에 대해 Process/Thread 를 생성하는 방식으로 대응합니다. 항상 여유로운 프로세스/스레드를 생성합니다. 미리 설정해둔 유휴(Idle) 프로세스의 수에 따라 넘어가면 kill 하고, 유휴 스레드가 적으면 kill 을 하는 방식으로 스레드를 관리합니다. Apache 는 일반적으로 요청 하나에 스레드 하나가 대응되도록 구성되어 있습니다. 하나의 프로세스가 관리할 수 있는 스레드의 수는 한정되어 있는데, 따라서 사용자의 접속이 증가하면 프로세스를 새로 fork 합니다. Apache 는 fork 를 할 때마다 CPU와 메모리 사용량이 증가한다는 단점이 있습니다.Nginx 는 멀티 프로세스 + 싱글 스레드 방식을 사용합니다. low memory usage, high concurrency 를 지원하기 위해 async event driven 방식을 채택하고 있고 싱글스레드에서 요청에 응답을 합니다. Nginx 는 master process 가 다수의 worker process 를 관리합니다. master process 는 worker process 를 관리하는 일만을 담당하고 worker process 에서 사용자의 응답에 대응합니다. 각각의 worker 는 초당 수천개의 동시접속, 요청을 처리 가능합니다.Apache, Nginx 의 동시 접속자가 늘어날 때 RPS (Request Per Second) 의 변화 추이는 아래 그림과 같습니다. RPS 는 1초에 처리 가능한 Request 의 개수라고 이해하시면 됩니다. 대표적인 웹 서버인 Apache 와 Nginx 에서의 RPS 처리 성능을 비교한 그래프를 보면 Apache Httpd 의 경우 성능이 급속도로 떨어지는 것을 확인 가능합니다.","10k-의-스레드-실행시-생길수-있는-문제들#10K 의 스레드 실행시 생길수 있는 문제들":"첫번째로 메모리 문제가 발생합니다. thread 각각은 메모리 스택을 가집니다. PCB 보다는 작지만 64Bit JVM 의 경우 1개의 스레드에 대해 1024KByte(1MB)를 사용한다고 합니다. 1만명일 경우 10000MB = 10GB 가 필요하다는 계산에 이르게 됩니다.두번째로 스레드가 많을 경우 Context Switching 시에 경합(Racing Condition)이 발생합니다. 각각의 Thread 가 사용할 CPU 시간을 할당받기 위해 서로 경쟁을 하게 됩니다. 소켓 프로그래밍의 각 커넥션을 10K 의 스레드로 동작할 경우 10K 스레드 각각이 accept(), listen() 동작 등으로 인한 polling 을 하기 위한 경쟁이 발생합니다. 즉 Busy Wait 증상이 나타나기 시작합니다. 채팅창에 텍스트를 입력하지 않더라도 accept(), listen() 을 위한 무한 polling 을 10K의 스레드에서 수행중이기에 10K의 스레드 각각이 서로 CPU 자원을 차지하기 위해 싸우게 됩니다.\nHow Many Threads Is Too Many? 에서는 아래의 그림으로 위 현상으로 인한 결과를 이야기합니다.","가능한-해결책--select-poll-epoll-kqueue-iocp-를-이용한-다중화멀티플렉싱#가능한 해결책 : select, poll, epoll, kqueue, iocp 를 이용한 다중화(멀티플렉싱)":"C10K Problem 에서는 아래와 같이 select(), poll(), kqueue 등의 방법을 제안하고 있습니다. 1990 년도의 linux 에서는 epoll 이 없었기에 BSD OS기반의 서버에서 kqueue 를 사용하거나 select, poll 을 사용하는 것이 주요 방법이었습니다.","select-poll#select, poll":"위 문서에서 보듯 1990년대에 10K 문제는 select, poll 을 통해서 해결했습니다. select, poll 을 쉽게 설명하면 IO 를 멀티플렉싱(다중화)하고 통지하고, 감시할 수 있도록 해주는 기술이라고 생각하면 됩니다.select 함수는 아래의 특징을 갖습니다.\n다중 소켓 관리 : 여러 개의 소켓, 파일 디스크립터를 한번에 감시할 수 있습니다.\n이벤트 기반(Event Driven) : 특정 소켓에서 이벤트가 발생했을 때 알림을 받아 처리할 수 있습니다. 이렇게 함으로써 블로킹 되지 않고 다른 작업을 수행하다가 필요한 소켓에서 이벤트가 발생했을 때에 처리를 할 수 있습니다.\n비동기(Asynchronous) : 비동기적으로 동작하여, 입출력이 준비되지 않아도 다른 작업을 처리 가능합니다.\n1990년대 네트워크 IO 모델은 select(), poll() 이 전부였습니다. select 는 파일디스크립터를 사용하기 때문에 클라이언트 1024개만 처리가 가능합니다. poll() 의 경우 제한이 없습니다. 두 모델 모두 이벤트 발생시 어떤 소켓에서 처리해야 할지 알수 없기에 소켓들을 모두 하나씩 체크합니다. 일일이 소켓들을 하나씩 체크하기에 O(n)의 시간이 소요되는데, 이벤트가 발생할 때마다 소켓을 검색하기 위해 O(n)의 시간이 소요됩니다. 참고) 파일디스크립터\n유닉스 계열의 OS 에서는 일반적인 파일, 네트워크 소켓, 파이프, 블록 디바이스, 캐릭터 디바이스 등의 모든 객체를 파일로 관리합니다.\n열려있는 파일에 접근할 때 fd 를 이용해서 파일을 지정하는데, fd 는 음이 아닌 정수이며, file descriptor table의 index로 사용됩니다.\n파일디스크립터의 수가 클 수록 그 수에 도달하기까지 for 문을 순회해야 한다는 문제도 있고 애플리케이션에서 fd  들을 관리해야 했기 때문에 유지보수가 쉽지 않았다는 문제 역시 있었습니다.또한 select 함수는 커널에 의해 완성되는 기능이 아니라 순수 함수에 의해 동작하기 때문에 select 함수 호출 시 전달된 정보는 운영체제에 등록되지 않고, 따라서 select 호출 시 마다 매번 과련 정보를 전달해줘야 했습니다. 따라서 관찰 대상의 범위, 내용에 변경이 있을 때 변경 사항만 알려줄 수 있으면 한다는 요구사항을 epoll 이 충족시켜줬습니다.","epoll-kqueue-iocp#epoll, kqueue, IOCP":"epoll, kqueue, IOCP는 널리 알려진 I/O 멀티플렉싱(다중화) 기술이며, non-blocking I/O 에 널리 사용되는 방식입니다.리눅스에서 사용되는 epoll() 은 select 의 단점을 보완한 IO 통지 모델입니다. 파일디스크립터를 사용자가 아닌 커널이 관리를 합니다. 파일 디스크립터를 지속적으로 감시할 필요가 없기에 BUSY WAIT 으로 인한 CPU 점유율 문제도 없습니다. select 를 사용시에는 파일 디스크립터를 찾기 위해 전체 파일 디스크립터를 순차검색하기 위햔 FD_ISSET 루프를 돌려야 했지만, epoll 은 이벤트가 발생한 파일 디스크립터만 구조제 배열로 넘겨주기에 메모리 카피 비용이 줄어들었습니다.우리에게 많이 알려진 Node.js 는 내부적으로 epoll() 을 기반으로 구현되어 있습니다. Nginx 는 epoll(), select(), kqueue() 를 기반으로 구현된 웹 서버입니다. Nginx 의 성능이 좋은 이유는 내부적으로 non-blocking I/O 방식의 epoll() 방식으로 구현되어 있었기 때문입니다.자바에서는 NIO 가 JDK4 에서부터 도입되었고 JDK 1.7 에서는 NIO2 라고 불리는 AIO가 도입되었습니다. NIO, AIO 는 모두 Non-Blocking I/O, Zero Copy 기술을 지원합니다. Netty 는 NIO 를 기반으로 동작합니다. NIO 역시 epoll 기반으로 이루어져 있습니다.(윈도우에서는 IOCP 기반, NIO2 에서는 윈도우 JVM 역시 epoll 기반으로 동작)kqueue, IOCP 는 epoll 과 같은 기능을 하는 BSD, MS Window 운영체제의 기능입니다. BSD 에서는 아주 오래전부터 kqueue 가 구현되어 있었습니다.  epoll 은 BSD 보다 늦게 나타났고, linux 2.6 부터 지원하기 시작했습니다. IOCP(Input/Output Completion Port)은 Microsoft Windows 에서 지원하는 기술이며, epoll 보다 먼저 구현되어 있었고 네트워크 성능면에서는 리눅스보다 우월했다는 평가도 존재했습니다.BSD 는 socket 을 처음으로 구현한 유닉스 버전이고, 네트워크 성능을 최대로 사용할 수 있는 유닉스 커널이었습니다. 이런 이유로 초창기 고성능 인터넷 서버는 BSD 기반의 서버가 많았습니다.","epoll#epoll":"epoll 은 리눅스에서 select() 의 단점을 보완해서 사용이 가능하도록 만든 I/O 다중화 (Multiplexing) 모델입니다. select() 를 사용할 때는 프로그래머가 직접 파일 디스크립터 배열을 가지고 있고 select() 함수가 호출될 때마다 전체 파일 디스크립터가 프로그래머가 관리하는 배열로 복사됩니다.하지만 epoll 을 사용할 때는 커널 공간이 파일 디스크립터를 관리하고 변경된 파일디스크립터 들만을 사용자에게 통지해주기 때문에 select 보다는 빠르게 동작할 수 있습니다.epoll 의 주요 함수는 epoll_create, epoll_ctl, epoll_wait 이 잇습니다.  epoll_create 를 이용해서 epoll 구조체를 생성할 수 있고 epoll_ctl 를 사용하면 파일디스크립터를 등록,수정,삭제하는 작업이 가능하며, epoll_wait 을 사용하면 파일 디스크립터의 변화를 감지할 수 있습니다.\nepoll 의 주요 특징은 아래와 같습니다.\nEvent Driven (이벤트 기반) : epoll 은 이벤트가 발생한 소켓에 대해 알림을 받아서 처리합니다. 풀링 작업 업싱 발생한 이벤트에 대해서만 작업을 처리합니다.\nAsynchronous (비동기) : 비동기적으로 동작하고, 입출력이 준비되지 않은 상태에서도 다른 작업을 수행 가능합니다.\nScalability (스케일링 가능성) : epoll 은 연결 수가 증가해도 성능 저하가 적게 발생합니다. 따라서 대규머 네트워크 애플리케이션에서 많은 수의 연결을 관리할 때 효과적입니다.","netty#Netty":"Netty 는 비동기 이벤트 기반의 오픈 소스 네트워크 애플리케이션 프레임워크 입니다.Netty 는 epoll 과 같은 운영체제 수준의 이벤트 루프를 활용해서 네트워크 이벤트를 처리합니다. epoll 은 위에서 살펴봤듯 I/O 멀티플렉싱(다중화) 기술 중 하나입니다. Netty 는 이벤트 기반 아키텍처를 선택하고 있기 때문에 비동기 논 플로킹 기반의 작업 처리가 가능합니다.HTTP 외에도 다양한 프로토콜을 지원하고 Java NIO, Selector 기반으로 적은 리소스로 높은 성능을 보장해줍니다. 불필요한 메모리 copy 를 최소한으로 하며, 이벤트 모델 기반입니다.","spring-reactive-stack-의-구성#Spring Reactive Stack 의 구성":"Reactor 기반의 Netty 를 사용한다면 Reactor Netty 를 사용하게 됩니다. Reactor Netty 는 Netty 를 Reactor 기반으로 조합성,편의성을 크게 확장한 WAS 컨테이너 입니다.Reactor 는 Pivotal 사에서 공식적으로 제공한 Reactive Streams 구현체 라이브러리입니다.Spring Webflux 는  Servlet 기반 웹 애플리케이션의 동기적인 처리 방식 대신 비동기 및 반응형 프로그래밍 모델을 제공합니다. Spring WebFlux는 Java 8의 CompletableFuture 및 Reactor 프로젝트를 기반으로 한 리액티브 라이브러리를 활용하여 구현되어있는 Spring Web 을 위한 반응형 프로그래밍 라이브러리 입니다.서블릿 기반의 톰캣 컨테이너에서는 request-per-thread 정책을 통해 요청 하나 당 스레드 하나를 생성해서 대응했고 Spring Data 역시 IO 요청 하나당 스레드 하나를 생성해서 대응했습니다. 하지만 Spring Webflux 는 Reactor Netty 기반에서 동작하는데, Netty는 내부적으로 IO 요청을 멀티플렉싱(다중화)하도록 되어 있기 때문에 Servlet 기반의 요청 처리 모델에 비해 조금 더 높은 트래픽을 지연 없이 수용할 수 있습니다.Spring Webflux 의 주요특징, 개념은 아래와 같습니다.\n비동기 및 반응형 프로그래밍: Spring WebFlux는 비동기적이며 반응형 프로그래밍 모델을 채택합니다. 이는 높은 동시성과 확장성을 제공하며, 논블로킹 I/O를 활용하여 더 많은 동시 요청을 처리할 수 있습니다.\nReactor 라이브러리: Spring WebFlux는 Reactor 라이브러리를 기반으로 하여, Flux와 Mono라는 리액티브 타입을 제공합니다. Flux는 여러 개의 데이터를 처리하는 데 사용되고, Mono는 0 또는 1개의 데이터를 처리하는 데 사용됩니다.\n함수형 엔드포인트: Spring WebFlux는 기존의 컨트롤러 대신 함수형 엔드포인트를 제공합니다. 이는 람다 표현식이나 Java 8의 함수형 인터페이스를 사용하여 간결하고 가독성 있는 코드를 작성할 수 있게 합니다.\n반응형 서버 및 클라이언트: Spring WebFlux는 반응형 서버와 클라이언트를 모두 제공합니다. 서버 측에서는 Netty와 같은 서버를 이용하여 비동기적으로 요청을 처리하고, 클라이언트 측에서는 WebClient를 통해 외부 서비스에 비동기적으로 요청을 보낼 수 있습니다.\n어노테이션 기반의 라우팅: Spring WebFlux는 기존의 Spring MVC와 유사한 어노테이션 기반의 라우팅을 지원하여 빠르게 웹 애플리케이션을 개발할 수 있습니다.\n모노리틱 및 마이크로서비스 아키텍처 지원: Spring WebFlux는 단일 서버에서 실행되는 전통적인 모노리틱 애플리케이션부터 분산된 마이크로서비스 아키텍처까지 다양한 환경에서 사용할 수 있습니다."}},"/spring-webflux/spring-mvc-vs-spring-webflux":{"title":"Spring Mvc Vs Spring Webflux","data":{"spring-mvc-vs-spring-webflux#Spring MVC vs Spring Webflux":"참고 : https://docs.spring.io/spring-framework/reference/web/webflux/new-framework.html\nSpring Webflux 에서도 Annotated Controller 라고 불리는 @Controller를 사용가능합니다. Spring MVC 에서도 Spring Webflux 의 Reactive Client 를 사용가능합니다. 그리고 Spring Webflux 에서도 Tomcat, Jetty, Undertow 등을 사용 가능합니다.","reactive-구현체와-reactive-adapter#Reactive 구현체와 Reactive Adapter":"Reactor, RxJava, Mutiny, kotlin coroutine 등과 같은 Reactive Streams 구현체는 모두 Reactive Streams 의 Publiser 타입으로 호환이 가능합니다. 그리고 이 Publisher 는 ReactiveAdapter 를 통해서 적용이 되며, Reactive AdapterRegistry 에 등록되어서 여러 종류의 Reactive Streams 구현체를 사용하는 것이 가능합니다.","spring-reactive-stack-의-구성#Spring Reactive Stack 의 구성":"Reactor 기반의 Netty 를 사용한다면 Reactor Netty 를 사용하게 됩니다. Reactor Netty 는 Netty 를 Reactor 기반으로 조합성,편의성을 크게 확장한 WAS 컨테이너 입니다.Reactor 는 Pivotal 사에서 공식적으로 제공한 Reactive Streams 구현체 라이브러리입니다.Spring Webflux 는  Servlet 기반 웹 애플리케이션의 동기적인 처리 방식 대신 비동기 및 반응형 프로그래밍 모델을 제공합니다. Spring WebFlux는 Java 8의 CompletableFuture 및 Reactor 프로젝트를 기반으로 한 리액티브 라이브러리를 활용하여 구현되어있는 Spring Web 을 위한 반응형 프로그래밍 라이브러리 입니다.Spring Webflux 의 주요특징, 개념은 아래와 같습니다.\n비동기 및 반응형 프로그래밍: Spring WebFlux는 비동기적이며 반응형 프로그래밍 모델을 채택합니다. 이는 높은 동시성과 확장성을 제공하며, 논블로킹 I/O를 활용하여 더 많은 동시 요청을 처리할 수 있습니다.\nReactor 라이브러리: Spring WebFlux는 Reactor 라이브러리를 기반으로 하여, Flux와 Mono라는 리액티브 타입을 제공합니다. Flux는 여러 개의 데이터를 처리하는 데 사용되고, Mono는 0 또는 1개의 데이터를 처리하는 데 사용됩니다.\n함수형 엔드포인트: Spring WebFlux는 기존의 컨트롤러 대신 함수형 엔드포인트를 제공합니다. 이는 람다 표현식이나 Java 8의 함수형 인터페이스를 사용하여 간결하고 가독성 있는 코드를 작성할 수 있게 합니다.\n반응형 서버 및 클라이언트: Spring WebFlux는 반응형 서버와 클라이언트를 모두 제공합니다. 서버 측에서는 Netty와 같은 서버를 이용하여 비동기적으로 요청을 처리하고, 클라이언트 측에서는 WebClient를 통해 외부 서비스에 비동기적으로 요청을 보낼 수 있습니다.\n어노테이션 기반의 라우팅: Spring WebFlux는 기존의 Spring MVC와 유사한 어노테이션 기반의 라우팅을 지원하여 빠르게 웹 애플리케이션을 개발할 수 있습니다.\n모노리틱 및 마이크로서비스 아키텍처 지원: Spring WebFlux는 단일 서버에서 실행되는 전통적인 모노리틱 애플리케이션부터 분산된 마이크로서비스 아키텍처까지 다양한 환경에서 사용할 수 있습니다."}},"/webflux-websocket/example":{"title":"Example","data":{}},"/webflux-websocket/intro":{"title":"Intro","data":{}}}